[["index.html", "Motus R Book A walk through the use of R for Motus automated radio-telemetry data", " Motus R Book Tara L. Crewe, Zoe Crysler, and Philip Taylor A walk through the use of R for Motus automated radio-telemetry data Our goal with this online handbook is to show Motus (https://motus.org) users how to use the R statistical programming language (https://www.r-project.org/) to import tag detections data for a project or receiver; clean data and filter false positives; explore detections data through visualizations and summaries; transform the data, e.g., by determining time since sunrise/sunset or magnetic declination; and run various analytical procedures. We hope the contents will be of use, and if you have suggestions for additional examples, please let us know by emailing motus@birdscanada.org. The current version is largely based on the earlier work by Crewe et al. 2018 (available at https://motus.org/motusRBook/archives/MotusRBook2018-01.pdf), and has since been supplemented by various people on the Motus team. Published September 2020 using motus v4.0.0 This work is licensed under a Creative Commons Attribution 4.0 International License "],["introduction.html", "1 Introduction 1.1 What this book does not cover 1.2 Prerequisites 1.3 Sample datasets 1.4 Acknowledgements", " 1 Introduction This chapter was contributed by Tara L. Crewe, Zoe Crysler, and Philip Taylor The Motus Wildlife Tracking System (Motus; Taylor et al. 2017; https://www.motus.org) is an international, collaborative automated radio-telemetry network to track the movement and behaviour of flying organisms affixed with digitally encoded radio-transmitters. Motus was developed at Acadia University in 2012-2013. In 2014, a major infrastructure expansion was made possible through a Canada Foundation for Innovation grant to Western University, The University of Guelph, and Acadia University. Since then, Motus has grown through the collaboration of independent researchers and organizations (see https://motus.org/about/). It is now managed as a program of Bird Studies Canada (https://www.birdscanada.org) in partnership with Acadia University. Motus is unique among automated telemetry arrays in that all researchers in a geographic region (e.g., the Americas or Europe) use a shared radio frequency. This allows tagged animals to be detected by any receiving station across the network, greatly broadening the spatial scope of potential research questions. Motus users also use a shared data infrastructure and web portal: all data collected from across the network are centrally stored and archived, which allows users to access detections of their tags by anyones receiver in the network, and individuals that maintain receivers have access to all detections of anyones tags on those receivers. Having a shared data infrastructure also means that users can benefit from R functions written specifically for Motus data by any and all users. The motus R package described in this book is in continual development, and the intent of this online handbook is to help users learn the various functionalities of the package, and potentially contribute to it. We also show how additional R packages such as ggplot can be used to explore, visualize, transform, and analyze Motus data. The content of the handbook will continue to evolve and grow along with the analytical needs of the network. Those interested in contributing code to the Motus R package or this handbook can send proposed additions to motus@birdscanada.org. Taylor, P. D., T. L. Crewe, S. A. Mackenzie, D. Lepage, Y. Aubry, Z. Crysler, G. Finney, C. M. Francis, C. G. Guglielmo, D. J. Hamilton, R. L. Holberton, P. H. Loring, G. W. Mitchell, D. R. Noriis, J. Paquet, R. A. Ronconi, J. Smetzer, P. A. Smith, L. J. Welch, and B. K. Woodworth. 2017. The Motus Wildlife Tracking System: a collaborative research network to enhance the understanding of wildlife movement. Avian Conservation and Ecology 12(1):8. https://doi.org/10.5751/ACE-00953-120108. 1.1 What this book does not cover This book does not cover how to register radio tags with Motus, manage tags and station deployments, or upload raw detections data for processing. Information to guide you through those tasks can be found under the resources tab on the Motus website at https://motus.org/resources/. Please remember to register your tags prior to deployment, and enter tag and station metadata online in a timely manner. Please also review the Motus collaboration policy and tag registration and fee schedule at https://motus.org/policy/. 1.2 Prerequisites This book assumes that you have a basic understanding of R. Regardless of whether you are new to R or not, we highly recommend that you become familiar with R for Data Science by Garrett Grolemund and Hadley Wickham (http://r4ds.had.co.nz/). Their book covers how to import, visualize, and summarize data in R using the tidyverse collection of R packages (https://www.tidyverse.org/). It also provides an invaluable framework for organizing your workflow to create clean, reproducible code (http://r4ds.had.co.nz/workflow-projects.html). We follow their lead by, wherever possible, using the tidyverse framework throughout this book. 1.3 Sample datasets Throughout this book we use subsets of real datasets to illustrate how to access, manage, explore and analyze Motus data in R. We recommend that you run through the sample code in each chapter with the sample dataset before running through with your own data, because you will undoubtedly need to modify the code we provide in order to deal most effectively with your own data (every situation is different). Chapters 2 through 6 use a subset of data from the James Bay Shorebird Project. The James Bay Shorebird Project conducts monitoring and research on shorebirds staging along the James Bay coast, and is a collaborative effort among the Ontario Ministry of Natural Resources and Forestry, Bird Studies Canada, Trent University, and Environment and Climate Change Canadas Canadian Wildlife Service, in conjunction with a larger conservation initiative involving James Bay First Nations and Nature Canada. The Royal Ontario Museum was a contributing partner until 2016. The goals of the project are to 1) improve the ability to estimate indices of abundance and population trends for shorebird species staging along the western James Bay coast, 2) understand movement patterns and their causes, and 3) identify the relative importance of shorebird staging sites and their habitats. Collectively, this information will aid in the development of conservation measures for Red Knot and other shorebird species through habitat protection like Western Hemisphere Shorebird Reserve Network (WHSRN) designation. More information can be viewed on the James Bay Shorebird Project website at https://www.jamesbayshorebirdproject.com/, on Facebook https://www.facebook.com/jamesbayshorebirdproject/, or by contacting their project lead: Christian Friis Wildlife Biologist Canadian Wildlife Service Environment and Climate Change Canada / Government of Canada christian.friis@canada.ca / Tel: 416.739.4908 Biologiste de la Faune Service Canadien de la Faune Environnement et Changement Climatique Canada / Gouvernement du Canada christian.friis@canada.ca / TÃ©l. : 416.739.4908 In Chapter 7, we use a subset of data collected by the Motus project Studies of Migratory Birds and Bats, 2014-2017 (Projects #20 and #50) to illustrate the calculation of vanishing bearings of birds departing a stopover site. This project holds Motus data for several Western University projects that took place in southern Ontario, Canada. These projects were led by principal investigators (Chris Guglielmo and Yolanda Morbey) and a number of their graduate students. A variety of species of birds and bats were tracked. For more information contact: Chris Guglielmo, Professor, Department of Biology, Western University, Canada, cguglie2@uwo.ca / Tel: 519.661.2111 (ext. 81204) Yolanda Morbey, Associate Professor, Department of Biology, Western University, Canada, ymorbey@uwo.ca / Tel: 519.661.2111 (ext. 80116) 1.4 Acknowledgements Some of the text included in this book was adapted from John Brzustowskis GitHub repository for the motus R package at: https://github.com/jbrzusto/motus. Motus was conceived as the SensorGnome network by Philip Taylor and John Brzustowski at Acadia University. Initial expansion of the network was supported by a Canada Foundation for Innovation Grant to Western University (Dr. Christopher Guglielmo), The University of Guelph (Dr. Ryan Norris), and Acadia University (Dr. Philip Taylor). The development of the Motus web interface, R package, and accompanying handbook were made possible through a Canarie grant to Bird Studies Canada (https://www.canarie.ca/). Motus continues to grow as a program of Bird Studies Canada, through the collaboration of numerous independent researchers, organizations, and individuals. A non-exhaustive list of Motus partners and collaborators can be found at https://motus.org/data/partners.jsp. If your organization is not listed, please contact motus@birdscanada.org. Many people have worked together to bring Motus technology, the web interface, and the R-package together. The core Motus Team includes Joey Bernard, John Brzustowski, Tara Crewe, Zoe Crysler, Jeremy Hussell, Catherine Jardine, Steffi LaZerte, Denis Lepage, Stuart Mackenzie, Paul Morrill, and Philip Taylor. "],["loadingPackages.html", "2 Loading R Packages 2.1 Installing Motus packages 2.2 Installing other packages 2.3 Internal data processing", " 2 Loading R Packages This chapter was contributed by Tara L. Crewe, Zoe Crysler, and Philip Taylor. Revisions by Steffi LaZerte and Denis Lepage 2.1 Installing Motus packages Two R packages have been developed for Motus users: motus: provides functions for downloading and updated detections and deployment data, as well as for creating summary plots, and transforming (add sun rise/sun set times) and analyzing Motus data. motusData: provides sample datasets used in some of the chapters of this book. Motus users can install the latest stable versions of the R packages using the following code. As with all R packages, you only need to install the packages once; after installation, you need to load each package (using library()) each time you open a new R session. Please note that some functionalities of the remotes package may require updated versions of R and RStudio. To avoid errors, please ensure you are using the most recent releases of R and RStudio, and update your R packages using update.packages() in the R console. To update your existing packages: update.packages() Begin by installing the required packages, if not already installed. If you have used the older version of motus which included use of the motusClient package, it is recommended to first uninstall both packages. remove.packages(c(&quot;motus&quot;, &quot;motusClient&quot;)) Then proceed with the installation of the motus package install.packages(&quot;remotes&quot;) library(remotes) # install motus install_github(&quot;MotusWTS/motus&quot;) # install motusData package which contains sample datasets, e.g., vanishBearing # used in Chapter 7 install_github(&quot;MotusWTS/motusData&quot;) library(motus) library(motusData) If you need to update the existing motus package, you need to specify force = TRUE: # force a re-installation of motus package in case of required updates install_github(&quot;MotusWTS/motus&quot;, force = TRUE) library(motus) If you want to know what version of the motus package you currently have installed: packageVersion(&quot;motus&quot;) 2.1.1 Troubleshooting the installation Occasionally users run into problems while trying to install or update motus. Often this is related to problems with different versions of package dependencies. Here we suggest several solutions. Update all packages during the installation remotes::install_github(&quot;MotusWTS/motus&quot;, upgrade = &quot;always&quot;) If the installation of Motus generates errors saying that some of the existing packages cannot be removed, you can try to quit any R session, manually delete the problematic package folder from your R libraries and manually install the package again before trying to install motus. You can also try to set up a custom R library folder with .libPaths() and ensure that you have full write permissions on that folder, or try to start R in administrator (Windows) or SUDO mode (Linux/Ubuntu) and try installing again. To set a custom library folder for installing new packages: .libPaths(&quot;C:/r-libraries/&quot;) In some cases, it is easier to upgrade R itself by reinstalling the newest version of R: https://cran.r-project.org/. Note: While this results in a nice clean installation with fewer problems, it necessitates the re-installation of R packages which can be time-consuming. If reinstalling R is not an option, you get an error related to packages built under a current version of R, AND updating your packages doesnt help, you can consider overriding the error with the following code. Note: This might help you install motus but may result in other problems. If possible, its best to resolve the errors rather than ignoring them. Sys.setenv(&quot;R_REMOTES_NO_ERRORS_FROM_WARNINGS&quot;=TRUE) remotes::install_github(&quot;MotusWTS/motus&quot;, upgrade = &quot;always&quot;) 2.2 Installing other packages Throughout the book, we use tidyverse, which is a collection of R packages for data science, including tidyr, dplyr, ggplot2, and lubridate for managing and manipulating dates. More information on tidyverse can be found at https://www.tidyverse.org/, or by browsing (or better still, thoroughly reading) R for Data Science by Garrett Grolemund and Hadley Wickham (http://r4ds.had.co.nz/). For mapping we also use the rworldmap, and ggmap packages. These can be installed from CRAN, as follows: install.packages(&quot;maps&quot;) library(maps) install.packages(&quot;tidyverse&quot;) library(tidyverse) install.packages(&quot;rworldmap&quot;) library(rworldmap) install.packages(&quot;ggmap&quot;) library(ggmap) We also install but do not load the plyr package; we use it directly for the handy round_any function (with the code plyr::round_any()), but loading it can cause problems with the dplyr functions: install.packages(&quot;plyr&quot;) 2.3 Internal data processing As an animal moves within the detection range of a Motus station, radio transmissions, or bursts, are detected by antenna(s) and recorded by a receiver. These raw detection data are either uploaded to the Motus database instantaneously via internet connection, or downloaded from the receiver and uploaded to Motus manually. Behind the scenes, various functions read and process the raw detections data to produce the tag detections file that users access using the R package (see Chapter 3). While most users will not need to call on the internal data processing functions, a complete list of functions within the Motus server R package can be found on GitHub (https://github.com/jbrzusto/motusServer). The code behind each function can be viewed on GitHub, or by typing the following in the R console after loading the R package, replacing function.name with the name of the R function of interest: function.name In the next chapter we will examine and load some data. "],["accessingData.html", "3 Accessing and understanding detections data 3.1 Data structure 3.2 Database types 3.3 Load relevant R packages 3.4 Set system environment 3.5 Downloading tag detections 3.6 Export your flat dataframe to CSV or RDS file 3.7 Update and/or open an existing database 3.8 Check if new data are available 3.9 Force an update/re-import of tag and receiver deployment metadata 3.10 Import full tag and receiver metadata 3.11 Ensure that you have the correct database version 3.12 R object naming convention 3.13 Summary: download, access, and export data", " 3 Accessing and understanding detections data This chapter was contributed by Tara L. Crewe, Zoe Crysler, and Philip Taylor. Revisions by Steffi LaZerte and Denis Lepage Before downloading your detection data, please ensure that you have no pending metadata issues through the online Data Issues page This chapter will begin with an introduction to the structure of the detections database, followed by instructions on how to download and access the data. At the end, a summary section that includes a script to download, select variables, clean data, and export is provided (see 3.13) 3.1 Data structure Each tag detection database is stored as an SQLite (dplyr::src_sqlite) file with the extension .motus. The sqlite format was chosen because: it is flexible, allowing for many data formats. it is accessible from many software platforms (not just R). it is appendable, meaning the database can be created and updated on disk without having to read in and resave the entire contents. This will save time and computer memory when searching to see if any new detections are available for your project or receiver. The .motus file contains a series of interrelated tables where data are stored in a condensed format to save memory. The following tables are included in your .motus file; activity: data related to radio activity for each hour period (hourBin) at each antenna, including a count of the number of short runs used in helping identify false detections. admInfo: internal table used to keep track of your the motus package used to create your motus file, and the data version. antDeps: metadata related to antenna deployments, e.g., deployment height, angle, antenna type. batchRuns: metadata for runIDs and associated batchIDs batches: detection data for a given receiver and boot number. filters: metadata related to user created filters associated with the specified receiver. gps: metadata related to Geographic Positioning System (GPS) position of receiver. hits: detection data at the level of individual hits. meta: metadata related to the project and datatype (tags vs. receivers) that are included in the .motus file nodeData: data related to nodes by batchID and time (ts) nodeDeps; metadata related to nodes projAmbig: metadata related to what projects have ambiguous tag detections projs: metadata related to projects, e.g., project name, principal investigator. pulseCounts: number of radio pulses measured on each antenna over 1 hour periods (hourBin). recvDeps: metadata related to receiver deployments, e.g., deployment date, location, receiver characteristics. recvs: metadata related to receiver serial number and associated Motus deviceID runs: detection data associated with a run (continuous detections of a unique tag on a given antenna or node). runsFilters: a list of runIDs associated with user created filters and assigned probabilities. species: metadata related to species, e.g., unique identifier, scientific name, common name. tagAmbig: metadata related to ambiguous tags, e.g., ambigID and associated motusTagID tagDeps: metadata related to tag deployments, e.g., deployment date, location, and species. tagProp: metadata related to custom deployment properties entered by the principal investigator (e.g. body weight). tags: metadata related to tags, e.g., unique identifier, tag characteristics (e.g., burst interval). In addition to these tables, there are also virtual tables or views, which have been created through queries that merge data from the various tables into a single convenient view that contains all of the fields you are likely to need. The following views are currently included in each .motus file: allambigs: lists in long-data format each motusTagID (up to 6) associated with each negative ambigID. alltags: provides the full detection data for all tags, and all ambiguous (duplicate) tags, associated with your project. Ambiguous detections are repeated for each motusTagID represented by each ambigID. alltagsGPS: same as alltags but includes GPS latitude, longitude and altitude (much slower to load on large databases). Because the file is a dplyr::src_sqlite file, all of the dplyr functions can be used to filter and summarize the .motus database, without needing to first save the data as a flat file (a typical two-dimensional dataframe). The SQL format is very advantageous when you have a large file  the queries using SQL will be substantially faster than those done on a flat dataframe. 3.2 Database types There are two types of tag detection databases available for download: receiver database: includes all detections of any registered tags from a single receiver. A receiver database has a name like SG-1234BBBK5678.motus, where the name is the serial number of the receiver. project database: includes all detections of your registered tags from across the Motus network. A tag project database has a name like project-123.motus, where the number is the Motus project ID. These two databases correspond to the basic model of data sharing: you get all detections of anyones tags by your receivers (i.e., one receiver tag database for each receiver you deploy). you get all detections of your tags by anyones receivers (i.e., one project tag database for each of your Motus projects). 3.3 Load relevant R packages Before we begin working with data, we need to load the required packages for this chapter. If you have not yet installed these packages (from github and CRAN) then please return to Chapter 2 and do so. library(motus) library(lubridate) library(dplyr) 3.4 Set system environment Set the system environment time zone to Greenwich Mean Time (UTC), to ensure that you are always working in UTC. This is a very important step, and should be part of every working session. If you fail to do this, then two problems can arise. Times are stored in the Motus database in UTC, and if you do not keep your environment in UTC, then they can be inadvertently changed during import. Second, if tags have been detected across multiple time zones, then they can also inadvertently be changed. Sys.setenv(TZ = &quot;UTC&quot;) 3.5 Downloading tag detections To import tag detections for your project or receiver, you need a numerical project id or character scalar receiver serial number. The success of the Motus network is dependent on the timely upload of detection data from receivers, and on the maintenance of accurate and up to date tag and receiver metadata by collaborators. After downloading your data from the Motus server, users are encouraged to check for updated detection data (see sections 3.7 and 3.8) and metadata (see section 3.9) each time they run an analysis, because collaborators can add detection data and metadata at any time, and these could influence the completeness of your own detections data. Be warned that large datasets can take some time (sometimes a few hours) to download from the Motus server when downloading for the first time. After the initial download, loading a .motus file into R and updating for any new data will be near instantaneous. 3.5.1 Download data for a project for the first time All data downloads are completed using the tagme() function in the motus R package. This function will save an SQLite database to your computer with the extension .motus; further details on data structure are in section 3.1. The following parameters are available for the tagme() function: projRecv: integer project number OR a character vector receiver serial number. new: if set to TRUE, it will create a new empty .motus file in your local directory. Do not use this parameter or set it to FALSE if you already have a .motus file. update: if set to TRUE, will download all available data to your existing .motus file. Must be set to TRUE on your first data download and any subsequent downloads if you wish to check for new data. Set to FALSE if you do not wish to check for new data (e.g., if working offline). dir: Your .motus data is automatically saved to your working directory, unless you specify a different location using this parameter. forceMeta: if set to TRUE, it will force an update of metadata to an existing .motus file. Throughout this book we use sample data (see section 1.3) which has been assigned to project 176. Lets get started by downloading data by project - this will include all detections of your tags on any receiver. Note that when downloading data from the Motus server for the first time, you must specify new = TRUE and update = TRUE. You will also be prompted to login (see 3.5.2 below). Unless the directory that you want your data saved in is stated explicitly within the function call, data will be downloaded to the current working directory. Lets start by determining what our working directory is so we know where our file will be saved. getwd() Specify the project number you wish to download detections for, in this case the sample data project. proj.num &lt;- 176 As this is the first time you are downloading data for project 176, set new = TRUE and update = TRUE. This will create a .motus file in your current working directory, which was shown above using getwd() This will also create an SQL object in your R environment called sql.motus sql.motus &lt;- tagme(projRecv = proj.num, new = TRUE, update = TRUE) Alternatively you can specify a different location to save the data by entering your preferred filepath. In this example we save to our data folder using the dir parameter. Note that ./ simply means relative to the current folder (shown by getwd()). sql.motus &lt;- tagme(projRecv = proj.num, new = TRUE, update = TRUE, dir = &quot;./data/&quot;) Note: Youll need to use the username motus.sample and the password motus.sample to access this data (see below for more details)! Using tagme() as shown above will download a file to your working or specified directory called project-176.motus for the sample data (the number in the file name corresponds to the project number). The progress of the download process should print on the console; if you are not seeing it, try scrolling down your screen while tagme() is running. In the event that your connection to the Motus server fails prior to a complete download (e.g., due to a poor internet connection), use tagme(proj.num, update = TRUE) to continue the download from where it left off, ensuring to specify a directory if it is saved outside the working directory. 3.5.2 User Authentication 3.5.2.1 Login The first time you call a function using the Motus R package, you will be asked to enter your motus.org username and password in the R console to authenticate your access to project data. This will only happen once per R session. If you do not have a Motus username and password, you can sign up at https://motus.org/data/user/new. Permission to access project data will then be granted by Motus staff or the project principal investigator. Throughout this book we use sample data (see section 1.3) which has been assigned to project 176. When accessing this data you will need to login using username and password motus.sample in the R console when prompted by the tagme() function (see section 3.5.1). It will look like this: To download data for one of your own projects, you simply need to change the project number to that of your own project in the tagme() call, and enter your own Motus login/password in the R console when prompted. If you are already logged in as the sample data user, you will need to first logout to download your own data (see 3.5.2.2). 3.5.2.2 Logging out Once you are logged in under one user account, you will not be able to access data from another account. If you need to logout of the current account to access other data, you can run the code below. motusLogout() 3.5.3 Download data for a receiver for the first time We could also download data by receiver through the same process as described above. This will provide you with all detections of any tags on the specified receiver. As there are no receivers registered to sample project 176, this call will not work. If you have a receiver registered to your own project, replace the receiver serial number in the tagme call below with the serial number for your own receiver, ensuring that you are logged in using your own credentials (see section 3.5.2.2). proj.num &lt;- &quot;SG-123BBBK1234&quot; sql.motus &lt;- tagme(projRecv = proj.num, new = TRUE, update = TRUE) This will download a file to your working directory named SG-123BBBK1234.motus. Some users may wish to work directly with the .motus SQLite file. However, since many users are more familiar with a flat dataframe format, instructions to view the the data as a flat dataframe within R, and on how to export the flat file to .csv or .rds format, are included below. Throughout the majority of this book, we use a flat dataframe format. 3.5.4 Downloading multiple receivers at the same time If you have a large number of receivers in your project, and wish to get receiver specific data for each one, rather than downloading them one by one as above, we can download them with a simple loop. Note that since the sample project doesnt have any receivers associated with it, this script will not result in a download but you can try it with your own project if you have receivers. # specify the project whose receivers you wish to download: proj.num &lt;- 176 # get a copy of the metadata only sql.motus &lt;- tagme(proj.num, new = TRUE, update = FALSE, dir = &quot;./data/&quot;) metadata(sql.motus, proj.num) tbl.recvDeps &lt;- tbl(sql.motus, &quot;recvDeps&quot;) df.serno &lt;- tbl.recvDeps %&gt;% filter(projectID == proj.num) %&gt;% select(serno) %&gt;% distinct() %&gt;% collect() %&gt;% as.data.frame() # loop through each receiver (may take a while!) for (row in 1:nrow(df.serno)) { tagme(df.serno[row, &quot;serno&quot;], dir = &quot;./data/&quot;, new = TRUE, update = TRUE) } # Note you can remove the dir argument if you want to save it to your working # directory, just make sure that you use the same directory in both calls You can also create a list of receivers youd like to download if you dont want to download project-wide receivers: # create list of receivers you&#39;d like to download df.serno &lt;- c(&quot;SG-AB12RPI3CD34&quot;, &quot;SG-1234BBBK4321&quot;)) # loop through each receiver (may take a while!), and save to the working directory for (k in 1:length(df.serno)) { tagme(df.serno[k], new = TRUE, update = TRUE) } # loop through each receiver (may take a while!), and save to a specified directory for (k in 1:length(df.serno)) { tagme(df.serno[k], dir = &quot;/Users/zoecrysler/Downloads/&quot;, new = TRUE, update = TRUE) } 3.5.5 Updating all .motus files within a directory Once you have .motus files, you can also update them all by simply calling the tagme() function but leaving all arguments blank, apart from the directory: # If you have them saved your working directory: tagme() # If you have them saved in a different directory: tagme(dir = &quot;./data/&quot;) 3.5.6 Accessing downloaded detection data Now that weve downloaded our data as an SQLite database and loaded it into an R object called sql.motus, we want to access the tables stored within. Detailed descriptions of all the tables stored in the .motus file can be found in section 3.1. You can also view the list of tables, and variables contained within those tables, using the DBI and RSQLite packages (these are automatically installed when you install motus). library(DBI) library(RSQLite) # specify the filepath where your .motus file is saved, and the file name. file.name &lt;- dbConnect(SQLite(), &quot;./data/project-176.motus&quot;) # get a list of tables in the .motus file specified above. dbListTables(file.name) ## [1] &quot;activity&quot; &quot;admInfo&quot; &quot;allambigs&quot; &quot;alltags&quot; &quot;alltagsGPS&quot; ## [6] &quot;antDeps&quot; &quot;batchRuns&quot; &quot;batches&quot; &quot;clarified&quot; &quot;filters&quot; ## [11] &quot;gps&quot; &quot;hits&quot; &quot;meta&quot; &quot;nodeData&quot; &quot;nodeDeps&quot; ## [16] &quot;projAmbig&quot; &quot;projBatch&quot; &quot;projs&quot; &quot;recvDeps&quot; &quot;recvs&quot; ## [21] &quot;runs&quot; &quot;runsFilters&quot; &quot;species&quot; &quot;tagAmbig&quot; &quot;tagDeps&quot; ## [26] &quot;tagProps&quot; &quot;tags&quot; # get a list of variables in the &quot;species&quot; table in the .motus file. dbListFields(file.name, &quot;species&quot;) ## [1] &quot;id&quot; &quot;english&quot; &quot;french&quot; &quot;scientific&quot; &quot;group&quot; ## [6] &quot;sort&quot; The virtual table alltags contains the detection data, along with all metadata variables that most users will ever need from the various underlying .motus tables (but now excludes GPS data). We access the tables using the tbl() function from the dplyr package which we installed in Chapter 2: # this retrieves the &quot;alltags&quot; table from the &quot;sql.motus&quot; SQLite file we read in earlier tbl.alltags &lt;- tbl(sql.motus, &quot;alltags&quot;) # virtual table We now have a new tbl.alltags object in R. The underlying structure of these tables is a list of length 2: str(tbl.alltags) ## List of 2 ## $ src:List of 2 ## ..$ con :Formal class &#39;SQLiteConnection&#39; [package &quot;RSQLite&quot;] with 7 slots ## .. .. ..@ ptr :&lt;externalptr&gt; ## .. .. ..@ dbname : chr &quot;C:\\\\Users\\\\BC officer\\\\Documents\\\\BC Motus\\\\General Motus\\\\Motus R\\\\MotusRBook\\\\data\\\\project-176.motus&quot; ## .. .. ..@ loadable.extensions: logi TRUE ## .. .. ..@ flags : int 70 ## .. .. ..@ vfs : chr &quot;&quot; ## .. .. ..@ ref :&lt;environment: 0x000000001c3b2310&gt; ## .. .. ..@ bigint : chr &quot;integer64&quot; ## ..$ disco: NULL ## ..- attr(*, &quot;class&quot;)= chr [1:4] &quot;src_SQLiteConnection&quot; &quot;src_dbi&quot; &quot;src_sql&quot; &quot;src&quot; ## $ ops:List of 2 ## ..$ x : &#39;ident&#39; chr &quot;alltags&quot; ## ..$ vars: chr [1:60] &quot;hitID&quot; &quot;runID&quot; &quot;batchID&quot; &quot;ts&quot; ... ## ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;op_base_remote&quot; &quot;op_base&quot; &quot;op&quot; ## - attr(*, &quot;class&quot;)= chr [1:5] &quot;tbl_SQLiteConnection&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; &quot;tbl_lazy&quot; ... The first part of the list, src, is a list that provides details of the SQLiteConnection, including the directory where the database is stored. The second part is a list that includes the underlying table. Thus, the R object alltags is a virtual table that stores the database structure and information required to connect to the underlying data in the .motus file. As stated above, the advantage of storing the data in this way is that it saves memory when accessing very large databases, and functions within the dplyr package can be used to manipulate and summarize the tables before collecting the results into a typical flat format dataframe. If you want to use familiar functions to get access to components of the underlying data frame, then use the collect() function. For example, to look at the names of the variables in the alltags table: tbl.alltags %&gt;% collect() %&gt;% names() # list the variable names in the table ## [1] &quot;hitID&quot; &quot;runID&quot; &quot;batchID&quot; &quot;ts&quot; ## [5] &quot;tsCorrected&quot; &quot;sig&quot; &quot;sigsd&quot; &quot;noise&quot; ## [9] &quot;freq&quot; &quot;freqsd&quot; &quot;slop&quot; &quot;burstSlop&quot; ## [13] &quot;done&quot; &quot;motusTagID&quot; &quot;ambigID&quot; &quot;port&quot; ## [17] &quot;runLen&quot; &quot;bootnum&quot; &quot;tagProjID&quot; &quot;mfgID&quot; ## [21] &quot;tagType&quot; &quot;codeSet&quot; &quot;mfg&quot; &quot;tagModel&quot; ## [25] &quot;tagLifespan&quot; &quot;nomFreq&quot; &quot;tagBI&quot; &quot;pulseLen&quot; ## [29] &quot;tagDeployID&quot; &quot;speciesID&quot; &quot;markerNumber&quot; &quot;markerType&quot; ## [33] &quot;tagDeployStart&quot; &quot;tagDeployEnd&quot; &quot;tagDepLat&quot; &quot;tagDepLon&quot; ## [37] &quot;tagDepAlt&quot; &quot;tagDepComments&quot; &quot;tagDeployTest&quot; &quot;fullID&quot; ## [41] &quot;deviceID&quot; &quot;recvDeployID&quot; &quot;recvDeployLat&quot; &quot;recvDeployLon&quot; ## [45] &quot;recvDeployAlt&quot; &quot;recv&quot; &quot;recvDeployName&quot; &quot;recvSiteName&quot; ## [49] &quot;isRecvMobile&quot; &quot;recvProjID&quot; &quot;recvUtcOffset&quot; &quot;antType&quot; ## [53] &quot;antBearing&quot; &quot;antHeight&quot; &quot;speciesEN&quot; &quot;speciesFR&quot; ## [57] &quot;speciesSci&quot; &quot;speciesGroup&quot; &quot;tagProjName&quot; &quot;recvProjName&quot; 3.5.7 Adding GPS Data If GPS data is required, users will either have to use the alltagsGPS view, or will have to add GPS values to a data subset. To use the alltagsGPS view (note that this can be slow, which is why GPS data is excluded by default): tbl.alltagsGPS &lt;- tbl(sql.motus, &quot;alltagsGPS&quot;) Alternatively, to speed things up you can first filter your data, then use the getGPS() function to retrieve GPS values. # Filter the data tbl.Dunlin &lt;- tbl(sql.motus, &quot;alltags&quot;) %&gt;% filter(speciesEN == &quot;Dunlin&quot;) %&gt;% collect() # Get the daily median location of GPS points for these data Dunlin.GPS &lt;- getGPS(src = sql.motus, data = tbl.Dunlin) We match GPS locations to hitIDs according to one of several different time values, specified by the by argument. This can be one of three options: the median location within by = X minutes of a hitID here, X can be any number greater than zero and represents the size of the time block in minutes over which to calculate a median location be aware that you should ideally not chose a period smaller than the frequency at which GPS fixes are recorded, or some hits will not be associated with GPS by = \"daily\" median location (default, implied in the above example) similar to by = X except the duration is 24hr (same as by = 1440) this method is most suitable for receiver deployments at fixed location. or the by = \"closest\" location in time individual GPS lat/lons are returned, matching the closest hitID timestamp this method is most accurate for mobile deployments, but is potentially slower than by = X. you can also specify a cutoff which will only match GPS records which are within cutoff = X minutes of the hit. This way you can avoid having situations where the closest GPS record is actually days away. Dunlin.GPS &lt;- getGPS(src = sql.motus, data = tbl.Dunlin, by = 60) Dunlin.GPS &lt;- getGPS(src = sql.motus, data = tbl.Dunlin, by = &quot;closest&quot;, cutoff = 120) To keep all hitIDs, regardless of whether they GPS data or not, use the argument keepAll = TRUE. Dunlin.GPS &lt;- getGPS(src = sql.motus, data = tbl.Dunlin, keepAll = TRUE) Finally, use the left_join() function to add GPS to your data subset. Note that this sample data doesnt actually have GPS values so these examples are for illustration only. tbl.Dunlin.GPS &lt;- left_join(tbl.Dunlin, Dunlin.GPS, by = &quot;hitID&quot;) As there is no GPS data in this example data set, well continue with our original tbl.alltags file. 3.5.8 Converting to flat file To convert the alltags view or other table in the .motus file into a typical flat format, i.e., with every record for each field filled in, use the collect() and as.data.frame() functions. The output can then be further manipulated, or used to generate a RDS file of your data for archiving or export. df.alltags &lt;- tbl.alltags %&gt;% collect() %&gt;% as.data.frame() Now we have a flat dataframe of the alltags table called df.alltags. We can look at some metrics of the file: names(df.alltags) # field names str(df.alltags) # structure of your data fields head(df.alltags) # prints the first 6 rows of your df to the console summary(df.alltags) # summary of each column in your df Note that the format of the time stamp (ts) field is numeric and represents seconds since January 1 1970. We recommend that when you transform your tables into flat dataframes, that you format the time stamp using the lubridate package at that time, e.g.: df.alltags &lt;- tbl.alltags %&gt;% collect() %&gt;% as.data.frame() %&gt;% # for all fields in the df (data frame) mutate(ts = as_datetime(ts, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;)) # the tz = &quot;UTC&quot; is not necessary here, provided you have set your system time to UTC # ... but it serves as a useful reminder! Note that time stamps can only be manipulated in this way after collecting the data into a flat dataframe. If you want to load only part of your entire virtual table (e.g. certain fields, certain tags, or all tags from a specified project or species), you can use dplyr functions to filter the data before collecting into a dataframe. Some examples are below: To select certain variables: # to grab a subset of variables, in this case a unique list of Motus tag IDs at # each receiver and antenna. df.alltagsSub &lt;- tbl.alltags %&gt;% select(recv, port, motusTagID) %&gt;% distinct() %&gt;% collect() %&gt;% as.data.frame() To select certain tag IDs: # filter to include only motusTagIDs 16011, 23316 df.alltagsSub &lt;- tbl.alltags %&gt;% filter(motusTagID %in% c(16011, 23316)) %&gt;% collect() %&gt;% as.data.frame() %&gt;% mutate(ts = as_datetime(ts, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;)) To select a specific species: # filter to only Red Knot (using speciesID) df.4670 &lt;- tbl.alltags %&gt;% filter(speciesID == 4670) %&gt;% collect() %&gt;% as.data.frame() %&gt;% mutate(ts = as_datetime(ts, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;)) # filter to only Red Knot (using English name) df.redKnot &lt;- tbl.alltags %&gt;% filter(speciesEN == &quot;Red Knot&quot;) %&gt;% collect() %&gt;% as.data.frame() %&gt;% mutate(ts = as_datetime(ts, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;)) Using dplyr, your virtual table can also be summarized before converting to a flat file. For example, to find the number of different detections for each tag at each receiver: df.detectSum &lt;- tbl.alltags %&gt;% count(motusTagID, recv) %&gt;% collect() %&gt;% as.data.frame() In later chapter(s) we will show you additional ways of summarizing and working with your data. 3.6 Export your flat dataframe to CSV or RDS file A good workflow is to create a script that deals with all your data issues (as described in later chapters), and then saves the resulting dataframe for re-use. If you do this, you can quickly start an analysis or visualization session from a known (and consistent) starting point. We use an .rds file, which preserves all of the associated R data structures (such as time stamps). saveRDS(df.alltags, &quot;./data/df_alltags.rds&quot;) Some users may also want to export the flat dataframe into a .csv file for analysis in other programs. This can easily be done with the following code. Note that it does not preserve time stamps: write.csv(df.alltags, &quot;./data/df_alltags.csv&quot;) 3.7 Update and/or open an existing database As you or other users upload data to our server, you may have additional tag detections that werent present in your initial data download. Since the .motus file is a SQLite database, you can update your existing file with any newly available data, rather than doing a complete new download of the entire database. To open and update a detections database that already exists (has been downloaded previously), we use the tagme() function but set new = FALSE: sql.motus &lt;- tagme(projRecv = proj.num, new = FALSE, update = TRUE, dir = &quot;./data/&quot;) If you are working offline, and simply want to open an already downloaded database without connecting to the server to update, use new = FALSE and update = FALSE: # use dir = to specify a directory sql.motus &lt;- tagme(projRecv = proj.num, new = FALSE, update = FALSE) 3.8 Check if new data are available To check if new data are available for your project or receiver without downloading the data, you can use the tellme() function, which returns a list with: numHits: number of new tag detections. numBytes: approximate uncompressed size of data transfer required, in megabytes. numRuns: number of runs of new tag detections, where a run is a series of continuous detections for a tag on a given antenna. numBatches: number of batches of new data. numGPS: number of GPS records of new data. The following assumes that a local copy of the database already exists: tellme(projRecv = proj.num) # If db is in the working directory tellme(projRecv = proj.num, dir = &quot;./data/&quot;) # To specify a different directory To check how much data is available for a project but you do not have a database for it, use the new parameter: tellme(projRecv = proj.num, new = TRUE) 3.9 Force an update/re-import of tag and receiver deployment metadata Tag and receiver metadata are automatically merged with tag detections when data are downloaded. However, if metadata have been updated since your initial download, you can force re-import of the metadata when updating a database by running: sql.motus &lt;- tagme(projRecv = proj.num, forceMeta = TRUE) 3.10 Import full tag and receiver metadata When you use tagme() to download or update your .motus file, you are provided with the metadata for: any tags registered to your project which have detections; tags from other projects which are associated with ambiguous detections (see Chapter 5) in your data; receivers that your tags and any ambiguous tags were detected on. In many instances, you will want access to the full metadata for all tags and receivers across the network, e.g., to determine how many of your deployed tags were not detected, or to plot the location of stations with and without detections. The metadata() function can be used to add the complete Motus metadata to your .motus file. The metadata function only needs to be run once, but we suggest that you re-import the metadata occasionally to ensure that you have the most recent and up-to-date information. Running the metadata function as follows will add the appropriate metadata from across the network (all tags and all receivers) to the recvDeps and tagDeps tables in your .motus file: # access all tag and receiver metadata for all projects in the network. metadata(sql.motus) Alternatively, you can load metadata for a specific project(s) using: # access tag and receiver metadata associated with project 176 metadata(sql.motus, projectIDs = 176) # access tag and receiver metadata associated with projects 176 and 1 metadata(sql.motus, projectIDs = c(176, 1)) 3.11 Ensure that you have the correct database version When you call the tagme function to load the sqlite database, the version of the R package used to download the data is stored in an admInfo table. Over time, changes will be made to the functionality of the R package that may require adding new tables, views or fields to the database. If your version of the database does not match the version of the R package, some of the examples contained in this book may not work. The following call will check that your database has been updated to the version matching the current version of the motus R package. If your database does not match the most current version of the R package, use tagme() with update = TRUE to update your database to the correct format. Refer to Appendix B if the checkVersion() call returns a warning. checkVersion(sql.motus) 3.12 R object naming convention Throughout this chapter and the rest of the book, we name R objects according to their structure and the source of the data contained in the object. So, SQLite objects will be prefixed with sql., virtual table objects will be prefixed with tbl., and dataframe objects will be prefixed with df.; the rest of the name will include the name of the .motus table that the data originates from. Throughout the rest of the book we will be relying on and referencing the naming formats below; please ensure that you are familiar with these before continuing to the next chapter. The following code assumes you have already downloaded the sample data and do not need to update it; if you have not downloaded the data, see section 3.5.1 for instructions on initial download: # SQLite R object, which links to the .motus file: sql.motus &lt;- tagme(176, update = TRUE, dir = &quot;./data&quot;) # virtual table object of the alltags table in the sample.motus file: tbl.alltags &lt;- tbl(sql.motus, &quot;alltags&quot;) df.alltags &lt;- tbl.alltags %&gt;% collect() %&gt;% as.data.frame() %&gt;% # dataframe (&quot;flat&quot;) object of alltags table mutate(ts = as_datetime(ts, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;)) 3.13 Summary: download, access, and export data Throughout the book we will predominantly be working with the alltags table in flat format. Although described in detail above, here we include a quick summary of how you download, access, and convert the sample data for use in the rest of the book. In later sections of the book, we include additional recommended modifications and filtering of unnecessary variables, more information is available in section 5.1 in Chapter 5. # set proj.num to 176 for sample data proj.num &lt;- 176 # - download and load detection data from the sample project and save in data folder # - login and password for sample data is &quot;motus.sample&quot; # - if you are accessing already-downloaded data, use new = FALSE; if you don&#39;t # want to update your data, also set update = FALSE sql.motus &lt;- tagme(proj.num, new = TRUE, update = TRUE, dir = &quot;./data/&quot;) # access the &quot;alltags&quot; table within the SQLite file tbl.alltags &lt;- tbl(sql.motus, &quot;alltags&quot;) # convert &quot;tbl.alltags&quot; to a flat dataframe and change numeric time to a datetime object df.alltags &lt;- tbl.alltags %&gt;% collect() %&gt;% as.data.frame() %&gt;% mutate(ts = as_datetime(ts, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;)) For your own data we suggest creating a script with the following workflow: download and/or update your data select variables of interest for the table you are working with (typically alltags) include any initial cleaning save the resulting data as an .rds file as described in section 3.6. We suggest using RDS instead of CSV, because the RDS format preserves the underlying structure of the data (e.g. POSIX times stay as POSIX times). If you want to export your data to another program, then a CSV format might be preferred. We caution that producing a flat file using the full suite of fields can use a lot of memory, and can slow R down considerably when dealing with large datasets. For some combinations of data sets and computers, it may be impossible to directly use data frames in R. If that is the case, then this is the point in your workflow where you should carefully consider the information you need from within your data set (for example, how it is aggregated) and simplify it. You can always return to this script and creating a new RDS file with different variables, or aggregated at a different scale. To read in a saved RDS file you can run: # reads in your file &quot;df.alltags.rds&quot; saved in the data folder df.alltags.saved &lt;- readRDS(&quot;./data/df_alltags.rds&quot;) In the next chapter we will check for missing metadata. "],["deployments.html", "4 Tag and Receiver Deployments 4.1 Load relevant R packages and set working environment 4.2 Load .motus file 4.3 Tag Deployments 4.4 Check Receiver Metadata", " 4 Tag and Receiver Deployments This chapter was contributed by Tara L. Crewe, Zoe Crysler, and Philip Taylor. Before working with your detection data, a first step is to summarize and visualize the metadata for tag and receiver deployments registered to your project. Summarizing and plotting your deployments can be an effective way to find any errors in tag or receiver deployment metadata, which can in turn influence the completeness of the detections data for your project and the projects of others with detections of their own tags on your receivers. This chapter is a complement to the online Data Issues page, which provides each project with a list of metadata issues (missing or outlying values) to be accepted or ignored. As such, please address any and all errors associated with your project on the Data Issues page before importing your data through R. This chapter does not provide a full check of your deployment metadata, but will help uncover errors that have been missed by the automatic queries on the Data Issues page. We use the James Bay Shorebird Project sample dataset throughout this chapter (see Section 1.3). As you run through the code to look at your own deployments, please fix any errors or omissions in your metadata by signing in to https://motus.org/, and under the Manage Data tab, select either Manage Tags to fix tag deployment metadata or Manage Receivers to fix receiver deployment metadata. It is important to fix metadata errors online, so that errors are fixed at the source and archived on the Motus Server, ensuring all users have access to the correct tag and receiver metadata. Metadata corrected online will automatically be corrected in your detection files. If you have already downloaded your detection data, you can update the existing file to include new metadata and detections (see sections 3.9, 3.7). 4.1 Load relevant R packages and set working environment Before we begin working with data, we need to load the required packages for this chapter. If you have not yet installed these packages (from GitHub or CRAN) then please return to Chapter 2 and do so. library(tidyverse) library(motus) library(lubridate) # Set the system environment time zone to UTC (to ensure that you are always working in UTC) Sys.setenv(TZ = &quot;UTC&quot;) 4.2 Load .motus file This chapter assumes that the .motus file has already been downloaded, if you have not done so please return to Chapter 3 for instructions on how to do so. To update and load the existing file into R, use tagme(), you may have to login as described in the previous chapter with username and password motus.sample proj.num &lt;- 176 sql.motus &lt;- tagme(proj.num, update = TRUE, dir = &quot;./data&quot;) 4.3 Tag Deployments In your .motus file, when using the tagme function, you are only provided with the metadata for any tags from your project with detections along with metadata for associated ambiguous tags from other projects, and receiver metadata for stations where your tags were detected. Here we will: download full tag metadata for our project only determine how many tags are registered to your project determine how many of those registered tags were deployed determine location of tag deployments determine completeness and accuracy of tag deployment metadata We will run through each of these in sequence. 4.3.1 Download full project tag metadata Incomplete metadata or missing tag registrations can result in missing detection data. We therefore want to assess the completeness of all tags registered to our projects - not just tags for which we have detections. In order to to this we will use the metadata() function for project 176, described in more detail in section 3.10. metadata(sql.motus, projectIDs = proj.num) 4.3.2 Number of registered tags Now that we have complete tag metadata for our project, we can check the number of tags registered by loading the tags table in the .motus file. The tags table contains the metadata of each registered tag, including a unique tagID and information on manufacturer, model, nominal and offset frequency, burst interval, and pulse length. The tags table does not include deployment information. We select the metadata specific to the James Bay Shorebird Project, and ignore tag metadata associated with any duplicate tags belonging to other projects: tbl.tags &lt;- tbl(sql.motus, &quot;tags&quot;) df.tags &lt;- tbl.tags %&gt;% filter(projectID == proj.num) %&gt;% collect() %&gt;% as.data.frame() The number of rows in the df.tags database is equivalent to the number of tags registered to the James Bay Shorebird Project in the sample dataset (i.e., 18 tags): nrow(df.tags) # number of registered tags in the database ## [1] 18 You can view the motusTagIDs: unique(df.tags$tagID) ## [1] 16011 16035 16036 16037 16038 16039 16044 16047 16048 16052 17357 19129 ## [13] 22867 22897 22902 22905 23316 23319 If you are missing registered tags, please follow the instructions at https://motus.org/tag-registration/. 4.3.3 Number of registered tags that were deployed The tag deployment metadata table (tagDeps) in the .motus file is required to check which registered tags have deployments. This file includes the date, time, species, and location of tag deployment. The database is subset to project 176, and we use the anti_join() function to determine which registered tags have (or do not have) corresponding deployment information. tbl.tagDeps &lt;- tbl(sql.motus, &quot;tagDeps&quot;) df.tagDeps &lt;- tbl.tagDeps %&gt;% filter(projectID == proj.num) %&gt;% collect() %&gt;% as.data.frame() %&gt;% # once in df format, can format dates with lubridate mutate(tsStart = as_datetime(tsStart, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;), tsEnd = as_datetime(tsEnd, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;)) anti_join(df.tags, df.tagDeps, by = &quot;tagID&quot;) ## [1] tagID projectID mfgID type codeSet ## [6] manufacturer model lifeSpan nomFreq offsetFreq ## [11] bi pulseLen ## &lt;0 rows&gt; (or 0-length row.names) In the sample data, there are no registered tags without deployment metadata, which suggests that all tags were deployed. If you have undeployed tags in your own files, please check your records to ensure this is the case; without deployment metadata, detections for registered but undeployed tags will be missing from your detections database. 4.3.4 Number of deployments per tag A tag might be deployed more than once, for example, if a previously deployed tag was recovered, and then later re-deployed on another individual. When tags are deployed more than once, the detections data should be considered independently for each deployment. Throughout this book we use the motusTagID as a unique identifier for a deployment. However, when a tag is deployed more than once, the motusTagID will remain consistent between deployments, and we instead need to use the tagDeployID, or combination of motusTagID and tagDeployID to distinguish which detections belong to which deployment. Here, we check whether there are any tags with more than one deployment in the sample data (there are none), and then show you how to make a combined tagID/deployID variable to use in place of the motusTagID if you have multiple deployments of a tag in your own data: df.alltags %&gt;% select(motusTagID, tagDeployID) %&gt;% filter(!(is.na(tagDeployID))) %&gt;% # remove NA tagDeployIDs distinct() %&gt;% group_by(motusTagID) %&gt;% mutate(n = n()) %&gt;% filter(n &gt; 1) ## # A tibble: 0 x 3 ## # Groups: motusTagID [0] ## # ... with 3 variables: motusTagID &lt;int&gt;, tagDeployID &lt;int&gt;, n &lt;int&gt; If you do have multiple deployments for a tag, we recommend creating a motusTagDepID to use in place of the motusTagID to define unique deployments of a tag. Moving forward, you would use motusTagDepID in place of motusTagID as you work through the rest of the book: df.alltags &lt;- df.alltags %&gt;% mutate(motusTagDepID = paste(motusTagID, tagDeployID, sep = &quot;.&quot;)) # and do the same for the tag metadata df.tagDeps &lt;- df.tagDeps %&gt;% mutate(motusTagDepID = paste(tagID, deployID, sep = &quot;.&quot;)) 4.3.5 Location of tag deployments Creating a map of your tag deployments can point out any obvious errors in the tag deployment latitude or longitude that werent captured by the online metadata message centre queries. a. Load base map files Load base map files from the rworldmap package: na.lakes &lt;- map_data(map = &quot;lakes&quot;) na.lakes &lt;- mutate(na.lakes, long = long - 360) # Include all of the Americas to begin na.map &lt;- map_data(map = &quot;world2&quot;) na.map &lt;- filter(na.map, region %in% c(&quot;Canada&quot;, &quot;USA&quot;)) na.map &lt;- mutate(na.map, long = long- 360) # Others countries in the Americas that you may want to plot, depending on your # location: &quot;Mexico&quot;, &quot;lakes&quot;,&quot;Belize&quot;, &quot;Costa Rica&quot;, &quot;Panama&quot;, &quot;Guatemala&quot;, # &quot;Honduras&quot;, &quot;Nicaragua&quot;, &quot;El Salvador&quot;, &quot;Colombia&quot;, &quot;Venezuela&quot;, &quot;Ecuador&quot;, # &quot;Peru&quot;, &quot;Brazil&quot;, &quot;Guyana&quot;,&quot;Suriname&quot;, &quot;Bolivia&quot;, &quot;French Guiana&quot;, &quot;Jamaica&quot;, # &quot;Cuba&quot;, &quot;Haiti&quot;, &quot;Dominican Republic&quot;, &quot;The Bahamas&quot;, &quot;Turks and Caicos # Islands&quot;, &quot;Puerto Rico&quot;, &quot;British Virgin Islands&quot;, &quot;Montserrat&quot;, &quot;Dominica&quot;, # &quot;Saint Lucia&quot;, &quot;Barbados&quot;, &quot;Grenada&quot;, &quot;Trinidad and Tobago&quot;, &quot;Chile&quot;, # &quot;Argentina&quot;, &quot;Uruguay&quot; b. Map the locations of tag deployments Map the location of tag deployments for the sample data: # set limits to map based on locations of detections, ensuring they include the # deployment locations xmin &lt;- -100 #min(df.tagDeps$longitude, na.rm = TRUE) - 5 xmax &lt;- max(df.tagDeps$longitude, na.rm = TRUE) + 5 ymin &lt;- min(df.tagDeps$latitude, na.rm = TRUE) - 5 ymax &lt;- max(df.tagDeps$latitude, na.rm = TRUE) + 5 # map using ggplot ggplot(data = na.lakes, aes(x = long, y = lat)) + geom_polygon(data = na.map, aes(long, lat, group = group), colour = &quot;grey&quot;, fill=&quot;grey98&quot;) + geom_polygon(aes(group = group), colour = &quot;grey&quot;, fill = &quot;white&quot;) + coord_map(projection = &quot;mercator&quot;, xlim = c(xmin, xmax), ylim = c(ymin, ymax)) + labs(x = &quot;&quot;, y = &quot;&quot;) + theme_bw() + geom_point(data = filter(df.tagDeps, projectID == 176), aes(longitude, latitude), size = 2, shape = 1, colour = &quot;red&quot;) If there are any errors in tag deployment location, please correct these online at https://motus.org/data/. 4.3.6 Check completeness and accuracy of tag deployment metadata Required tag metadata includes deployment start date/time, end date/time (if applicable), deployment latitude, deployment longitude, and species. Lack of information on deployment date, time, and location in particular can influence the estimated lifespan of your tag, and therefore whether the tagFinder will look for your tag at the appropriate time(s). It can also increase the potential for ambiguities with duplicate tags in the system. a. Look at range of metadata values As a first step, use summary(df.tagDeps) to get an idea of the range of each variable, and whether any variables have missing (NA) or odd values. The following summarizes a subset of the variables in the df.tagDeps database. There are several things to consider: are the range of start and end dates reasonable for your deployments, or are there obvious errors in the timing of deployments? Is the range in deployment latitude and longitude reasonable? Are the values for species IDs correct? df.tagDeps %&gt;% select(tagID, projectID, tsStart, tsEnd, speciesID, latitude, longitude) %&gt;% summary() ## tagID projectID tsStart ## Min. :16011 Min. :176 Min. :2015-08-02 11:40:00 ## 1st Qu.:16038 1st Qu.:176 1st Qu.:2015-08-13 15:25:00 ## Median :16050 Median :176 Median :2015-09-10 17:50:30 ## Mean :18616 Mean :176 Mean :2016-01-24 12:49:36 ## 3rd Qu.:22890 3rd Qu.:176 3rd Qu.:2016-09-25 15:34:15 ## Max. :23319 Max. :176 Max. :2016-10-15 16:00:00 ## tsEnd speciesID latitude longitude ## Min. :2015-12-17 11:40:00 Min. :4180 Min. :50.19 Min. :-80.69 ## 1st Qu.:2015-12-28 15:25:00 1st Qu.:4670 1st Qu.:50.52 1st Qu.:-80.45 ## Median :2016-03-10 17:50:30 Median :4690 Median :51.48 Median :-80.45 ## Mean :2016-07-28 18:09:36 Mean :4674 Mean :51.18 Mean :-75.85 ## 3rd Qu.:2017-06-06 09:53:45 3rd Qu.:4690 3rd Qu.:51.48 3rd Qu.:-67.92 ## Max. :2017-06-26 16:00:00 Max. :4820 Max. :51.80 Max. :-63.75 There are no missing start dates (tsStart), and deployment start dates range from 2015 to 2016, which is reasonable for this project. The species IDs are numeric, and somewhat meaningless without an ability to assign an actual species name to the numeric ID, which we do next, however there are no missing values. b. Check that species IDs are appropriate for your data The species table in the .motus file associates each numeric species ID with an English, French, and scientific name. We load that table, and subset to the suite of numeric speciesIDs in the tag metadata: # generate list of species IDs in project 176 metadata sp.list &lt;- unique(df.tagDeps$speciesID) # Species metadata tbl.species &lt;- tbl(sql.motus, &quot;species&quot;) tbl.species %&gt;% filter(id %in% sp.list) %&gt;% collect() %&gt;% as.data.frame() ## id english french ## 1 4180 Semipalmated Plover Pluvier semipalmÃ© ## 2 4670 Red Knot BÃ©casseau maubÃ¨che ## 3 4680 Sanderling BÃ©casseau sanderling ## 4 4690 Semipalmated Sandpiper BÃ©casseau semipalmÃ© ## 5 4760 White-rumped Sandpiper BÃ©casseau Ã  croupion blanc ## 6 4780 Pectoral Sandpiper BÃ©casseau Ã  poitrine cendrÃ©e ## 7 4820 Dunlin BÃ©casseau variable ## scientific group sort ## 1 Charadrius semipalmatus BIRDS NA ## 2 Calidris canutus BIRDS NA ## 3 Calidris alba BIRDS NA ## 4 Calidris pusilla BIRDS NA ## 5 Calidris fuscicollis BIRDS NA ## 6 Calidris melanotos BIRDS NA ## 7 Calidris alpina BIRDS NA This lists all species that are included in the tag deployment metadata for the project. If there are species that do not make sense, this is likely due to a data entry error when assigning a deployment to a species. You can look for records in your tag metadata that are associated with a particular speciesID using the following code; you would then use the deployID associated with the entry/entries to find and update the deployment record in your project metadata online: filter(df.tagDeps, speciesID == 4780) ## deployID tagID projectID status tsStart tsEnd ## 1 10517 22867 176 &lt;NA&gt; 2016-09-06 15:35:00 2017-05-18 15:35:00 ## deferSec speciesID bandNumber markerNumber markerType latitude longitude ## 1 NA 4780 &lt;NA&gt; 2641-20877 metal band 51.79861 -80.69139 ## elevation ## 1 NA ## comments ## 1 Sex:F, Age:HY, Bill28, Tarsus:26.2, Wing Chord:123, Wing Flat:129, Mass:57.7, Flag: (FEW)7P6, Blood:Y, Canada, Ontario, James Bay, LONGRIDGE, Comments: REKN tag on mesh; has a duplicate tag same burst rate 380-272 a HY REKN banded at Mingan Islands on 02-Oct-2016 and band number 9822-53171\\n ## id bi tsStartCode tsEndCode fullID age sex ## 1 NA NA 1L 3L SampleData#272.1:5.3@166.38(M.22867) &lt;NA&gt; &lt;NA&gt; ## test motusTagDepID ## 1 NA 22867.10517 Please remember, any metadata corrections need to be made online 4.4 Check Receiver Metadata There are two sources of receiver metadata in Motus detection data: receivers registered to your own project, and receivers registered to the projects of others. You can access metadata for all receivers in the network, because negative data (i.e., my tag was not detected at station X even though station X was active) is often as important as positive data. It also allows you to map where your tags were detected relative to the distribution of receivers throughout the Motus network. Receiver metadata errors or omissions that you find in your .motus file can only be fixed for receivers registered to your own project. All users are encouraged to enter complete and accurate receiver metadata for the benefit of the entire network. If you anticipate needing specific information on receiver or antenna deployments for stations deployed by others, please consider using the Motus discussion group (https://motus.org/discussion/) to request that other registered users record the receiver deployment details you will need; be specific about the exact receiver deployment details you are interested in, and when and where in the network your tags will be deployed and potentially detected. In the following steps we will: download full receiver metadata across the network determine number of project receiver deployments determine timing of project receiver deployments determine location of network-wide and project receiver deployments determine completeness and accuracy of receiver metadata 4.4.1 Download full receiver metadata Later on in this chapter we will want to map all receivers in the network, so we will now load metadata from all projects, as opposed to simply project 176 as we did above. The metadata() function is described in more detail in section 3.10. metadata(sql.motus) 4.4.2 Number of project receiver deployments To see which (if any) receiver deployments are registered to your project, import, subset and summarize the receiver deployment data: tbl.recvDeps &lt;- tbl(sql.motus, &quot;recvDeps&quot;) df.projRecvs &lt;- tbl.recvDeps %&gt;% filter(projectID == proj.num) %&gt;% collect() %&gt;% as.data.frame() %&gt;% mutate(tsStart = as_datetime(tsStart, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;), tsEnd = as_datetime(tsEnd, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;)) summary(df.projRecvs) ## deployID serno receiverType deviceID ## Min. :1134 Length:18 Length:18 Min. : 74.00 ## 1st Qu.:2287 Class :character Class :character 1st Qu.: 75.75 ## Median :3101 Mode :character Mode :character Median :280.00 ## Mean :2952 Mean :250.11 ## 3rd Qu.:4002 3rd Qu.:333.00 ## Max. :4221 Max. :528.00 ## ## macAddress status name fixtureType ## Length:18 Length:18 Length:18 Length:18 ## Class :character Class :character Class :character Class :character ## Mode :character Mode :character Mode :character Mode :character ## ## ## ## ## latitude longitude isMobile ## Min. :51.15 Min. :-80.80 Min. :0.0000 ## 1st Qu.:51.48 1st Qu.:-80.63 1st Qu.:0.0000 ## Median :51.66 Median :-80.57 Median :0.0000 ## Mean :51.58 Mean :-80.47 Mean :0.1667 ## 3rd Qu.:51.74 3rd Qu.:-80.45 3rd Qu.:0.0000 ## Max. :51.88 Max. :-79.81 Max. :1.0000 ## NA&#39;s :3 NA&#39;s :3 ## tsStart tsEnd projectID ## Min. :2014-07-12 00:00:00 Min. :2014-11-06 00:00:00 Min. :176 ## 1st Qu.:2015-05-24 06:00:00 1st Qu.:2015-10-20 00:00:00 1st Qu.:176 ## Median :2016-05-17 12:00:00 Median :2016-03-16 21:05:00 Median :176 ## Mean :2016-01-23 14:03:16 Mean :2016-03-25 17:06:15 Mean :176 ## 3rd Qu.:2016-08-04 01:26:15 3rd Qu.:2016-12-01 00:00:00 3rd Qu.:176 ## Max. :2017-08-20 23:30:00 Max. :2017-08-20 23:30:00 Max. :176 ## NA&#39;s :2 ## elevation siteName utcOffset ## Min. :-7.00 Length:18 Min. : NA ## 1st Qu.:-6.25 Class :character 1st Qu.: NA ## Median :-5.50 Mode :character Median : NA ## Mean :-5.50 Mean :NaN ## 3rd Qu.:-4.75 3rd Qu.: NA ## Max. :-4.00 Max. : NA ## NA&#39;s :16 NA&#39;s :18 There are 18 receiver deployments registered to the sample project. Four deployments are missing latitude and longitude, and six deployments are missing end dates, which suggests that those receivers are still deployed. The following code keeps only variables of interest (by removing those we do not need), and arranges the remaining records by receiver ID, latitude, and start date: df.projRecvs %&gt;% mutate(dateStart = date(tsStart)) %&gt;% select(-serno,-fixtureType, -macAddress, -tsStart, -tsEnd, -elevation, -projectID, -status, -receiverType, -siteName) %&gt;% arrange(deviceID, latitude, dateStart) ## deployID deviceID name latitude longitude isMobile utcOffset ## 1 3100 74 Washkaugou 51.1540 -79.8144 0 NA ## 2 2291 75 North Bluff 51.4839 -80.4500 0 NA ## 3 3102 75 North Bluff 51.4839 -80.4501 0 NA ## 4 4051 75 North Bluff 51.4839 -80.4501 0 NA ## 5 4221 75 North Bluff 51.4839 -80.4501 0 NA ## 6 3103 78 Piskwamish 51.6579 -80.5678 0 NA ## 7 4050 78 Piskwamish 51.6580 -80.5679 0 NA ## 8 1134 280 Longridge 51.8230 -80.6911 0 NA ## 9 2285 280 Longridge 51.8231 -80.6912 0 NA ## 10 3097 280 Longridge 51.8244 -80.6909 0 NA ## 11 4048 280 Halfway Point 51.8753 -80.7973 0 NA ## 12 1135 285 Netitishi 51.2913 -80.1167 0 NA ## 13 2289 285 Netitishi 51.2913 -80.1168 0 NA ## 14 2286 349 Piskwamish 51.6578 -80.5676 0 NA ## 15 1137 349 Piskwamish 51.6582 -80.5669 0 NA ## 16 3813 528 NP mobile NA NA 1 NA ## 17 4001 528 BurntPointAerial NA NA 1 NA ## 18 4002 528 JamesBayAerial NA NA 1 NA ## dateStart ## 1 2016-05-18 ## 2 2015-05-25 ## 3 2016-05-18 ## 4 2017-05-17 ## 5 2017-08-20 ## 6 2016-05-18 ## 7 2017-05-17 ## 8 2014-07-16 ## 9 2015-05-24 ## 10 2016-05-17 ## 11 2017-05-16 ## 12 2014-07-12 ## 13 2015-05-25 ## 14 2015-05-24 ## 15 2014-07-16 ## 16 2015-07-06 ## 17 2016-07-19 ## 18 2016-08-09 The number of receiver deployments in the metadata should correspond with the number of field deployments. Looking at the isMobile column for the four receiver deployments that are missing latitude and longitude information, it is evident that these are mobile receivers that do not have a fixed position (ie. they have a value of 1). Because they are mobile, coordinates of the deployment arent expected, and in this case will remain NA. Receiver deployment coordinates for mobile receivers, when present, are meant to represent the starting point for the deployment. 4.4.3 Timing of project receiver deployments The timing of deployments can be displayed graphically; horizontal line(s) in the following plot show the time span for each receiver (deviceID) deployment registered to the James Bay Shorebird Project. Note that for the two receivers without deployment end dates, the code assigns an arbitrary end date based on the maximum end date of the other receivers plus one month - without this fix, deployments without end dates do not get displayed. Different deployments of the same receiver should not overlap in time: # put data in long format to simplify plotting (or use geom_segment) df.projRecvs.long &lt;- df.projRecvs %&gt;% select(deviceID, deployID, tsStart, tsEnd) %&gt;% gather(when, ts, c(tsStart, tsEnd)) %&gt;% # fake end date: mutate(ts = if_else(is.na(ts), max(ts, na.rm = TRUE) + duration(1, &quot;month&quot;), ts)) ggplot(data = df.projRecvs.long, aes(x = ts, y = as.factor(deviceID), colour = as.factor(deployID))) + theme(legend.position = &quot;none&quot;) + geom_line(lwd = 3) + # instead, centre to the right geom_text(data = filter(df.projRecvs.long, when == &quot;tsStart&quot;), aes(label = deployID), hjust = &quot;left&quot;, nudge_y = 0.2, size = 3, angle = 45) + theme_bw() + labs(x = &quot;Year&quot;, y = &quot;Receiver ID&quot;) If you want more detail for a given year (or all years) you can either subset and re-plot, or use the day of year on the x-axis, and facet_wrap() by year. ggplot(data = df.projRecvs.long, aes(x = yday(ts), y = as.factor(deviceID), colour = as.factor(deployID))) + theme_bw() + theme(legend.position = &quot;none&quot;) + geom_line(lwd = 3) + # centre labels to the left geom_text(data = filter(df.projRecvs.long, when == &quot;tsStart&quot;), aes(label = deployID), hjust = &quot;left&quot;, nudge_y = 0.4, size = 3) + labs(x = &quot;Day of year&quot;, y = &quot;Receiver ID&quot;) + facet_grid(year(ts) ~ ., scales = &quot;free&quot;) 4.4.4 Location of receiver deployments Maps provide better spatial context than simple plots; the following steps plot the location of Motus receivers on a map of North America, with receivers deployed by the sample project displayed in red. a. Load all receiver metadata df.recvDeps &lt;- tbl.recvDeps %&gt;% collect() %&gt;% as.data.frame() %&gt;% mutate(tsStart = as_datetime(tsStart, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;), tsEnd = as_datetime(tsEnd, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;)) b. Load base map files na.lakes &lt;- map_data(map = &quot;lakes&quot;) na.lakes &lt;- mutate(na.lakes, long = long - 360) # Include all of the Americas to begin na.map &lt;- map_data(map = &quot;world2&quot;) na.map &lt;- filter(na.map, region %in% c(&quot;Canada&quot;, &quot;USA&quot;, &quot;Mexico&quot;, &quot;lakes&quot;, &quot;Belize&quot;, &quot;Costa Rica&quot;, &quot;Panama&quot;, &quot;Guatemala&quot;, &quot;Honduras&quot;, &quot;Nicaragua&quot;, &quot;El Salvador&quot;, &quot;Colombia&quot;, &quot;Venezuela&quot;, &quot;Ecuador&quot;, &quot;Peru&quot;, &quot;Brazil&quot;, &quot;Guyana&quot;,&quot;Suriname&quot;, &quot;Bolivia&quot;, &quot;French Guiana&quot;, &quot;Jamaica&quot;, &quot;Cuba&quot;, &quot;Haiti&quot;, &quot;Dominican Republic&quot;, &quot;The Bahamas&quot;, &quot;Turks and Caicos Islands&quot;, &quot;Puerto Rico&quot;, &quot;British Virgin Islands&quot;, &quot;Montserrat&quot;, &quot;Dominica&quot;, &quot;Saint Lucia&quot;, &quot;Barbados&quot;, &quot;Grenada&quot;, &quot;Trinidad and Tobago&quot;, &quot;Chile&quot;, &quot;Argentina&quot;, &quot;Uruguay&quot;, &quot;Paraguay&quot;)) %&gt;% mutate(long = long - 360) c. Map the location of receivers in the Americas Map showing the location of network-wide receivers (dark grey x) and receivers deployed by the James Bay Shorebird Project (project 176; red x). # set map limits using detection locations; # ensure they include the deployment locations xmin &lt;- min(df.recvDeps$longitude, na.rm = TRUE) - 2 xmax &lt;- -20 # restrict to the Americas (excluding a few points in Europe) ymin &lt;- -60 #min(df.recvDeps$longitude, na.rm = TRUE) - 2 ymax &lt;- max(df.recvDeps$latitude, na.rm = TRUE) + 2 # map ggplot(data = na.lakes, aes(x = long, y = lat)) + theme_bw() + geom_polygon(data = na.map, aes(long, lat, group = group), colour = &quot;grey&quot;, fill = &quot;grey98&quot;) + geom_polygon(aes(group = group), colour = &quot;grey&quot;, fill = &quot;white&quot;) + coord_map(projection = &quot;mercator&quot;, xlim = c(xmin, xmax), ylim = c(ymin, ymax)) + labs(x = &quot;&quot;, y = &quot;&quot;) + geom_point(data = df.recvDeps, aes(longitude, latitude, colour = as.logical(projectID == 176)), size = 0.8, shape = 4) + scale_colour_manual(values = c(&quot;grey30&quot;, &quot;red&quot;), name = &quot;Project 176 Deployment&quot;) d. Map the location of project specific receivers only Map of project-specific receivers, created by setting the x-axis (longitude) and y-axis (latitude) map limits using the df.projRecvs dataframe created above. Deployments are restricted to those that were active at in 2016. # set map limits using detection locations; # ensure they include the deployment locations xmin &lt;- min(df.projRecvs$longitude, na.rm = TRUE) - 2 xmax &lt;- max(df.projRecvs$longitude, na.rm = TRUE) + 2 ymin &lt;- min(df.projRecvs$latitude, na.rm = TRUE) - 1 ymax &lt;- max(df.projRecvs$latitude, na.rm = TRUE) + 1 # map ggplot(data = na.lakes, aes(x = long, y = lat))+ theme_bw() + geom_polygon(data = na.map, aes(long, lat, group = group), colour = &quot;grey&quot;, fill = &quot;grey98&quot;) + geom_polygon(aes(group = group), colour = &quot;grey&quot;, fill = &quot;white&quot;) + coord_map(projection = &quot;mercator&quot;, xlim = c(xmin, xmax), ylim = c(ymin, ymax)) + labs(x = &quot;&quot;, y = &quot;&quot;) + geom_point(data = filter(df.projRecvs, year(tsStart) == 2016, !is.na(latitude)), # remove mobile receivers aes(longitude, latitude, colour = as.factor(deviceID)), size = 2, shape = 1)+ scale_colour_discrete(name = &quot;Receiver ID&quot;) 4.4.5 Completeness and accuracy of receiver metadata Motus users will be concerned primarily with the completeness of metadata for receiver deployments with detection(s) of their tags, because these can directly influence the interpretation of those detections. For example, missing deployment latitude or longitude will result in an unknown location for the tag detection, and missing information on antenna type and/or orientation can impede the estimation of flight or departure orientation. In many cases, however, metadata for receiver deployments without tag detections can also be useful, for example to estimate probability of detecting an animal that passes within range of a station. In this section, the focus is on metadata for receivers registered to a particular project. Depending on your interests, these summaries can be applied to a larger group of receivers, e.g., all receivers with detections or all receivers within certain geographic limits (with or without detections). a. Load receiver and antenna metadata # antenna metadata for ALL Motus antenna deployments; # to simplify, keep only the variables of interest. tbl.antDeps &lt;- tbl(sql.motus, &quot;antDeps&quot;) df.antDeps &lt;- tbl.antDeps %&gt;% select(deployID, port, antennaType, bearing, heightMeters) %&gt;% collect() %&gt;% as.data.frame() # receiver deployments; select variables of interest df.recvDeps &lt;- df.recvDeps %&gt;% select(deployID, receiverType, deviceID, name, latitude, longitude, isMobile, tsStart, tsEnd, projectID, elevation) df.stationDeps &lt;- left_join(df.recvDeps, df.antDeps, by = &quot;deployID&quot;) Subset these to receivers registered to a project: df.stationDeps &lt;- filter(df.stationDeps, projectID == proj.num) b. Look at range of metadata values Use summary() to get a general idea of the distribution of the variables in the data. summary(df.stationDeps) ## deployID receiverType deviceID name ## Min. :1134 Length:55 Min. : 74.0 Length:55 ## 1st Qu.:2286 Class :character 1st Qu.: 75.0 Class :character ## Median :3100 Mode :character Median :280.0 Mode :character ## Mean :2919 Mean :201.3 ## 3rd Qu.:4048 3rd Qu.:285.0 ## Max. :4221 Max. :528.0 ## ## latitude longitude isMobile ## Min. :51.15 Min. :-80.80 Min. :0.00000 ## 1st Qu.:51.48 1st Qu.:-80.60 1st Qu.:0.00000 ## Median :51.66 Median :-80.57 Median :0.00000 ## Mean :51.57 Mean :-80.46 Mean :0.05455 ## 3rd Qu.:51.70 3rd Qu.:-80.45 3rd Qu.:0.00000 ## Max. :51.88 Max. :-79.81 Max. :1.00000 ## NA&#39;s :3 NA&#39;s :3 ## tsStart tsEnd projectID ## Min. :2014-07-12 00:00:00 Min. :2014-11-06 00:00:00 Min. :176 ## 1st Qu.:2015-05-24 00:00:00 1st Qu.:2015-11-02 00:00:00 1st Qu.:176 ## Median :2016-05-18 00:00:00 Median :2016-10-05 08:15:00 Median :176 ## Mean :2016-02-22 12:28:39 Mean :2016-05-04 00:08:20 Mean :176 ## 3rd Qu.:2017-05-16 15:55:00 3rd Qu.:2016-12-01 00:00:00 3rd Qu.:176 ## Max. :2017-08-20 23:30:00 Max. :2017-08-20 23:30:00 Max. :176 ## NA&#39;s :7 ## elevation port antennaType bearing ## Min. :-7.000 Length:55 Length:55 Min. : 10.00 ## 1st Qu.:-7.000 Class :character Class :character 1st Qu.: 66.25 ## Median :-7.000 Mode :character Mode :character Median :145.00 ## Mean :-5.714 Mean :151.34 ## 3rd Qu.:-4.000 3rd Qu.:215.00 ## Max. :-4.000 Max. :357.50 ## NA&#39;s :48 NA&#39;s :11 ## heightMeters ## Min. :5.60 ## 1st Qu.:5.60 ## Median :5.80 ## Mean :5.85 ## 3rd Qu.:6.00 ## Max. :6.20 ## NA&#39;s :3 There are the 4 deployments with missing latitude and longitude associated with the four deployments of mobile receivers that we saw earlier. Elevation is missing from 74 of 91 records, but elevation is not a required field, and can be estimated from other sources, or directly in R (for example, see https://stackoverflow.com/questions/8973695/conversion-for-latitude-longitude-to-altitude-in-r). Antenna bearing is missing from 18 of 91 records, and height of the antenna(s) is missing for 4 of 91 records. Subset the records with missing antenna bearing to see if these can be fixed: df.stationDeps %&gt;% filter(is.na(bearing)) %&gt;% select(-elevation, -deviceID, -tsEnd) ## deployID receiverType name latitude longitude isMobile ## 1 3097 SENSORGNOME Longridge 51.8244 -80.6909 0 ## 2 3100 SENSORGNOME Washkaugou 51.1540 -79.8144 0 ## 3 3102 SENSORGNOME North Bluff 51.4839 -80.4501 0 ## 4 3103 SENSORGNOME Piskwamish 51.6579 -80.5678 0 ## 5 3813 LOTEKSRX800 NP mobile NA NA 1 ## 6 4001 LOTEKSRX800 BurntPointAerial NA NA 1 ## 7 4002 LOTEKSRX800 JamesBayAerial NA NA 1 ## 8 4048 SENSORGNOME Halfway Point 51.8753 -80.7973 0 ## 9 4050 SENSORGNOME Piskwamish 51.6580 -80.5679 0 ## 10 4051 SENSORGNOME North Bluff 51.4839 -80.4501 0 ## 11 4221 SENSORGNOME North Bluff 51.4839 -80.4501 0 ## tsStart projectID port antennaType bearing heightMeters ## 1 2016-05-17 00:00:00 176 4 omni-whip NA 6.0 ## 2 2016-05-18 00:00:00 176 4 omni-whip NA 6.0 ## 3 2016-05-18 00:00:00 176 4 omni-whip NA 6.0 ## 4 2016-05-18 00:00:00 176 4 omni-whip NA 6.0 ## 5 2015-07-06 00:00:00 176 1 yagi-3 NA NA ## 6 2016-07-19 08:00:00 176 1 yagi-3 NA NA ## 7 2016-08-09 07:15:00 176 1 yagi-3 NA NA ## 8 2017-05-16 15:55:00 176 3 omni-whip NA 6.2 ## 9 2017-05-17 15:19:00 176 4 omni-whip NA 6.2 ## 10 2017-05-17 15:00:00 176 4 omni-whip NA 6.2 ## 11 2017-08-20 23:30:00 176 4 omni-whip NA 6.2 Receiver deployments with missing antenna bearing(s) are restricted to deployments of omni-directional antennas or mobile receivers, and so the missing values make sense. These records also show that the four records with missing antenna height are also associated with the four mobile receivers, and so again the missing values make sense and do not need to be fixed. Remember that any missing metadata needs to be corrected online. Metadata corrected online will automatically be corrected in your detection files. If you have already downloaded your detection data, you can update the existing file to include new metadata and detections (see sections 3.9, 3.7). In the next chapter we will examine our data for false positives, and remove detections of ambiguous tags. "],["dataCleaning.html", "5 Data Cleaning 5.1 Load required packages 5.2 Load detections data 5.3 Assess tag detections 5.4 Preliminary filtering 5.5 Preparing the data 5.6 Preliminary data checks 5.7 Examining ambiguous detections 5.8 Checking validity of run lengths of 2 or 3 5.9 Filtering the data", " 5 Data Cleaning This chapter was contributed by Tara L. Crewe, Zoe Crysler, and Philip Taylor. Revisions by Catherine Jardine, Steffi LaZerte and Denis Lepage There are three sources of error that can result in tag detections appearing in your database that are incorrect. First, random radio noise (static) can be detected and interpreted to be the transmission of a tag. These are called false positives. Second, despite our best efforts to avoid it, duplicate tags are sometimes transmitting in the network at the same time. When two tags are deployed at the same time that have the same ID code, burst interval, and nominal transmit frequency, it results in situations where the detections may belong to either tag. If that happens, we must rely on contextual information to separate them (if we can). We term these Ambiguous tags. Third, a tag can appear to be present when two tags are transmitting at the same time that by chance produce a signal that looks like a third tag that is not in fact present. Such tags are most common at roosting sites or breeding colonies, where many tags are transmitting simultaneously. We term these Aliased tags. We do not deal explicitly with Aliased tags in this chapter; we are working on a way to globally identify them and eliminate them from the data. We mention them here because you may encounter situations with what appear to be highly plausible detections that dont make biological sense. Please contact us if you think you have some of these Aliased tag detections in your database. The goal of this chapter is to provide you with the tools you need to check your data for false detections, and remove them from your data. We do so by providing example workflows that deal with false positives and ambiguous tags in the following steps: Run a preliminary filter to remove all detections with runLen of 3 or less, and detections with intermediate runLens made during periods of high noise/activity. A run is a group of consecutive detections of a tag detected on a single antenna at a single receiver. In general, a detection with a run length of 2 or 3 (i.e., 2 or 3 bursts) has a high probability of being a false positive detection. With the exception of a few quiet stations with little noise, we generally recommend that you filter out all detections with a run length of 3 or less. However, because you will likely lose some true detections in the process, we also recommend that after a full analysis of your data, you return to these detections and examine them individually, to determine (usually contextually) if they can be considered real. Stations that are particularly noisy may also have false detections with longer runLens. Determine how many of your tag detections may be ambiguous detections Provide a workflow for examining individual tags, and determine if runs in those tags are errors Filter errors from your data 5.1 Load required packages Follow the instructions in Chapter 2 to install the following packages before loading, if they are not already installed. Sys.setenv(tz = &quot;UTC&quot;) library(motus) library(tidyverse) library(lubridate) 5.2 Load detections data Recall from Chapter 3 that when accessing the sample database, you will need to input motus.sample in the R console as both username and password when prompted by the tagme() user authentication process. This section assumes you have already completed the initial sample data download. proj.num &lt;- 176 sql.motus &lt;- tagme(proj.num, update = TRUE, dir = &quot;./data/&quot;) 5.3 Assess tag detections First, determine which project tags have detections. There are several reasons why deployed tags might not be detected, including: The tag was not properly activated on deployment. To avoid this, always check that a tag is active using a hand-held receiver before attaching the tag to your study animal and releasing it. An animal with a properly activated tag might not have passed within range of a receiving station. Study designs that incorporate strategic placement of receivers to meet project goals can improve the probability of a tag being detected. Missing or incorrect tag deployment metadata in the Motus database can result in the data processing algorithm not looking for your tag at the time the tag was deployed, or at all. Please ensure your tag metadata are entered correctly. Before going further, please check whether any of your tags were deployed more than once, as described in section 4.3.4. If so, you will need to use tagDeployID or a combination of motusTagID and tagDeployID to uniquely define detections associated with a tag deployment (either will do, but combining the two fields will let you know which tagID is associated with each deployment). In the sample data, all tags were deployed only once, and so we use the motusTagID as a unique identifier for a tag deployment in all R code throughout the book. Using the count() function we can see that there are detections for 18 tags deployed by the sample project. tbl(sql.motus, &quot;alltags&quot;) %&gt;% filter(tagProjID == proj.num) %&gt;% # subset to include only tags registered to project count(motusTagID) %&gt;% as.data.frame() ## motusTagID n ## 1 16011 127 ## 2 16035 456 ## 3 16036 118 ## 4 16037 1353 ## 5 16038 162 ## 6 16039 1126 ## 7 16044 305 ## 8 16047 839 ## 9 16048 98 ## 10 16052 159 ## 11 17357 289 ## 12 19129 1288 ## 13 22867 5767 ## 14 22897 34796 ## 15 22902 2923 ## 16 22905 26010 ## 17 23316 5734 ## 18 23319 22759 If we break down these counts by run length using the following code we further see that many have run lengths of 3 (the run 3 column). tbl(sql.motus, &quot;alltags&quot;) %&gt;% filter(tagProjID == proj.num) %&gt;% # subset to include only tags registered to project mutate(rl.gt.3 = if_else(runLen == 3, &quot;run 3&quot;, &quot;run &gt; 3&quot;)) %&gt;% count(motusTagID, rl.gt.3) %&gt;% collect() %&gt;% spread(key = rl.gt.3, value = n) ## # A tibble: 18 x 3 ## # Groups: motusTagID [18] ## motusTagID `run &gt; 3` `run 3` ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 16011 118 9 ## 2 16035 441 15 ## 3 16036 115 3 ## 4 16037 1335 18 ## 5 16038 156 6 ## 6 16039 1117 9 ## 7 16044 287 18 ## 8 16047 758 81 ## 9 16048 83 15 ## 10 16052 144 15 ## 11 17357 286 3 ## 12 19129 1189 99 ## 13 22867 5572 195 ## 14 22897 34373 423 ## 15 22902 2854 69 ## 16 22905 25782 228 ## 17 23316 5551 183 ## 18 23319 22567 192 Although some of these may be valid detections, we have found it simpler to just remove them from our analysis, and possibly revisit them at a later stage. In the next few sections we will explore a series of filters that do just this. 5.4 Preliminary filtering We can perform some preliminary filtering based on run length (runLen). As runs are composed of sequences of hits, the longer the run the more confident we can be that it represents a true detection. However, local conditions at an individual receiver may vary in their exposure to background radio noise. Sites with relatively more background noise may be more prone to reporting false detections. Therefore the standard motus filter relies both on the length of the run, and the amount of radio activity at a given site. This value is stored as a field called motusFilter in the runs table. An additional table (activity) allows users to calculate a filter based on different criteria if they want. 5.4.1 Understanding the motusFilter Starting in July 2019, data downloaded from motus with the tagme() function will include a standard filter value that can be used to identify detections that we believe have a higher probability of being false hits. The various outputs on the motus web site are pre-filtered, but the R package provides access to all detections, allowing users more control over which detections to keep or omit. The motusFilter field in the runs table represents the probability that the run is a true detection. Currently the motusFilter contains just two values 0 or 1. Runs with a motusFilter of 0 have a low probability of being true detections. 5.4.2 How the motusFilter is generated The motusFilter is based the number of detections of different run lengths at a given site, across all motus projects. Periods with lots of radio interference will typically generate a high number of very short runs that are in reality spurious data. In the presence of a high ratio of runs with length = 2 at a given time, we consider that site as noisy and increase the minimum threshold for run lengths that we consider to be valid detections. In general, a detection with a run length of 2 or 3 (i.e., 2 or 3 bursts) has a relatively high probability of being a false positive detection. Therefore, runs with a length 3 or less are conservatively assigned a motusFilter of 0. For runs greater than length 3, data in the activity table provides a method of assessing the relative amount of background noise at a site which can be used to assess the probability of these runs being true detections. The activity table provides the number of runs of various lengths for each hour (called hourBin) within each batch and for each antenna. A high number of detections within an hour (e.g., &gt;= 100) with a high proportion of short runs (e.g., length 2 &gt;= 85%) are indicative of a noisy environment, more likely to generate false positives. For those periods, we treat the intermediate run lengths (3 &lt; runLen &lt; 5) as invalid (motusFilter = 0). Intermediate run lengths are otherwise considered valid (motusFilter = 1). The motusFilter values in the runs table have been calculated on the basis of the above criteria, which were determined through some empirical examination of data. If you are working with a dataset downloaded through tagme() prior to July 2019 it will not include those values. In those cases, you will either need to download a new copy of the entire dataset for your project or receiver, or to use the filterByActivity() function described below to calculate the missing values. To omit runs identified as dubious by motusFilter we can use an anti-join. # Number of rows with runs 3 hits or less filter(tbl(sql.motus, &quot;alltags&quot;), runLen &lt;= 3) %&gt;% collect() %&gt;% nrow() ## [1] 4511 # Identify runs to remove to_remove &lt;- tbl(sql.motus, &quot;runs&quot;) %&gt;% select(runID, motusFilter) %&gt;% filter(motusFilter == 0) # Use anti-join to remove those runs from the alltags tbl_filtered &lt;- anti_join(tbl(sql.motus, &quot;alltags&quot;), to_remove, by = &quot;runID&quot;) # Number of rows with runs 3 hits or less after being filtered filter(tbl_filtered, runLen &lt;= 3) %&gt;% collect() %&gt;% nrow() ## [1] 0 5.4.3 Custom filters with the filterByActivity() function The motusFilter is one method of determining false detections, but motus users are encouraged to explore alternative filter parameters. The motus R-package includes a filterByActivity() function that allows users to specify custom parameters used to identify false positives based on the activity table. Users can return either just the true positives (return = \"good\"), just the false positives (return = \"bad\") or all hits (return = \"all\") but with a new column, probability, which reflects either 0 (expected false positive) or 1 (expected true positive). For example, the following code, adds a probability column to the sample project data, which is identical to the motusFilter column (i.e., by default filterByActivity() uses the same conditions). Note that this function requires the SQLite database connection (not a flat data frame), but returns a data.frame of the alltags view (not a SQLite database connection). tbl_motusFilter &lt;- filterByActivity(sql.motus, return = &quot;all&quot;) Users can adjust these parameters to be less strict (i.e., exclude fewer detections). This example excludes all runs of length 2 or less and will exclude any runs less than length 4 from hourBins which have more than 500 runs and where at least 95% of those runs have a run length of 2. tbl_relaxed &lt;- filterByActivity(sql.motus, minLen = 2, maxLen = 4, maxRuns = 500, ratio = 0.95, return = &quot;all&quot;) These parameters can also be more strict (i.e., exclude more detections). This next example excludes all runs of length 4 or less and will exclude any runs less than length 10 from hourBins which have more than 50 runs and where at least 75% of those runs have a run length of 2. tbl_strict &lt;- filterByActivity(sql.motus, minLen = 4, maxLen = 10, maxRuns = 50, ratio = 0.75, return = &quot;all&quot;) Note that the filters may exclude some true detections in the process. Therefore, we recommend that after a full analysis of your data, you return to these detections and examine them individually, to determine (usually contextually) if they can be considered real. 5.5 Preparing the data When accessing the alltags view, we filter the data and remove some unnecessary variables to reduce the overall size of the data set and make it easier to work with. This is particularly important for large, unwieldy projects; details on how to view the variables in a tbl, and how to filter and subset prior to collecting data into a dataframe can be found in Chapter 3.5.8. 5.5.1 Label detections by probability First we will use the filterByActivity() function to label dubious detections. This returns all the data in the alltags view with a new probability column. tbl.alltags &lt;- filterByActivity(sql.motus, return = &quot;all&quot;) Alternatively we can change the default, so the filterByActivity() function uses the alltagsGPS view. However, on very large databases this could be slow. tbl.alltags.gps &lt;- filterByActivity(sql.motus, return = &quot;all&quot;, view = &quot;alltagsGPS&quot;) 5.5.2 Clean up Lets filter to the good detections. We will filter to 1 for detections to keep and 0 for dubious detections. Then well use the collect() and as.data.frame() functions to transform the dataframe into a flat (i.e. non SQLite) file, and then transform all time stamp variables from seconds since January 1 1970 to datetime (POSIXct) format. df.alltags.sub &lt;- tbl.alltags %&gt;% filter(probability == 1) %&gt;% collect() %&gt;% as.data.frame() %&gt;% mutate(ts = as_datetime(ts), # work with dates AFTER transforming to flat file tagDeployStart = as_datetime(tagDeployStart), tagDeployEnd = as_datetime(tagDeployEnd)) Let us also save the excluded detections for later analysis. df.block.0 &lt;- filter(tbl.alltags, probability == 0) %&gt;% select(motusTagID, runID) %&gt;% distinct() %&gt;% collect() %&gt;% data.frame() 5.5.3 Add GPS data The filterByActivity() function can use the alltagsGPS view, but this may be slow. A way around this speed problem is to use the getGPS() function to retrieve the GPS values of a data subset (data) after the data has been filtered. Note that in this example, the sample dataset doesnt have GPS data # Retrieve GPS data for each hitID gps_index &lt;- getGPS(sql.motus, data = df.alltags.sub, by = &quot;closest&quot;) # Merge GPS points in with our data df.alltags.sub &lt;- left_join(df.alltags.sub, gps_index, by = &quot;hitID&quot;) We match GPS locations to hitIDs according to one of several different time values, specified by the by argument. This can be the closest location in time, the daily median location, or the median location within X minutes of a hitID (here, X can be any number greater than zero and represents the size of the time block in minutes over which to calculate a median location). If using the closest option, you can also specify a cutoff which will only match GPS records which are within cutoff = X minutes of the hit. This way you can avoid having situations where the closest GPS record is actually days away (see also Chapter 3.5.7). We then create receiver latitude and longitude variables (recvLat, recvLon, recvAlt) based on the coordinates recorded by the receiver GPS (gpsLat, gpsLon, gpsAlt), and where those are not available, infilled with coordinates from the receiver deployment metadata (recvDeployLat, recvDeployLon, recvDeployAlt). Missing GPS coordinates may appear as NA if they are missing, or as 0 or 999 if there was a problem with the unit recording. Finally, we create receiver names by adding rounded recvLat and recvLon to the recvDeployName for those receivers in the database that do not have these values filled in. As more users explore (and fix!) their metadata, these missing values should begin to disappear. Well fix this here as sometimes if there is missing metadata (ie. a missing receiver deployment spanning some of your detections), you will get NAs which can lead to problems later on. df.alltags.sub &lt;- df.alltags.sub %&gt;% mutate(recvLat = if_else((is.na(gpsLat)|gpsLat == 0|gpsLat == 999), recvDeployLat, gpsLat), recvLon = if_else((is.na(gpsLon)|gpsLon == 0|gpsLon == 999), recvDeployLon, gpsLon), recvAlt = if_else(is.na(gpsAlt), recvDeployAlt, gpsAlt)) %&gt;% select(-noise, -slop, -burstSlop, -done, -bootnum, -mfgID, -codeSet, -mfg, -nomFreq, -markerNumber, -markerType, -tagDepComments, -fullID, -deviceID, -recvDeployLat, -recvDeployLon, -recvDeployAlt, -speciesGroup, -gpsLat, -gpsLon, -recvAlt, -recvSiteName) %&gt;% mutate(recvLat = plyr::round_any(recvLat, 0.05), recvLon = plyr::round_any(recvLon, 0.05), recvDeployName = if_else(is.na(recvDeployName), paste(recvLat, recvLon, sep=&quot;:&quot;), recvDeployName)) # Note that in the select statement, you can just select the variables you need # e.g.: select(runID, ts, sig, freqsd, motusTagID, ambigID, runLen, tagProjID, # tagDeployStart, tagDeployEnd, etc.) # As opposed to those you don&#39;t need (-done, -bootnum, etc.) Now we have a nice clean data frame! 5.6 Preliminary data checks Prior to more specific filtering the data, we will perform a few summaries and plots of the data. 5.6.1 Summarize tag detections An initial view of the data is best achieved by plotting. We will show you later how to plot detections on a map, but we prefer a simpler approach first; plotting detections through time by both latitude and longitude. First however, we should simplify the data. If we dont, we risk trying to plot thousands or millions of points on a plot (which can take a long time). Well do this by creating a little function here, since we will use this operation again in future steps. Note that we will need to remove about 150 detections, because there is no geographic data associated with the receiver metadata, and so no way to determine the location of those detections. Do a simple check to see if these receivers belong to you, and if so, please fix the metadata online! For example, here we can see which receivers are missing (is.na(recvLat)). df.alltags.sub %&gt;% filter(is.na(recvLat)) %&gt;% select(recvLat, recvLon, recvDeployName, recvDeployID, recv, recvProjID, recvProjName) %&gt;% distinct() ## recvLat recvLon recvDeployName recvDeployID recv recvProjID ## 1 NA NA NP mobile 3813 Lotek-280 176 ## 2 NA NA NA:NA NA SG-1415BBBK0382 NA ## 3 NA NA NA:NA NA SG-2814BBBK0547 NA ## recvProjName ## 1 SampleData ## 2 &lt;NA&gt; ## 3 &lt;NA&gt; Simplify the data for plotting We can simplify the data by summarizing by the runID. If you want to summarize at a finer/coarser scale, you can also create other groups. The simplest alternative is a rounded timestamp variable; for example by using mutate(ts.h = plyr::round_any(ts, 3600). Other options are to just use date (e.g date = as_date(ts)). Here is an advanced example creating a function so we can re-use this simplification later. fun.getpath &lt;- function(df) { df %&gt;% filter(tagProjID == proj.num, # keep only tags registered to the sample project !is.na(recvLat) | !(recvLat == 0)) %&gt;% # drops data without lon/lat group_by(motusTagID, runID, recvDeployName, ambigID, tagDepLon, tagDepLat, recvLat, recvLon) %&gt;% #summarizing by runID to get max run length and mean time stamp: summarize(max.runLen = max(runLen), ts.h = mean(ts)) %&gt;% arrange(motusTagID, ts.h) } # end of function df.alltags.path &lt;- fun.getpath(df.alltags.sub) ## `summarise()` regrouping output by &#39;motusTagID&#39;, &#39;runID&#39;, &#39;recvDeployName&#39;, &#39;ambigID&#39;, &#39;tagDepLon&#39;, &#39;tagDepLat&#39;, &#39;recvLat&#39; (override with `.groups` argument) We would initially plot a subset of tags by either latitude or longitude, to get an overview of where there might be issues. Here, to simplify the example, we plot only six tags. We avoid examining the ambiguous tags for now. ggplot(data = filter(df.alltags.path, motusTagID %in% c(16011, 16035, 16036, 16037, 16038, 16039)), aes(x = ts.h, y = recvLat)) + theme_bw() + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) + geom_point() + geom_path() + facet_wrap(~ motusTagID, scales = &quot;free&quot;, ncol = 2) Although there dont seem to be any immediate problems, lets take a look at the tags showing up around 44 degrees during September. Lets examine these tags in more detail by examining the runs in the data frame that are associated with detections in September. df.alltags.sub %&gt;% filter(month(ts) %in% c(9), motusTagID %in% c(16035, 16037, 16039), recvLat &lt; 44) %&gt;% group_by(recvDeployName, month(ts), runLen) %&gt;% summarize(n = length(ts), n.tags = length(unique(motusTagID))) %&gt;% arrange(runLen) ## `summarise()` regrouping output by &#39;recvDeployName&#39;, &#39;month(ts)&#39; (override with `.groups` argument) ## # A tibble: 13 x 5 ## # Groups: recvDeployName, month(ts) [5] ## recvDeployName `month(ts)` runLen n n.tags ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Assateague State Park 9 6 6 1 ## 2 FINWR 9 6 6 1 ## 3 FINWR 9 10 10 1 ## 4 FINWR 9 20 20 1 ## 5 Prime Hook 9 23 23 1 ## 6 BULL 9 24 24 1 ## 7 Prime Hook 9 27 27 1 ## 8 Bombay Hook 9 32 32 1 ## 9 Prime Hook 9 32 32 1 ## 10 Bombay Hook 9 36 36 1 ## 11 BULL 9 38 38 1 ## 12 Bombay Hook 9 53 53 1 ## 13 FINWR 9 73 73 1 Since we have already filtered dubious detections, these remaining ones dont seem immediately unreliable (all with runs of at least 6). If you are interested, you can re-run the code above, but on the full data frame (tbl(sql.motus, \"alltags\")) containing run lengths of 2 or 3. You will see that there are likely false positive detections at these sites, that were already eliminated by filtering. These additional detections provide further evidence that these sites experienced some radio noise during these particular months, resulting in some false positive detections. You may also be interested more generally in exploring which data have only short run lengths. For example, the following code shows the maximum run length at all sites by month (for those runs which havent been removed by filtering). df.alltags.sub %&gt;% mutate(month = month(ts)) %&gt;% group_by(recvDeployName, month) %&gt;% summarize(max.rl = max(runLen)) %&gt;% spread(key = month, value = max.rl) ## `summarise()` regrouping output by &#39;recvDeployName&#39; (override with `.groups` argument) ## # A tibble: 42 x 6 ## # Groups: recvDeployName [42] ## recvDeployName `4` `5` `8` `9` `10` ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Assateague State Park NA NA NA 6 NA ## 2 BennettMeadow NA NA NA NA 11 ## 3 BISE NA NA NA NA 6 ## 4 Bombay Hook NA NA NA 53 NA ## 5 Brier2 NA NA NA 29 NA ## 6 BSC HQ NA 21 NA NA NA ## 7 BULL NA NA NA 38 5 ## 8 Comeau (Marshalltown) NA NA NA 4 NA ## 9 CONY NA NA NA NA 7 ## 10 D&#39;Estimauville NA NA NA 40 NA ## # ... with 32 more rows Alternatively, you can produce a list of sites where the maximum run length of detections was never greater than (say) 4, which may sometimes (but not always!) indicate they are simply false detections. df.alltags.sub %&gt;% mutate(month = month(ts)) %&gt;% group_by(recvDeployName, month) %&gt;% summarize(max.rl = max(runLen)) %&gt;% filter(max.rl &lt; 5) %&gt;% spread(key = month, value = max.rl) ## `summarise()` regrouping output by &#39;recvDeployName&#39; (override with `.groups` argument) ## # A tibble: 3 x 4 ## # Groups: recvDeployName [3] ## recvDeployName `4` `9` `10` ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Comeau (Marshalltown) NA 4 NA ## 2 Old Cut 4 NA NA ## 3 TRUS NA NA 4 It is impossible to go through every possible issue that you may encounter here. Users are strongly encouraged to explore their data fully, and make reasoned decisions on which detections are unlikely or indeterminate. Through the rest of this chapter we will show you how to collect these runs, and apply them to your data prior to analysis. To start, if we decided that those detections in September were false positives, we could create a data frame that contains the motusTagIDs and runIDs for them. We could then re-create the plot with the newly filtered data. # Collect dubious detections df.block.1 &lt;- df.alltags.sub %&gt;% filter(month(ts) %in% 9, motusTagID %in% c(16035, 16037, 16039)) %&gt;% select(motusTagID, runID) %&gt;% distinct() # use the function we created earlier to make a new &#39;path&#39; data frame for plotting df.alltags.path &lt;- fun.getpath(filter(df.alltags.sub, motusTagID %in% c(16011, 16035, 16036, 16037, 16038, 16039), !(runID %in% df.block.1$runID))) ## `summarise()` regrouping output by &#39;motusTagID&#39;, &#39;runID&#39;, &#39;recvDeployName&#39;, &#39;ambigID&#39;, &#39;tagDepLon&#39;, &#39;tagDepLat&#39;, &#39;recvLat&#39; (override with `.groups` argument) ggplot(data = df.alltags.path, aes(x = ts.h, y = recvLat)) + theme_bw() + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) + geom_point() + geom_path() + facet_wrap(~ motusTagID, scales = &quot;free&quot;, ncol = 2) The reader is encouraged to explore the rest of the tags within this group, to determine if there are additional false positives. 5.7 Examining ambiguous detections Before we go further, we need to check to see if any tags have ambiguous detections. If there are, we will need to explore them, and create additional filters to remove detections from our database. Are any of your tags associated with ambiguous detections? The clarify() function in the motus R package provides a summary of ambiguities in the detections data. Each ambigID refers to a selection of detections that could belong to one or more (up to 6) motusTagIDs, which are listed in the id1 to id6 columns: clarify(sql.motus) ## ambigID numHits id1 fullID1 id2 ## 1 -56 5734 22867 SampleData#272.1:5.3@166.38(M.22867) 23316 ## 2 -106 279 17021 Selva#172:6.1@166.38(M.17021) 17357 ## 3 -114 86 22897 SampleData#303.1:5.3@166.38(M.22897) 24298 ## 4 -134 22749 22905 SampleData#301:5.3@166.38(M.22905) 23319 ## 5 -171 2074 22778 RBrownAMWO#308:5.3@166.38(M.22778) 22902 ## 6 -337 4 10811 Niles#152:6.1@166.38(M.10811) 16011 ## fullID2 id3 fullID3 ## 1 SampleData#272:5.3@166.38(M.23316) NA &lt;NA&gt; ## 2 SampleData#172:6.1@166.38(M.17357) NA &lt;NA&gt; ## 3 NEONICS#303:5.3@166.38(M.24298) NA &lt;NA&gt; ## 4 SampleData#301.1:5.3@166.38(M.23319) NA &lt;NA&gt; ## 5 SampleData#308.1:5.3@166.38(M.22902) 24303 NEONICS#308:5.3@166.38(M.24303) ## 6 SampleData#152:6.1@166.38(M.16011) NA &lt;NA&gt; ## id4 fullID4 id5 fullID5 id6 fullID6 motusTagID tsStart tsEnd ## 1 NA &lt;NA&gt; NA &lt;NA&gt; NA &lt;NA&gt; NA NA NA ## 2 NA &lt;NA&gt; NA &lt;NA&gt; NA &lt;NA&gt; NA NA NA ## 3 NA &lt;NA&gt; NA &lt;NA&gt; NA &lt;NA&gt; NA NA NA ## 4 NA &lt;NA&gt; NA &lt;NA&gt; NA &lt;NA&gt; NA NA NA ## 5 NA &lt;NA&gt; NA &lt;NA&gt; NA &lt;NA&gt; NA NA NA ## 6 NA &lt;NA&gt; NA &lt;NA&gt; NA &lt;NA&gt; NA NA NA We can see that there are six tags with ambiguous detections within this data set. Detections associated with five of the six ambigIDs could belong to one of two tags, and detections associated with one ambigID (-171) could belong to one of three tags. The fullID fields list the project names associated with the duplicate tags (e.g., SampleData, Selva, Niles), along with features of the tags (manufacturer tag ID, burst, and transmit frequency). Lets get a data frame of these, and do some plots to see where there may be issues. df.ambigTags &lt;- df.alltags.sub %&gt;% select(ambigID, motusTagID) %&gt;% filter(!is.na(ambigID)) %&gt;% distinct() Using our getpath() function, well create paths and then plot these detections. Well add some information to the plot, showing where (in time) the tags are actually ambiguous. We can then inspect the overall plots (or portions of them) to determine if we can contextually unambiguously assign a detection of an ambiguous tag to a single deployment. df.alltags.path &lt;- fun.getpath(filter(df.alltags.sub, motusTagID %in% df.ambigTags$motusTagID, tagProjID == proj.num)) %&gt;% # create a boolean variable for ambiguous detections: mutate(Ambiguous = !(is.na(ambigID))) ## `summarise()` regrouping output by &#39;motusTagID&#39;, &#39;runID&#39;, &#39;recvDeployName&#39;, &#39;ambigID&#39;, &#39;tagDepLon&#39;, &#39;tagDepLat&#39;, &#39;recvLat&#39; (override with `.groups` argument) # to put all ambiguous tags from the same project on the same plot together, we # need to create a new &#39;ambig tag&#39; variable we call &#39;newID. ambigTags.2 &lt;- filter(df.alltags.sub) %&gt;% select(ambigID, motusTagID) %&gt;% filter(!is.na(ambigID)) %&gt;% distinct() %&gt;% group_by(ambigID) %&gt;% summarize(newID = paste(unique(ambigID), toString(motusTagID), sep = &quot;: &quot;)) %&gt;% left_join(df.ambigTags, by = &quot;ambigID&quot;) ## `summarise()` ungrouping output (override with `.groups` argument) # and merge that with df.alltags.path df.alltags.path &lt;- left_join(df.alltags.path, ambigTags.2, by = &quot;motusTagID&quot;) %&gt;% arrange(ts.h) ggplot(data = df.alltags.path, aes(x = ts.h, y = recvLat, group = Ambiguous, colour = Ambiguous)) + theme_bw() + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) + geom_point() + geom_path() + facet_wrap(~ newID, scales = &quot;free&quot;, ncol = 2) Lets deal with the easy ones first. ambigID -337: motusTagIDs 10811 and 16011 df.alltags.sub %&gt;% filter(ambigID == -337) %&gt;% count(motusTagID, tagDeployStart, tagDeployEnd, tagDepLat, tagDepLon) ## motusTagID tagDeployStart tagDeployEnd tagDepLat tagDepLon n ## 1 10811 2014-10-28 07:00:00 2015-08-03 07:00:00 39.1140 -74.7142 4 ## 2 16011 2015-08-02 11:39:59 2015-12-17 11:39:59 51.4839 -80.4500 4 We can see from the plot that ambiguous tag -337 is ambiguous only at the beginning of the deployment. We can see from the summary of the tag deployment data that there were only 4 detections, at the exact latitude of deployment of tag 16011, and just before the non-ambiguous detections of motusTagID 16011. So the issue here is simply that the tail end of the deployment of tag 10811 slightly overlaps with the deployment of tag 16011. We can confidently claim these detections as belonging to motusTagID 16011, and remove the ambiguous detections assigned to the other tag. Well create another data frame to keep track of these runs. # we want the detections associated with the motusTagID that we want to # ultimately REMOVE from the data frame df.block.2 &lt;- df.alltags.sub %&gt;% filter(ambigID == -337, motusTagID == 10811) %&gt;% select(motusTagID, runID) %&gt;% distinct() ambigID -134: motusTagIDs 22905 and 23319 df.alltags.sub %&gt;% filter(ambigID == -134) %&gt;% count(motusTagID, tagDeployStart, tagDeployEnd, tagDepLat, tagDepLon, month(ts)) ## motusTagID tagDeployStart tagDeployEnd tagDepLat tagDepLon ## 1 22905 2016-10-01 16:00:00 2017-06-12 16:00:00 50.19278 -63.74528 ## 2 23319 2016-10-15 16:00:00 2017-06-26 16:00:00 50.19278 -63.74528 ## month(ts) n ## 1 10 22279 ## 2 10 22279 Here we have a similar situation, but one that is a bit more complex. Two identical tags were deployed at the same location, shortly after one another. Lets examine a simple plot. ggplot(data = filter(df.alltags.sub, motusTagID %in% c(22905, 23319)), aes(x = ts, y = sig, group = recvDeployName, colour = recvDeployName)) + geom_point() + theme_bw() + labs(x = &quot;Time&quot;, y = &quot;Signal strength&quot;) + facet_grid(recvLon ~ .) It appears that these are overlapping detections, at two sites in proximity to one another. Additional information from the field researchers may enable us to disentangle them, but it is not clear from the data. We will therefore remove all detections of this ambiguous tag from the database. # we want the detections associated with the motusTagID that we want to # ultimately REMOVE from the data frame df.block.3 &lt;- df.alltags.sub %&gt;% filter(ambigID == -134) %&gt;% select(motusTagID, runID) %&gt;% distinct() ambigID -171: motusTagIDs 22778, 22902 and 22403 The ambiguous detections for this tag, which occur in the Great Lakes region, could also belong to motusTagID 22778 from the RBrownAMWO project or motusTagID 24303 from the Neonics project. Lets take a closer look at these detections. First, find the deployment dates and locations for each tag. df.alltags.sub %&gt;% filter(ambigID == -171) %&gt;% filter(!is.na(tagDeployStart)) %&gt;% select(motusTagID, tagProjID, start = tagDeployStart, end = tagDeployEnd, lat = tagDepLat, lon = tagDepLon, species = speciesEN) %&gt;% distinct() %&gt;% arrange(start) %&gt;% collect() %&gt;% as.data.frame() ## motusTagID tagProjID start end lat ## 1 22902 176 2016-10-01 16:00:00 2017-06-12 16:00:00 50.19278 ## 2 22778 82 2016-10-21 00:00:00 2018-09-09 00:00:00 45.13535 ## 3 24303 146 2017-05-10 22:30:59 2017-06-30 22:30:59 42.60600 ## lon species ## 1 -63.74528 Red Knot ## 2 -67.29323 American Woodcock ## 3 -80.46900 White-crowned Sparrow And plot the ambiguous detections. df.ambig.171 &lt;- filter(df.alltags.sub, ambigID == -171) ggplot(data = df.ambig.171, aes(x = ts, y = sig, colour = as.factor(port))) + theme_bw() + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) + geom_point() + geom_smooth(method = &quot;loess&quot;, se = FALSE) + facet_wrap(as_date(ts) ~ recvDeployName, scales = &quot;free_x&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; We see that there are a large number of ambiguous detections on 10 May 2017 at Old Cut (Long Point, Lake Erie, Ontario), consistent with a bird hanging around. These are almost certainly detections of motusTagID 24303 which was deployed at Old Cut on 10 May 2017. Subsequent detections on the 18th of May are near Old Cut (Bird Studies Canada HQ, Port Rowan, Ontario), and then a location to the North of Old Cut (Hagersville, Ontario). These detections are consistent with a bird departing on migration. Note in particular the pattern in the latter two panels of increasing then decreasing signal strength which indicates a bird is flying through the beam of an antenna. These detections belong to another project, so we simply remove all detections of that ambiguous tag from our database. # we want the detections associated with the motusTagID that we want to # ultimately REMOVE from the data frame df.block.4 &lt;- df.alltags.sub %&gt;% filter(ambigID == -171) %&gt;% select(motusTagID, runID) %&gt;% distinct() ambigID -114: motusTagIDs 22897 and 24298 Next we look at the ambiguities for ambiguous tag -114. df.alltags.sub %&gt;% filter(ambigID == -114) %&gt;% filter(!is.na(tagDeployStart)) %&gt;% select(motusTagID, tagProjID, start = tagDeployStart, end = tagDeployEnd, lat = tagDepLat, lon = tagDepLon, species = speciesEN) %&gt;% distinct() %&gt;% arrange(start) %&gt;% collect() %&gt;% as.data.frame() ## motusTagID tagProjID start end lat ## 1 22897 176 2016-10-01 16:00:00 2017-06-12 16:00:00 50.19278 ## 2 24298 146 2017-05-10 03:00:00 2017-06-30 03:00:00 42.60690 ## lon species ## 1 -63.74528 Red Knot ## 2 -80.46900 White-crowned Sparrow We again subset these and plot them. An initial plot suggested that all of the detections are of a migratory flight, so we construct a somewhat different plot from the one above, that emphasizes this behaviour better. df.ambig.114 &lt;- df.alltags.sub %&gt;% filter(ambigID == -114) %&gt;% mutate(LatLonStationName = paste(recvLat, recvLon, recvDeployName, sep=&quot;: &quot;)) ggplot(data = df.ambig.114, aes(x = ts, y = sig, colour = LatLonStationName)) + geom_point() + theme_bw() Notice that the detections are consistent with a migratory departure from the Long Point area (Old Cut Field Station, Lake Erie, Ontario) about a week after the ambiguous tag 24298 was deployed at the same location. This again suggests that these ambiguous detections can be removed from our data because they belong to another project. df.block.5 &lt;- df.alltags.sub %&gt;% filter(ambigID == -114) %&gt;% select(motusTagID, runID) %&gt;% distinct() ambigID -106: motusTagIDs 17021 and 17357 These two tags pose an interesting problem. There is only a short period of overlap, between mid August 2015 and mid September. One individual is a Grey-cheeked Thrush, tagged in Colombia, the other a White-rumped Sandpiper, associated with the sample project. df.alltags.sub %&gt;% filter(ambigID == -106) %&gt;% filter(!is.na(tagDeployStart)) %&gt;% select(motusTagID, tagProjID, start = tagDeployStart, end = tagDeployEnd, lat = tagDepLat, lon = tagDepLon, species = speciesEN) %&gt;% distinct() %&gt;% arrange(start) %&gt;% collect() %&gt;% as.data.frame() ## motusTagID tagProjID start end lat ## 1 17021 57 2015-04-30 05:00:00 2015-09-14 05:00:00 11.12265 ## 2 17357 176 2015-08-11 07:20:00 2015-12-26 07:20:00 51.48390 ## lon species ## 1 -74.08735 Gray-cheeked Thrush ## 2 -80.45000 White-rumped Sandpiper We plot the ambiguous detections to examine the period of overlap. df.ambig.106 &lt;- filter(df.alltags.sub, ambigID == -106) ggplot(data = df.ambig.106, aes(x = ts, y = sig, colour = paste(recvLat, recvLon, recvDeployName, sep = &quot;: &quot;))) + theme_bw() + geom_point() + scale_colour_discrete(name = &quot;Lat/Lon and\\nStation Name&quot;) + facet_wrap(~ as_date(ts), scales = &quot;free_x&quot;) Both sets of detections are long run lengths, and look valid (increasing then decreasing signal strength). They are about a day apart, and so it is possible they represent two different birds, or the departure flight of the white-rumped sandpiper from its staging ground. Lets use the siteTrans() function (in the motus package, see section C.13) to examine the flight from Netitishi to MDR/Seal (in the Gulf of Maine) df.ambig.106 %&gt;% filter(motusTagID == 17021) %&gt;% # just pick one of the two ambiguous IDs siteTrans(latCoord = &quot;recvLat&quot;, lonCoord = &quot;recvLon&quot;) %&gt;% ungroup() %&gt;% filter(rate &lt; 60) %&gt;% # remove the simultaneous detections from Seal and MDR mutate(total.time = as.numeric(round(seconds_to_period(tot_ts)))) %&gt;% select(start = recvDeployName.x, end = recvDeployName.y, date = ts.x, `rate(m/s)` = rate, dist, total.time = total.time, bearing) ## # A tibble: 1 x 7 ## start end date `rate(m/s)` dist total.time bearing ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Netitishi_~ MDR_44,~ 2015-09-02 04:18:42 17.1 1.21e6 70879 128. These detections are &gt;1200 km distant from one another, but the flight speed (17 m/s) is consistent with a white-rumped Sandpiper. Given that the Gray-cheeked Thrush tag was near the end of its expected lifetime, we can reasonably claim these detections for our project, and remove the ambiguous detections associated with motusTagID 17021. df.block.6 &lt;- df.alltags.sub %&gt;% filter(ambigID == -106, motusTagID == 17021) %&gt;% select(motusTagID, runID) %&gt;% distinct() ambigID -56: motusTagIDs 22867 and 23316 These two tags were also both deployed by the same project. df.alltags.sub %&gt;% filter(ambigID == -56) %&gt;% filter(!is.na(tagDeployStart)) %&gt;% select(motusTagID, tagProjID, start = tagDeployStart, end = tagDeployEnd, lat = tagDepLat, lon = tagDepLon, species = speciesEN) %&gt;% distinct() %&gt;% arrange(start) %&gt;% collect() %&gt;% as.data.frame() ## motusTagID tagProjID start end lat ## 1 22867 176 2016-09-06 15:35:00 2017-05-18 15:35:00 51.79861 ## 2 23316 176 2016-10-02 16:00:00 2017-06-13 16:00:00 50.19278 ## lon species ## 1 -80.69139 Pectoral Sandpiper ## 2 -63.74528 Red Knot Tag 23316 was deployed by the James Bay Shorebird Project (sample project) about three weeks after tag 22867, which was deployed from a location far to the west. df.ambig.56 &lt;- df.alltags.sub %&gt;% filter(ambigID == -56) %&gt;% mutate(sig = ifelse(sig &gt; 0, sig * -1, sig)) ggplot(data = df.ambig.56, aes(x = recvLon, y = ts, colour = paste(recvLat, recvLon, recvDeployName, sep=&quot;: &quot;))) + theme_bw() + geom_point() + scale_colour_discrete(name=&quot;Lat/Lon and\\nStation Name&quot;) We can see from the plot that a tag is detected consistently near longitude -65, which is near the deployment location for motusTagID 23316 and after its deployment start date, it was also present at -65 during and after detections far to the west. Its likely all the detections at -65 belong to motusTagID 23316, but it is also clear that anything informative about this ambiguity occurs between about 9-11 October, so lets zoom in on that part of the data set. ts.begin &lt;- ymd_hms(&quot;2016-10-06 00:00:00&quot;) ts.end &lt;- ymd_hms(&quot;2016-10-12 23:00:00&quot;) ggplot(data = filter(df.ambig.56, ts &gt; ts.begin, ts &lt; ts.end), aes(x = ts, y = recvLon, colour = paste(recvLat, recvLon, recvDeployName, sep = &quot;: &quot;))) + theme_bw() + geom_point() + scale_colour_discrete(name = &quot;Lat/Lon and\\nStation Name&quot;) We can see that the ambiguous tag was detected consistently at Niapiskau and Grand Ile before and after the period when it was also detected to the north and west (at Washkaugou and Piskwamish) and then to the south (NBNJ, SHNJ, and CONY). We can look at this transition by filtering out the portion of the data not near Niapiskau, and again using the siteTrans function from the motus package. # other tag is a duplicate df.56.tmp &lt;- filter(df.ambig.56, !(recvLat == 50.2), motusTagID == 22867) siteTrans(df.56.tmp, latCoord = &quot;recvLat&quot;, lonCoord = &quot;recvLon&quot;) %&gt;% ungroup() %&gt;% filter(rate &lt; 60) %&gt;% # get rid of simultaneous detections mutate(total.time = as.numeric(round(seconds_to_period(tot_ts)))) %&gt;% select(start = recvDeployName.x, end = recvDeployName.y, date = ts.x, `rate(m/s)` = rate, dist, total.time = total.time, bearing) ## # A tibble: 2 x 7 ## start end date `rate(m/s)` dist total.time bearing ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Piskwamis~ Washkaug~ 2016-10-09 22:49:59 20.3 7.63e4 3767 137. ## 2 Washkaugo~ SHNJ_40.~ 2016-10-10 00:00:42 24.3 1.27e6 52386 157. The bird made a 14.5 hour flight between Washkaugou and SHNJ at a rate of 24 m/s, which is plausible. The researchers involved may have other data to support or refute the inference (e.g. an actual sighting of the Red Knot still in Niapiskau after this flight was recorded) but it seems likely that while one tag remained at sites around longitude -65, another tag made the above migratory flights. We can make another more detailed plot of signal strength to examine these potential migratory flights more closely: df.56.tmp &lt;- filter(df.alltags.sub, ambigID == -56, recvLon &lt; -70) ggplot(data = df.56.tmp, aes(x = ts, y = sig, colour = paste(recvLat, recvLon, recvDeployName, sep = &quot;: &quot;))) + theme_bw() + geom_point() + scale_colour_discrete(name = &quot;Lat/Lon and\\nStation Name&quot;) + facet_wrap(~ as_date(ts), scales = &quot;free_x&quot;) These look like typical fly-by patterns of increasing and then decreasing signal strength. This, coupled with overall detection patterns and knowledge of the species, leads us to believe that the ambiguous detections can be reasonably divided between the two individuals; one detected consistently around longitude -65 (23316), and the other migrating SW during the same period (22867). To address this problem, we need to create two filters - one that excludes ambiguous detections of tag 22867, and one that excludes some detections of 23316. In this instance, we can do this most easily by filtering on motusTagID and recvDeployName. # tag 23316 was only ever at &quot;Grand-Ile&quot;, &quot;Niapiskau&quot;, and tag 22867 was never # detected at those sites. So we exclude all detections not at &quot;Grand-Ile&quot;, # &quot;Niapiskau&quot; for motusTag 23316, and do the opposite for tag 22867. df.block.7 &lt;- df.alltags.sub %&gt;% filter(ambigID == -56, motusTagID == 23316, !(recvDeployName %in% c(&quot;Grand-Ile&quot;, &quot;Niapiskau&quot;))) %&gt;% select(motusTagID, runID) %&gt;% distinct() df.block.8 &lt;- df.alltags.sub %&gt;% filter(ambigID == -56, motusTagID == 22867, recvDeployName %in% c(&quot;Grand-Ile&quot;, &quot;Niapiskau&quot;)) %&gt;% select(motusTagID, runID) %&gt;% distinct() 5.8 Checking validity of run lengths of 2 or 3 At the beginning of this chapter, we dropped all detections with a run length of 2 or 3 or a run length of 4 in noisy conditions, because they are considered to have a high probability of being false positive. Now that weve cleaned the data, and are confident in the detections that remain, you might at this point decide to go back and take a closer look at those omitted detections. You could do this, for example, by re-running the various plots described in this chapter (begin with lat/lon by time plots), to see if any of those detections make sense in the context of where the true detections lie. It is up to the user to decide which detections are reasonable in terms of the biology and behaviour of each tagged individual. 5.9 Filtering the data 5.9.1 Filter and save to RDS To filter the data, we can omit rows in the df.block data frames from the original data using a anti_join(), which removes rows from x (df.alltags.sub) which are present in y (df.block). # combine our df.block data frames into a single dataframe df.block.all &lt;- bind_rows(df.block.0, df.block.2, df.block.3, df.block.4, df.block.5, df.block.6, df.block.7, df.block.8) df.alltags.sub &lt;- anti_join(df.alltags.sub, df.block.all, by = c(&quot;runID&quot;, &quot;motusTagID&quot;)) Now save the local data frame as an RDS file, for use in the next chapter. Recall from Section 3.6 that the RDS format preserves the R data structure, including time stamps. The other benefit of saving to RDS is that you have the output from a given workflow saved as a flat file, which you can access again with a simple readRDS statement. saveRDS(df.alltags.sub, file = &quot;./data/dfAlltagsSub.rds&quot;) And to read the data in again: df.alltags.sub &lt;- readRDS(&quot;./data/dfAlltagsSub.rds&quot;) 5.9.2 Save a custom filter in the motus database, and apply it to the data As an alternative to saving your data as an RDS file, the Motus R package offers functionalities to save your filters directly within your .motus file. Once they are saved in your database, you can do the type of anti_join() as above without having to rely on dataframes or an RDS file to store your data. To learn more about the functions available to work with Motus filters, refer to Appendix D for more details. # combine our df.block data frames into a single dataframe df.block.all &lt;- bind_rows(df.block.0, df.block.2, df.block.3, df.block.4, df.block.5, df.block.6, df.block.7, df.block.8) %&gt;% mutate(probability = 0) # create a new filter with name filtAmbigFalsePos and populate it with df.block.all tbl.filter &lt;- writeRunsFilter(sql.motus, &quot;filtAmbigFalsePos&quot;, df = df.block.all, delete = TRUE) ## Warning in createRunsFilter(src, filterName, motusProjID, update = FALSE): ## Warning: filter already exists. Use createRunsFilter function with update=TRUE ## if you want to update the properties (e.g. name) of the existing filter. ## Filter records saved # obtain a table object where the filtered records from tbl.filter.1 have been removed tbl.alltags.sub &lt;- anti_join(tbl.alltags, tbl.filter, by = c(&quot;runID&quot;, &quot;motusTagID&quot;)) "],["exploreData.html", "6 Exploring data with the Motus R package 6.1 Load required packages 6.2 Load data 6.3 Summarizing your data 6.4 Plotting your data 6.5 Mapping your data", " 6 Exploring data with the Motus R package This chapter was contributed by Tara L. Crewe, Zoe Crysler, and Philip Taylor. Once you have clarified any possible ambiguous tags, and removed false positives, you are ready to start analyzing your clean data set. This chapter will walk you through some simple procedures to start working with and visualizing the clean sample data set; you can modify these scripts to work with your own data. For a more in-depth R tutorial we strongly recommend working through R for Data Science by Garrett Grolemund and Hadley Wickham (http://r4ds.had.co.nz/). 6.1 Load required packages Follow the instructions in Chapter 2 to install the following packages before loading, if you havent already done so. library(motus) library(tidyverse) library(ggmap) library(lubridate) Sys.setenv(TZ = &quot;UTC&quot;) 6.2 Load data If you followed along with the the previous Chapter (Chapter 5) and are working with the cleaned df.alltags.sub file, you can skip this step and move to section 6.3. Otherwise, if you saved your data as an RDS file, you can load it using: df.alltags.sub &lt;- readRDS(&quot;./data/dfAlltagsSub.rds&quot;) # change dir to local directory Or, if youve applied a custom filter to your .motus file, you can load the previously downloaded sample motus data (see Chapter 3) and clean it now. Currently the main benefit of using the custom filter is that you apply the filter to the .motus file, which allows you more flexibility in applying dplyr functions to manage and filter the data (e.g., you can select different variables to include in the data than we included in the RDS file in Chapter 5). This approach also allows you to more readily integrate new data added to your database with the tagme function. Because we are selecting the same variables and filtering the same records, the following gives you the same dataset as the readRDS statement above: # load the .motus file (remember &#39;motus.sample&#39; is both username and password) proj.num &lt;- 176 sql.motus &lt;- tagme(proj.num, update = TRUE, dir = &quot;./data/&quot;) tbl.alltags &lt;- tbl(sql.motus, &quot;alltagsGPS&quot;) # obtain a table object of the filter tbl.filter &lt;- getRunsFilters(sql.motus, &quot;filtAmbigFalsePos&quot;) # filter and convert the table into a dataframe, with a few modications df.alltags.sub &lt;- left_join(tbl.alltags, tbl.filter, by = c(&quot;runID&quot;, &quot;motusTagID&quot;)) %&gt;% mutate(probability = ifelse(is.na(probability), 1, probability), recvLat = if_else((is.na(gpsLat)|gpsLat == 0|gpsLat == 999), recvDeployLat, gpsLat), recvLon = if_else((is.na(gpsLon)|gpsLon == 0|gpsLon == 999), recvDeployLon, gpsLon), recvAlt = if_else(is.na(gpsAlt), recvDeployAlt, gpsAlt)) %&gt;% filter(probability &gt; 0) %&gt;% select(-noise, -slop, -burstSlop, -done, -bootnum, -codeSet, -mfg, -nomFreq, -markerNumber, -markerType, -tagDepComments, -fullID, -deviceID, -recvDeployLat, -recvDeployLon, -recvDeployAlt, -speciesGroup, -gpsLat, -gpsLon, -recvAlt, -recvSiteName) %&gt;% collect() %&gt;% as.data.frame() %&gt;% mutate(ts = as_datetime(ts), # work with dates AFTER transforming to flat file tagDeployStart = as_datetime(tagDeployStart), tagDeployEnd = as_datetime(tagDeployEnd), recvDeployName = if_else(is.na(recvDeployName), paste(recvLat, recvLon, sep=&quot;:&quot;), recvDeployName)) Note that if your project is very large, you may want to convert only a portion of it to the dataframe, to avoid memory issues. Details on filtering the tbl prior to collecting as a dataframe are available in section 3.5.8. Here we do so by adding a filter to the above command, in this case, only creating a dataframe for motusTagID 16047, but you can decide how to best subset your data based on your need (e.g. by species or year): # create a subset for a single tag, to keep the dataframe small df.alltags.16047 &lt;- filter(df.alltags.sub, motusTagID == 16047) 6.3 Summarizing your data Here we will run through some basic commands, starting with the summary() function to view a selection of variables in a data frame: sql.motus %&gt;% tbl(&quot;alltags&quot;) %&gt;% select(ts, motusTagID, runLen, speciesEN, tagDepLat, tagDepLon, recvDeployLat, recvDeployLon) %&gt;% collect() %&gt;% summary() ## ts motusTagID runLen speciesEN ## Min. :1.438e+09 Min. :10811 Min. : 2.0 Length:108826 ## 1st Qu.:1.476e+09 1st Qu.:22897 1st Qu.: 30.0 Class :character ## Median :1.477e+09 Median :22905 Median : 122.0 Mode :character ## Mean :1.476e+09 Mean :22660 Mean : 355.9 ## 3rd Qu.:1.477e+09 3rd Qu.:23316 3rd Qu.: 404.0 ## Max. :1.498e+09 Max. :24303 Max. :2474.0 ## ## tagDepLat tagDepLon recvDeployLat recvDeployLon ## Min. :11.12 Min. :-80.69 Min. :-42.50 Min. :-143.68 ## 1st Qu.:50.19 1st Qu.:-63.75 1st Qu.: 50.20 1st Qu.: -63.75 ## Median :50.19 Median :-63.75 Median : 50.20 Median : -63.75 ## Mean :50.14 Mean :-65.77 Mean : 49.05 Mean : -65.64 ## 3rd Qu.:50.19 3rd Qu.:-63.75 3rd Qu.: 50.20 3rd Qu.: -63.75 ## Max. :51.80 Max. :-63.75 Max. : 62.89 Max. : -60.02 ## NA&#39;s :2025 NA&#39;s :2025 NA&#39;s :173 NA&#39;s :173 # same summary for the filtered sql data df.alltags.sub %&gt;% select(ts, motusTagID, runLen, speciesEN, tagDepLat, tagDepLon, recvLat, recvLon) %&gt;% summary() ## ts motusTagID runLen ## Min. :2015-08-03 06:37:11 Min. :16011 Min. : 4.0 ## 1st Qu.:2016-10-06 19:17:36 1st Qu.:22897 1st Qu.: 27.0 ## Median :2016-10-09 21:48:11 Median :22897 Median : 97.0 ## Mean :2016-09-05 10:37:42 Mean :22267 Mean : 235.1 ## 3rd Qu.:2016-10-19 10:37:42 3rd Qu.:22897 3rd Qu.: 287.0 ## Max. :2017-04-20 22:33:19 Max. :23316 Max. :1371.0 ## ## speciesEN tagDepLat tagDepLon recvLat ## Length:48133 Min. :50.19 Min. :-80.69 Min. :37.10 ## Class :character 1st Qu.:50.19 1st Qu.:-63.75 1st Qu.:50.20 ## Mode :character Median :50.19 Median :-63.75 Median :50.20 ## Mean :50.34 Mean :-65.56 Mean :50.05 ## 3rd Qu.:50.19 3rd Qu.:-63.75 3rd Qu.:50.20 ## Max. :51.80 Max. :-63.75 Max. :51.82 ## NA&#39;s :164 ## recvLon ## Min. :-80.69 ## 1st Qu.:-63.75 ## Median :-63.75 ## Mean :-65.26 ## 3rd Qu.:-63.75 ## Max. :-62.99 ## NA&#39;s :164 The dplyr package allows you to easily summarize data by group, manipulate variables, or create new variables based on your data. We can manipulate existing variables or create new ones with dplyrs mutate() function, here well convert ts to a POSIXct format, then make a new variable for year and day of year (doy). Well also remove the set of points with missing receiver latitude and longitudes. These may be useful in some contexts (for example if the approximate location of the receiver is known) but can cause warnings or errors when plotting. df.alltags.sub &lt;- df.alltags.sub %&gt;% mutate(ts = as_datetime(ts, tz = &quot;UTC&quot;), # convert ts to POSIXct format year = year(ts), # extract year from ts doy = yday(ts)) %&gt;% # extract numeric day of year from ts filter(!is.na(recvLat)) head(df.alltags.sub) ## hitID runID batchID ts tsCorrected sig sigsd freq freqsd ## 1 45107 8886 53 2015-10-26 11:19:49 1445858390 52 0 4 0 ## 2 45108 8886 53 2015-10-26 11:20:28 1445858429 54 0 4 0 ## 3 45109 8886 53 2015-10-26 11:21:17 1445858477 55 0 4 0 ## 4 45110 8886 53 2015-10-26 11:21:55 1445858516 52 0 4 0 ## 5 45111 8886 53 2015-10-26 11:22:44 1445858564 49 0 4 0 ## 6 199885 23305 64 2015-10-26 11:12:04 1445857924 33 0 4 0 ## motusTagID ambigID port runLen tagProjID mfgID tagType tagModel tagLifespan ## 1 16047 NA 3 5 176 378 ID NTQB-3-2 NA ## 2 16047 NA 3 5 176 378 ID NTQB-3-2 NA ## 3 16047 NA 3 5 176 378 ID NTQB-3-2 NA ## 4 16047 NA 3 5 176 378 ID NTQB-3-2 NA ## 5 16047 NA 3 5 176 378 ID NTQB-3-2 NA ## 6 16047 NA 1 11 176 378 ID NTQB-3-2 NA ## tagBI pulseLen tagDeployID speciesID tagDeployStart tagDeployEnd ## 1 9.6971 2.5 1839 4670 2015-09-10 18:00:00 2016-03-10 18:00:00 ## 2 9.6971 2.5 1839 4670 2015-09-10 18:00:00 2016-03-10 18:00:00 ## 3 9.6971 2.5 1839 4670 2015-09-10 18:00:00 2016-03-10 18:00:00 ## 4 9.6971 2.5 1839 4670 2015-09-10 18:00:00 2016-03-10 18:00:00 ## 5 9.6971 2.5 1839 4670 2015-09-10 18:00:00 2016-03-10 18:00:00 ## 6 9.6971 2.5 1839 4670 2015-09-10 18:00:00 2016-03-10 18:00:00 ## tagDepLat tagDepLon tagDepAlt tagDeployTest recvDeployID recv ## 1 51.4839 -80.45 NA NA 2510 Lotek-159 ## 2 51.4839 -80.45 NA NA 2510 Lotek-159 ## 3 51.4839 -80.45 NA NA 2510 Lotek-159 ## 4 51.4839 -80.45 NA NA 2510 Lotek-159 ## 5 51.4839 -80.45 NA NA 2510 Lotek-159 ## 6 51.4839 -80.45 NA NA 2512 Lotek-164 ## recvDeployName isRecvMobile recvProjID recvUtcOffset antType antBearing ## 1 Shelburne 0 74 NA yagi-9 127 ## 2 Shelburne 0 74 NA yagi-9 127 ## 3 Shelburne 0 74 NA yagi-9 127 ## 4 Shelburne 0 74 NA yagi-9 127 ## 5 Shelburne 0 74 NA yagi-9 127 ## 6 BennettMeadow 0 74 NA yagi-9 243 ## antHeight speciesEN speciesFR speciesSci tagProjName ## 1 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus SampleData ## 2 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus SampleData ## 3 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus SampleData ## 4 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus SampleData ## 5 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus SampleData ## 6 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus SampleData ## recvProjName gpsAlt filterID probability recvLat recvLon year doy ## 1 &lt;NA&gt; NA NA 1 42.60699 -72.71657 2015 299 ## 2 &lt;NA&gt; NA NA 1 42.60699 -72.71657 2015 299 ## 3 &lt;NA&gt; NA NA 1 42.60699 -72.71657 2015 299 ## 4 &lt;NA&gt; NA NA 1 42.60699 -72.71657 2015 299 ## 5 &lt;NA&gt; NA NA 1 42.60699 -72.71657 2015 299 ## 6 &lt;NA&gt; NA NA 1 42.68067 -72.47392 2015 299 We can also summarize information by group, in this case motusTagID, and apply various functions to these groups such as getting the total number of detections (n) for each tag, the number of receivers each tag was detected on, the first and last detection date, and the total number of days there was at least one detection: tagSummary &lt;- df.alltags.sub %&gt;% group_by(motusTagID) %&gt;% summarize(nDet = n(), nRecv = length(unique(recvDeployName)), tsMin = min(ts), tsMax = max(ts), totDay = length(unique(doy))) ## `summarise()` ungrouping output (override with `.groups` argument) head(tagSummary) ## # A tibble: 6 x 6 ## motusTagID nDet nRecv tsMin tsMax totDay ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dttm&gt; &lt;dttm&gt; &lt;int&gt; ## 1 16011 116 1 2015-08-03 06:37:11 2015-08-05 20:41:12 3 ## 2 16035 415 5 2015-08-14 17:53:49 2015-09-02 14:06:09 6 ## 3 16036 62 1 2015-08-17 21:56:44 2015-08-17 21:58:52 1 ## 4 16037 1278 3 2015-08-23 15:13:57 2015-09-08 18:37:16 14 ## 5 16038 70 1 2015-08-20 18:42:33 2015-08-22 22:19:37 3 ## 6 16039 1044 10 2015-08-23 02:28:45 2015-09-19 06:08:31 8 We can also group by multiple variables; applying the same function as above but now grouping by motusTagID and recvDeployName, we will get information for each tag detected on each receiver. Since we are grouping by recvDeployName, there will be by default only one recvDeployName in each group, thus the variable nRecv will be 1 for each row. This in not very informative, however we include this to help illustrate how grouping works: tagRecvSummary &lt;- df.alltags.sub %&gt;% group_by(motusTagID, recvDeployName) %&gt;% summarize(nDet = n(), nRecv = length(unique(recvDeployName)), tsMin = min(ts), tsMax = max(ts), totDay = length(unique(doy))) ## `summarise()` regrouping output by &#39;motusTagID&#39; (override with `.groups` argument) head(tagRecvSummary) ## # A tibble: 6 x 7 ## # Groups: motusTagID [2] ## motusTagID recvDeployName nDet nRecv tsMin tsMax ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dttm&gt; &lt;dttm&gt; ## 1 16011 North Bluff 116 1 2015-08-03 06:37:11 2015-08-05 20:41:12 ## 2 16035 Brier2 38 1 2015-09-02 14:03:19 2015-09-02 14:06:09 ## 3 16035 D&#39;Estimauville 32 1 2015-09-02 07:58:43 2015-09-02 08:04:24 ## 4 16035 Netitishi 274 1 2015-08-14 17:53:49 2015-09-01 21:35:32 ## 5 16035 Southwest Head 65 1 2015-09-02 13:06:13 2015-09-02 13:14:39 ## 6 16035 Swallowtail 6 1 2015-09-02 13:21:27 2015-09-02 13:22:22 ## # ... with 1 more variable: totDay &lt;int&gt; 6.4 Plotting your data Plotting your data is a powerful way to visualize broad and fine-scale detection patterns. This section will give you a brief introduction to plotting using ggplot2. For more in depth information on the uses of ggplot2, we recommend the Cookbook for R, and the Rstudio ggplot2 cheatsheet. To make coarse-scale plots with large files, we suggest first rounding the detection time to the nearest hour or day so that processing time is faster. Here we round detection times to the nearest hour, then make a basic plot of hourly detections by motusTagID: df.alltags.sub.2 &lt;- df.alltags.sub %&gt;% mutate(hour = as.POSIXct(round(ts, &quot;hour&quot;))) %&gt;% select(motusTagID, port, tagDeployStart, tagDepLat, tagDepLon, recvLat, recvLon, recvDeployName, antBearing, speciesEN, year, doy, hour) %&gt;% distinct() ggplot(data = df.alltags.sub.2, aes(x = hour, y = as.factor(motusTagID))) + theme_bw() + geom_point() + labs(x = &quot;Time (rounded to hour)&quot;, y = &quot;MotusTagID&quot;) Lets focus only on tags deployed in 2016, and we can colour the tags by species: ggplot(data = filter(df.alltags.sub.2, year(tagDeployStart) == 2016), aes(x = hour, y = as.factor(motusTagID), colour = speciesEN)) + theme_bw() + geom_point() + labs(x = &quot;Time (rounded to hour)&quot;, y = &quot;MotusTagID&quot;) + scale_colour_discrete(name = &quot;Species&quot;) We can see how tags moved latitudinally by first ordering by hour, and colouring by motusTagID: df.alltags.sub.2 &lt;- arrange(df.alltags.sub.2, hour) ggplot(data = filter(df.alltags.sub.2, year(tagDeployStart) == 2016), aes(x = hour, y = recvLat, col = as.factor(motusTagID), group = as.factor(motusTagID))) + theme_bw() + geom_point() + geom_path() + labs(x = &quot;Time (rounded to hour)&quot;, y = &quot;Receiver latitude&quot;) + scale_colour_discrete(name = &quot;MotusTagID&quot;) Now lets look at more detailed plots of signal variation. We use the full df.alltags.sub dataframe so that we can get signal strength for each detection of a specific tag. Lets examine fall 2016 detections of tag 22897 at Niapiskau; we facet the plot by deployment name, ordered by decreasing latitude: ggplot(data = filter(df.alltags.sub, motusTagID == 22897, recvDeployName == &quot;Niapiskau&quot;), aes(x = ts, y = sig)) + theme_bw() + geom_point() + labs(x = &quot;Time&quot;, y = &quot;Signal strength&quot;) + facet_grid(recvDeployName ~ .) We use the sunRiseSet() function available in the motus R package (see C.2) to get sunrise and sunset times for all detections. We then zoom in on a certain timeframe and add that information to the above plot by adding a geom_vline() statement to the code, which adds a yellow line for sunrise time, and a blue line for sunset time: # add sunrise and sunset times to the dataframe df.alltags.sub &lt;- sunRiseSet(df.alltags.sub, lat = &quot;recvLat&quot;, lon = &quot;recvLon&quot;) ggplot(data = filter(df.alltags.sub, motusTagID == 22897, ts &gt; ymd(&quot;2016-10-11&quot;), ts &lt; ymd(&quot;2016-10-17&quot;), recvDeployName == &quot;Niapiskau&quot;), aes(x = ts, y = sig)) + theme_bw() + geom_point() + labs(x = &quot;Time of year&quot;, y = &quot;Signal strength&quot;) + geom_vline(aes(xintercept = sunrise), col = &quot;orange&quot;) + geom_vline(aes(xintercept = sunset), col = &quot;blue&quot;) We can see that during this period, the tag was most often detected during the day, suggesting it may be actively foraging in this area during this time. The same plots can provide valuable movement information when the receivers are ordered geographically. We do this for motusTagID 16039: # We&#39;ll first order sitelat by latitude (for plots) df.alltags.sub &lt;- mutate(df.alltags.sub, recvDeployName = reorder(recvDeployName, recvLat)) ggplot(data = filter(df.alltags.sub, motusTagID == 16039, ts &lt; ymd(&quot;2015-10-01&quot;)), aes(x = ts, y = recvDeployName)) + theme_bw() + geom_point() + labs(x = &quot;Time of year&quot;, y = &quot;Receiver name (ordered by latitude)&quot;) We zoom in on a section of this plot and look at antenna bearings to see directional movement past stations: ggplot(data = filter(df.alltags.sub, motusTagID == 16039, ts &gt; ymd(&quot;2015-09-14&quot;), ts &lt; ymd(&quot;2015-10-01&quot;)), aes(x = ts, y = sig, col = as.factor(antBearing))) + theme_bw() + geom_point() + labs(x = &quot;Time of day&quot;, y = &quot;Signal strength&quot;) + scale_color_discrete(name = &quot;Antenna bearing&quot;) + facet_grid(recvDeployName ~ .) This plot shows the typical flyby pattern of a migrating animal, with signal strength increasing and then decreasing as the tag moves through the beams of the antennas. 6.5 Mapping your data To generate maps of tag paths, we will once again use summarized data so we can work with a much smaller database for faster processing. Here well summarize detections by day. As we did in Chapter 5, we create a simple function to summarize the data, since we will likely want to do this type of summary over and over again. # Simplify the data by summarizing by the runID # If you want to summarize at a finer (or coarser) scale, you can also create # other groups. The simplest alternative is a rounded timestamp variable; for # example by using mutate(ts.h = plyr::round_any(ts, 3600) function call. Other # options are to just use date (e.g date = as_date(ts)) fun.getpath &lt;- function(df) { df %&gt;% filter(tagProjID == proj.num, # keep only tags registered to the sample project !is.na(recvLat) | !(recvLat == 0)) %&gt;% group_by(motusTagID, runID, recvDeployName, ambigID, tagDepLon, tagDepLat, recvLat, recvLon) %&gt;% summarize(max.runLen = max(runLen), ts.h = mean(ts)) %&gt;% arrange(motusTagID, ts.h) %&gt;% data.frame() } # end of function call df.alltags.path &lt;- fun.getpath(df.alltags.sub) ## `summarise()` regrouping output by &#39;motusTagID&#39;, &#39;runID&#39;, &#39;recvDeployName&#39;, &#39;ambigID&#39;, &#39;tagDepLon&#39;, &#39;tagDepLat&#39;, &#39;recvLat&#39; (override with `.groups` argument) df.alltags.sub.path &lt;- df.alltags.sub %&gt;% filter(tagProjID == proj.num) %&gt;% # only tags registered to project arrange(motusTagID, ts) %&gt;% # order by time stamp for each tag mutate(date = as_date(ts)) %&gt;% # create date variable group_by(motusTagID, date, recvDeployName, ambigID, tagDepLon, tagDepLat, recvLat, recvLon) df.alltags.path &lt;- fun.getpath(df.alltags.sub.path) ## `summarise()` regrouping output by &#39;motusTagID&#39;, &#39;runID&#39;, &#39;recvDeployName&#39;, &#39;ambigID&#39;, &#39;tagDepLon&#39;, &#39;tagDepLat&#39;, &#39;recvLat&#39; (override with `.groups` argument) 6.5.1 Mapping with the ggmap package Mapping with ggmap can be a fast way to view flight paths and allows you to select from multiple base layers. There are several ways to use the ggmap package. One is with Google Maps, which, as of October 16, 2018, requires a Google Maps API key (see Appendix B section B.4 for more details). An alternative method is to use an open source of map tiles, such as Stamen Map tiles, which do not require an API key. The following example uses Stamen Map tiles. The first step is to create a map with a specified map are, maptype (terrain, toner, or watercolor, among others), and level of zoom (integer for zoom 3-21, 3 being continent level, 10 being city-scale. For stamen maps this represents the level of detail you want). We then add points for receivers and lines connecting consecutive detections by motusTagID. We can also add points for all receivers that were active during a certain time period if we have already downloaded all metadata. gmap &lt;- get_stamenmap(bbox = c(left = -90, right = -57, bottom = 35, top = 55), maptype = &quot;terrain-background&quot;, # select maptype zoom = 6) # zoom, must be a whole number # just use the tags that we have examined carefully and filtered (in the # previous chapter) df.tmp &lt;- df.alltags.path %&gt;% filter(motusTagID %in% c(16011, 16035, 16036, 16037, 16038, 16039)) %&gt;% arrange(ts.h) %&gt;% # arange by hour as.data.frame() ggmap(gmap) + theme_bw() + geom_point(data = df.tmp, aes(x = recvLon, y = recvLat), shape = 21, colour = &quot;black&quot;, fill = &quot;yellow&quot;) + geom_path(data = df.tmp, aes(x = recvLon, y = recvLat, group = motusTagID, col = as.factor(motusTagID))) + scale_color_discrete(name = &quot;MotusTagID&quot;) We make the same plot, with additional points for all receivers that were active during a specified time (concentrating on our area of interest): # get receiver metadata tbl.recvDeps &lt;- tbl(sql.motus, &quot;recvDeps&quot;) df.recvDeps &lt;- tbl.recvDeps %&gt;% collect() %&gt;% as.data.frame() %&gt;% mutate(tsStart = as_datetime(tsStart, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;), tsEnd = as_datetime(tsEnd, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;), # for deployments with no end dates, make an end date a year from now tsEnd = if_else(is.na(tsEnd), as.POSIXct(format(Sys.time(), &quot;%Y-%m-%d %H:%M:%S&quot;)) + dyears(1), tsEnd), tsEnd = as.POSIXct(tsEnd, tz = &quot;UTC&quot;, origin = &quot;1970-01-01&quot;)) # get running intervals for all receiver deployments siteOp &lt;- with(df.recvDeps, interval(tsStart, tsEnd)) # set the date range you&#39;re interested in dateRange &lt;- interval(as.POSIXct(&quot;2015-08-01&quot;), as.POSIXct(&quot;2016-01-01&quot;)) # create new variable &quot;active&quot; which will be set to TRUE if the receiver was # active at some point during your specified date range, and FALSE if not df.recvDeps$active &lt;- int_overlaps(siteOp, dateRange) # create map with receivers active during specified date range as red, and # receivers with detections as yellow ggmap(gmap) + theme_bw() + geom_point(data = subset(df.recvDeps, active == TRUE), ggplot2::aes(x = longitude, y = latitude), shape = 21, colour = &quot;black&quot;, fill = &quot;red&quot;) + geom_point(data = df.tmp, aes(x = recvLon, y = recvLat), shape = 21, colour = &quot;black&quot;, fill = &quot;yellow&quot;) + geom_path(data = df.tmp, aes(x = recvLon, y = recvLat, group = motusTagID, col = as.factor(motusTagID))) + scale_color_discrete(name = &quot;MotusTagID&quot;) 6.5.2 Creating simple outline maps We load the base maps. na.lakes &lt;- map_data(map = &quot;lakes&quot;) na.lakes &lt;- mutate(na.lakes, long = long- 360) # Include all of the Americas to begin na.map &lt;- map_data(map = &quot;world2&quot;) %&gt;% filter(region %in% c(&quot;Canada&quot;, &quot;USA&quot;)) %&gt;% mutate(long = long - 360) Then, to map the paths, we set the x-axis and y-axis limits based on the location of receivers with detections. Depending on your data, these might need to be modified to encompass the deployment location of the tags, if tags were not deployed near towers with detections. We then use ggplot to plot the map and tag paths. Here we use the Mercator projection and are colouring the paths by motusTagID, including a point for where the tag was deployed: # set limits to map based on locations of detections, ensuring they include the # deployment locations xmin &lt;- min(df.tmp$recvLon, na.rm = TRUE) - 2 xmax &lt;- max(df.tmp$recvLon, na.rm = TRUE) + 2 ymin &lt;- min(df.tmp$recvLat, na.rm = TRUE) - 1 ymax &lt;- max(df.tmp$recvLat, na.rm = TRUE) + 1 # map ggplot(data = na.lakes, aes(x = long, y = lat))+ theme_bw() + geom_polygon(data = na.map, aes(x = long, y = lat, group = group), colour = &quot;grey&quot;, fill = &quot;grey98&quot;) + geom_polygon(aes(group = group), colour = &quot;grey&quot;, fill = &quot;white&quot;) + coord_map(projection = &quot;mercator&quot;, xlim = c(xmin, xmax), ylim = c(ymin, ymax)) + labs(x = &quot;&quot;, y = &quot;&quot;) + geom_path(data = df.tmp, aes(x = recvLon, y = recvLat, group = as.factor(motusTagID), colour = as.factor(motusTagID))) + geom_point(data = df.tmp, aes(x = tagDepLon, y = tagDepLat), colour = &quot;black&quot;, shape = 4) + scale_colour_discrete(&quot;motusTagID&quot;) The functions above provide examples of how you can begin exploring your data and are by no means exhaustive. The next chapter will cover some common errors and troubleshooting you may encounter while trying to download and use the .motus sql files. "],["vanishingBearings.html", "7 Vanishing bearings 7.1 Things to be aware of 7.2 Estimate vanishing bearings: step-by-step 7.3 Literature Cited", " 7 Vanishing bearings This chapter was contributed by Ana Morales and Tara Crewe, using data collected by Morbey et al. (2017) (see 1.3), and with financial support from a NSERC CREATE Environmental Innovation Program internship awarded to A.M. through McGill University, with partner Bird Studies Canada (T.C.). Estimating the orientation of a bird departing a stopover site may be key in certain migration studies. In the context of an automated radio-telemetry study, the estimated departure direction is often called a vanishing bearing (SjÃ¶berg and Nilsson 2015). The ability to use characteristics of signal detections to estimate the vanishing bearing of a migrating animal is particularly important at sites where additional stations are not available to capture the flight path following departure from a stopover site. SjÃ¶berg and Nilsson (2015) calculated vanishing bearings using ordinary circular statistics to estimate the mean of the receiving antenna bearings over the last 5-10 minutes of detections, with the bearing of each detection weighted by strength of the signal. In other words, every signal detected was a vector pointing in the direction of the receiving antenna, with the length of the vector represented by signal strength. A stronger signal would therefore get a longer vector and a higher weight than a weaker signal. This chapter will show you how to estimate the departure bearing of your tagged birds using SjÃ¶berg and Nilssons method. You can modify these scripts to work with your own data, or use the sample data provided. Before you begin, there are a few assumptions and potential weaknesses you should be aware of: 7.1 Things to be aware of This method assumes that the tagged animal is departing from the general location of the receiving station, and moving radially away from the station. It is really important to note that this method WILL NOT WORK unless this assumption is met. Because tagged individuals most likely arent departing from the exact location of the receiver station, they should be considered coarse estimates of departure orientation. The deviation between estimated vanishing bearings and actual departure orientation that results from birds departing from locations removed from a station is called parallax error. Parallax error can be minimized by analyzing only departures in which we can be confident from signal strength characteristics that an individual departed from fairly close to the receiving station. Using radar data, SjÃ¶berg and Nilsson (2015) estimated parallax error to be +- 10 degrees when the bird departed close to the station. Manual telemetry can be used to determine the precise location of an individual during stopover. In the absence of known location, a good way to know if an individual departed from the general location of a receiving station is to look at the pattern of detections pre- and post-departure. If an individual departs from near a station, the data will show clear detection patterns by at least two different antennas prior to and during departure. The following plots use data collected for tagged warblers in spring 2014 and 2015 by Morbey et al. (2017), and show examples of a) a tag with a clear departure, and b) a tag that does not show a clear departure; more information on the data can be found in sections 1.3 and 7.2.2 below: Good departure: you can see that the bird stayed in the vicinity of the Old Cut station during stopover, as shown by increased signal variation during the day, and decreased signal variation during the night. On the night of departure, the tag shows the usual decrease in activity at night, followed by an increase of activity at around 02:30 am as it departs; the tag stops being detected by the Old Cuts station soon after, and is then detected by other nearby receivers during its departure flight: Unclear departure: this bird was not detected by the Old Cut station for quite a while, and was only detected during an apparent flyover; signal characteristics do not support a clear departure from the station. In this case, we do not know how far the bird was from the station during the flyby. We caution against using examples like this to estimate vanishing bearings: The more closely spaced the antennas on a station, the greater the resolution to estimate an accurate vanishing bearing. At the Old Cut field station, three antennas were spaced 120 degrees apart in 2014, and 90 degrees apart in 2015 (facing approximately east, north and west). In both years we calculated a coarse departure bearing using the mean of station-to-station bearings for warblers that were detected by multiple stations during departure. This gave us a known departure direction. We then calculated vanishing bearings to compare. The following is a figure showing the estimated coarse and vanishing bearing for a warbler departing northwards from Old Cut in spring 2014, when the 3 antennas were spaced 120 degrees apart. The red line represents the estimated vanishing bearing of tag ID 277. The blue line represents the average coarse bearing based on detections from other stations (red points): In the example below, estimated coarse and vanishing bearings are shown for a warbler departing to the north in spring 2015, when Old Cuts antennas were spaced 90 degrees apart. We can see that the estimated vanishing bearing is pretty close to the coarse bearing estimate. Overall, mean deviation between coarse and vanishing bearings was higher in 2014 (n = 14 departures) when antennas were spaced 120 degrees apart, than in 2015 (n = 12 departures) when antennas were spaced 90 degrees apart: This suggests that stations with closer spaced antennas yield more accurate vanishing bearings. If the estimation of vanishing bearings is a primary goal of your research, we suggest spacing antennas 60 degrees apart, as in SjÃ¶berg and Nilsson (2015). For receivers with negative signal strength values, weights need to be normalized When calculating weighted circular means, negative weights cannot be used. We therefore recommend normalizing the signal strength values by subtracting the minimum signal strength, and dividing by the difference between min and max signal strength, i.e., using r sig.norm = (sig - min(sig))/(max(sig)-min(sig)), eval = FALSE. Further, we suggest using the min and max signal strength at a station, across all data collected by the station, so that the full range of potential signal strength values are used in the normalization equation. We found that normalizing using the min and max signal strength for an individual departure can result in spurious vanishing bearing estimates if the range in signal strengths observed was not large. Using the full range of signal strength values in a project database will avoid this. 7.2 Estimate vanishing bearings: step-by-step We now walk through how to estimate vanishing bearings in the following steps: Load required R packages Load the data Select individuals that show clear departures from the station Get departure time for each individual Estimate vanishing bearings Plot vanishing bearing on a map 7.2.1 Load the required packages Follow the instructions in Chapter 2 to install the following packages before loading, if they are not already installed. library(circular) library(tidyverse) library(motus) library(ggplot2) library(jpeg) library(ggmap) #Make sure working on UTC Sys.setenv(TZ = &quot;UTC&quot;) 7.2.2 Load the sample data The sample data used in this chapter includes the detections of three Magnolia Warblers that were tagged at the Old Cut field research station of the Long Point Bird Observatory in Ontario, Canada, by Morbey et al. (2017). The warblers were tagged and released in spring 2015. The sample data are included in the motusData R package as the vanishBearing.rda file. In order to access these data, you will need to first install the motusData package following the instructions in section 2, prior to running the code in this chapter: # load the motusData package, which contains the sample data for this chapter library(motusData) # Load the sample data we provided from 3 individual warblers departing Old Cut # during the Spring of 2015. # We also do a couple manipulations here, to reorder the levels of the # recvSiteName factor, and order the data by ts. df.vanish &lt;- vanishBearing %&gt;% mutate(recvSiteName = reorder(recvSiteName, recvLat), motusTagID = as.factor(as.character(motusTagID))) %&gt;% # order sites by latitude arrange(ts) # arrange by ts 7.2.3 Select individuals that show clear departure detections First, we subset the data to the individuals that showed clear departures from the stopover site of interest. In fact, the sample data only includes three departures of birds we know have clear departures from Old Cut, but we show this step here regardless! By selecting only clear departures, we make sure that the bird departed from nearby the station, minimizing the potential for parallax error. We look for clear departures by first plotting latitude against time. In this case, we can see the birds departing north past several stations: ggplot(data = df.vanish, aes(x = ts, y = recvLat, colour = as.factor(recvSiteName))) + geom_point(pch = 21) + facet_wrap(~ motusTagID, scales = &quot;free&quot;, ncol = 1) + theme_bw() We also make sure that the bird was being detected by several antennas at once during departure; if detections are on only one antenna, the vanishing bearing will simply be the direction of the lone antenna with detections. We plot signal strength by time for a subset of the data, to show the last few hours of detections of the bird at Old Cut. Lets try this with tag # 16823 from our sample data: ggplot(data = filter(df.vanish, motusTagID == 16823, ts &gt; &quot;2015-05-30 00:00:00&quot;), aes(x = ts, y = sig, colour = as.factor(port))) + theme_bw() + geom_point(pch = 21) + facet_grid(recvSiteName ~ .) We can see the typical detection pattern of a bird departing from a site, shown by a decrease in movement (beginning to roost) at around 00:25 UTC, followed by an increase in activity and departure from the site later in the night after 03:00 UTC. Soon after leaving the site, it gets detected by five other stations further north. Because this bird was detected before and during departure, we can assume it has departed from somewhat close to the Old Cut station. With your own data, look at plots like these for each of your tagged individuals, and for the purpose of vanishing bearings, remove any individuals that dont have a clear departure. 7.2.4 Obtain departure times In order to estimate vanishing bearings based on the signal strength of departure detections, we must first determine the approximate time that the bird started its departure flight. For now, the best way to do this is by manually going through each set of detections from each bird and obtaining the approximate time by plotting the time versus signal strength. Continuing with tag 16823, lets find the departure time. ggplot(data = filter(df.vanish, motusTagID == 16823), aes(x = ts, y = sig, colour= as.factor(antBearing))) + theme_bw() + geom_point() + facet_grid(recvSiteName ~ .) We can see the complete set of detections of tag 16823 for Old Cut and other stations this bird was detected at post-departure. We then subset the plot in order to zoom in to the last few minutes of detections at Old Cut, which is where the bird is departing from. By zooming in we can find the exact departure time. ggplot(data = filter(df.vanish, motusTagID == 16823, ts &gt; &quot;2015-05-30 03:03:00&quot;, ts &lt; &quot;2015-05-30 03:10:00&quot;), aes(x = ts, y = sig, colour= as.factor(antBearing))) + theme_bw() + geom_point() In this case, we can see an increase in signal strength beginning at about 3:04 for the 90 and 260 degree antennas at Old Cut. These reach a peak in signal strength at about 3:04:59, after which signal strength declines. This suggests that the bird was likely south of the station when it began its departure - signal strength increased and peaked as it passed through the antenna beams, and then declined again as the bird moved away (north) from the Old Cut station. We choose the peak signal strength, i.e., 3:04:59 as the departure time for this bird, to exclude those detections where the bird was likely moving towards the station; we would not want the approaching station signals to contribute to the vanishing bearing, because it assumes the bird is moving radially away from the station. We create a dataframe with the departure times of each bird and their motusTagIDs, to use later for data filtering. We add departure times for the other two birds in the sample dataset; if you are keen, you can try the plots above on tags 16897 and 16791 to see how we came up with those departure times: ## create dataframe and assign column names dep.16823 &lt;- as.data.frame(cbind(16823, &quot;2015-05-30 03:04:59&quot;)) ## create dataframes for the other two tags: dep.16867 &lt;- as.data.frame(cbind(16867, &quot;2015-05-29 01:56:00&quot;)) dep.16791 &lt;- as.data.frame(cbind(16791, &quot;2015-05-08 02:41:40&quot;)) ## put them all together df.departTime &lt;- rbind(dep.16823, dep.16867, dep.16791) names(df.departTime) &lt;- c(&quot;motusTagID&quot;, &quot;ts_depart&quot;) ## convert time to posixCT using Lubridate functionality df.departTime &lt;- mutate(df.departTime, ts_depart = ymd_hms(ts_depart)) df.departTime ## motusTagID ts_depart ## 1 16823 2015-05-30 03:04:59 ## 2 16867 2015-05-29 01:56:00 ## 3 16791 2015-05-08 02:41:40 ## optionally, save to .RDS file to preserve time structure (you could save to ## .csv, but time structure will not be preserved) not run here: # saveRDS(df.departTime, file = &quot;./data/departureTimes.RDS&quot;) 7.2.5 Calculate vanishing bearings for individuals with departure times. Now, we subset our data to one individual to calculate its vanishing bearing. We will continue with the same individual, motusTagID 16823, using all detections after and including our specified departure time: Now that we have only the post-departure detections for the bird we are interested in, we calculate its vanishing bearing. First, we normalize the signal strengths, as discussed above, using the minimum and maximum observed signal strength across all data collected by the receiver. If there are differences in the range of signal strengths detected by antennas on a receiver, you might want to instead normalize by antenna. We do not have access to the entire database with the sample data, but we know the minimum and maximum signal strengths detected at the Old Cut stations are -78.0691 and -17.8707, respectively. We then calculate a weighted mean of departure angle across the entire departure period using the circular function. The numbers -78.0691 and -17.8707 are the minimum and maximum signal strength values for the Old Cut station. If using your own data, make sure you instead use the min and max signal strength for your station (using the full stationss data, not only from the subset of the tags you are analyzing). ## Merge sample data with departure times, subset data, and calculate vanishing bearing ## Note that we use the recvSiteName to specify the departure station of ## interest. Depending on whether the station has moved or changed names with ## deployments, recvDeployID might be more appropriate. depart.station &lt;- &quot;Old Cut&quot; min.sig &lt;- -78.0691 # normally max/min sig comes from the complete raw data for a station max.sig &lt;- -17.8707 # in this case, right join should drop any individuals that don&#39;t have departure # times in df.departTime df.vanishBearing &lt;- right_join(df.vanish, df.departTime, by = &quot;motusTagID&quot;) %&gt;% filter(ts &gt;= ts_depart, recvSiteName == depart.station) %&gt;% distinct() %&gt;% mutate(sig.norm = (sig - (min.sig))/((max.sig)-(min.sig)), circ.bear = circular(antBearing, type = c(&quot;angles&quot;), units = c(&quot;degrees&quot;), rotation = c(&quot;clock&quot;))) %&gt;% group_by(motusTagID, recvSiteName, recvLat, recvLon) %&gt;% summarise(vanish.bearing = weighted.mean(circ.bear, sig.norm, na.rm = FALSE, control.circular = list(type = &quot;angles&quot;, units = &quot;degrees&quot;, template = &quot;none&quot;, rotation = &quot;clock&quot;)), minutes.used = as.duration(min(ts) %--% max(ts))) %&gt;% as.data.frame() The resulting df.vanish dataframe contains the motusTagID, the vanishing bearing of the tag, the time in seconds/minutes used to estimate the bearing, and the receivers name and coordinates. We can make a circular plot with points for the individual vanishing bearings and an arrow for the mean bearing as follows: # if you have many bearings/points, can use stack = TRUE plot.circular(df.vanishBearing$vanish.bearing, zero = pi/2) arrows.circular(mean(df.vanishBearing$vanish.bearing), zero = pi/2) 7.2.6 Plot the vanishing bearings on a map Mapping your vanishing bearing(s) with ggmap can also be a great way to visualize the departure direction of your bird(s). Here we use Stamen maps to show the stations and orientations of antennas that detected the bird during departure, along with the orientation of the vanishing bearing. For information on using ggmap to create Google Maps, see Appendix B in section B.4. First, pick a tag to map: tagID &lt;- 16823 Then, create a map with a specified map centre, maptype (terrain, roadmap, satellite, or hybrid), and level of zoom (integer for zoom 3-21, 3 being continent level, 10 being city-scale). We add a yellow point for the stations with detections, yellow lines to represent antenna bearings with detections, and a red line for the vanishing bearing: ## First we obtain a map of our location of interest, in this case Old Cut map.OC &lt;- get_stamenmap(bbox = c(left = -80.6, right = -80.2, bottom = 42.5, top = 42.75), maptype = &quot;terrain-background&quot;, zoom = 12, color = &quot;color&quot;) ## Do the following to make a scale bar bb &lt;- attr(map.OC,&quot;bb&quot;) sbar &lt;- data.frame(lon.start = c(bb$ll.lon + 0.1*(bb$ur.lon - bb$ll.lon)), lon.end = c(bb$ll.lon + 0.25*(bb$ur.lon - bb$ll.lon)), lat.start = c(bb$ll.lat + 0.1*(bb$ur.lat - bb$ll.lat)), lat.end = c(bb$ll.lat + 0.1*(bb$ur.lat - bb$ll.lat))) sbar$distance &lt;- geosphere::distVincentyEllipsoid(c(sbar$lon.start,sbar$lat.start), c(sbar$lon.end,sbar$lat.end)) scalebar.length &lt;- 10 sbar$lon.end &lt;- sbar$lon.start + ((sbar$lon.end-sbar$lon.start)/sbar$distance)*scalebar.length*1000 ptspermm &lt;- 2.83464567 # need this because geom_text uses mm, and themes use pts. ## To map antenna bearings: ## Create a station dataframe with antenna bearings for all antennas with ## detections for the tag of interest df.stations &lt;- df.vanish %&gt;% filter(motusTagID == tagID) %&gt;% select(recvSiteName, antBearing, port, recvLon, recvLat) %&gt;% distinct() # determines length of the vectors for antenna bearings and vanishing bearing lines arr.sc &lt;- 0.03 rad &lt;- function(x) {x * pi/180} ## Now we make the map ggmap(map.OC) + geom_point(data = df.stations, aes(x = recvLon, y = recvLat), size = 1, colour = &quot;goldenrod&quot;) + # Add antenna bearings geom_segment(data = df.stations, aes(x = recvLon, xend = recvLon + (sin(rad(antBearing))*arr.sc), y = recvLat, yend = recvLat + (cos(rad(antBearing))*arr.sc)), colour = &quot;goldenrod&quot;) + # add vanishing bearings geom_segment(data = filter(df.vanishBearing, motusTagID == tagID), aes(x = recvLon, xend = recvLon + (sin(rad(vanish.bearing))*arr.sc), y = recvLat, yend = recvLat + (cos(rad(vanish.bearing))*arr.sc), colour = motusTagID)) + # Add scale bar geom_segment(data = sbar, aes(x = lon.start, xend = lon.end, y = lat.start, yend = lat.end), col = &quot;black&quot;, arrow = arrow(angle = 90, length = unit(0.1, &quot;cm&quot;), ends = &quot;both&quot;, type = &quot;open&quot;)) + geom_text(data = sbar, aes(x = (lon.start + lon.end)/2, y = lat.start + 0.025*(bb$ur.lat - bb$ll.lat), label = paste(format(scalebar.length), &#39;km&#39;)), hjust = 0.5, vjust = 0, size = 8/ptspermm, col = &quot;black&quot;) + labs(x = &quot;Longitude&quot;, y = &quot;Latitude&quot;) Lengths of the yellow and red lines do not represent antenna range or exact path of the bird. For this departure, we have detections on two other stations which corroborate the vanishing bearing. If desired, you can print the map to file as follows: tiff(file = paste(tagID, &quot;vanishBearing.tiff&quot;, sep=&quot;&quot;)) print(out.map) dev.off() 7.3 Literature Cited Morbey, Y.E., K.A. Jonasson, J.E. Deakin, A.T. Beauchamp, and C.G. Guglielmo. 2017. Studies of migratory birds and bats in southern Ontario, 2014-2017 (Projects #20 and #50). Data accessed from the Motus Wildlife Tracking System. Bird Studies Canada. Available: http://www.motus-wts.org. Accessed: May 1, 2018. SjÃ¶berg, S., and C. Nilsson. 2015. Nocturnal migratory songbirds adjust their travelling direction aloft: evidence from a radiotelemetry and radar study. Biology Letters 11:20150337. "],["advancedModelling.html", "8 Advanced modelling and analysis", " 8 Advanced modelling and analysis Numerous investigators have been developing more advanced tools for analyzing movement and behavioural data using Motus such as triangulation, position error and probability of detection, state-space movement modelling, and calculation of tag life histories (stopover duration, movement between subsequent sites, etc.). Aspects of some of these processes have been touched on in previous chapters. For investigators wishing to delve more into these subjects in more detail see: Baldwin, Justin W., Katie Leap, John T. Finn, and Jennifer R. Smetzer. Bayesian State-Space Models Reveal Unobserved off-Shore Nocturnal Migration from Motus Data. Ecological Modelling 386 (October 24, 2018): 3846. Researchers propose new biologically informed Bayesian state-space models for animal movement in JAGS that include informed assumptions about behaviour. Building from the bsam package in R a simple localization routine predicts bird location and spatial uncertainty. Baldwin, Justin. Modelling Bird Migration with Motus Data and Bayesian State-Space Models. University of Massachusetts Amherst, 2017. New biologically informed Bayesian state-space models are proposed for animal movements in JAGS that include informed assumptions about behaviour. The models are evaluated using a simulation study, and are then applied by employing a localization routine on a Motus data set to estimate unobserved locations and behaviours. Janaswamy, Ramakrishna, Pamela H. Loring, and James D. McLaren. A State Space Technique for Wildlife Position Estimation Using Non-Simultaneous Signal Strength Measurements. ArXiv.org, May 28, 2018. Combining a movement model to ensure biologically-consistent trajectories in three-dimensions, and an observation model to account for the effect of range, altitude, and bearing angle on the received signal strength, this novel state-space technique can estimate the location of airborne movements of VHF tags within the Motus array. As more advanced analysis and modelling tools become available they will be posted here. We strongly encourage participants to offer sample scripts and functions that can be integrated into this book. "],["falsePositives.html", "9 A tool to identify probable false positive detections 9.1 Introduction 9.2 Step 1  Classification of detections 9.3 Step 2  Identification of potential diagnostic parameters 9.4 Step 3  Prediction of the probability of being a false positive", " 9 A tool to identify probable false positive detections This chapter was contributed by Bianca Michalik, Amie MacDonald, and Philip Taylor. 9.1 Introduction As outlined in Chapter 5, there are several factors that might lead to false detections of your tags in your datasets. One type of these false detections are so called false positives, which can arise from other sources of electromagnetic pulses in the surroundings of receiving antennas. False positives are liberally allowed for during automated tag filtering at Motus to minimize the risk of missing any real detections. Therefore, we generally recommend you use the tools provided in section 5.3 to validate your data and to decide individually if a detection is valid in a biological context. However, this approach can be quite time consuming, especially when you are fortunate enough to have deployed lots of tags and consequently, you have a huge dataset. Furthermore, it can sometimes be critical to formulate exactly the conditions under which you might have excluded a detection from your further analyses if you did this by visual inspection of diagnostic plots. The goal of this chapter is to provide a tool to automatically predict the probability of a detection of being a false positive. The concept of our approach is quite simple: first, we want to use a subset of detection data from a solid a priori classification of detections either being good or bad. In the second step, we want to identify potential diagnostic physical parameters provided in the Motus alltags table (please see Appendix A for a detailed description of variables) to characterize the quality of a detection. Third, we run a logistic regression model with these parameters in order to predict the probability of each detection being a bad detection for all of your detection data. Finally, you can use the probability estimates provided from the model to define a threshold for filtering your data. Of course, it is generally necessary to re-evaluate the outcome of this process in a biological context. While this chapter primarily applies to detection of Lotek nanotags, detections from Cellular Tracking Technologies (CTT) PowerTags and LifeTags are also subject to false detections. Because the properties and the processing of the data are quite distinct, the topic of false detections in CTT tags will be covered in a different chapter at a later time. However, some of the principles explained here will apply to both types of tags, particularly the idea that longer, uninterrupted sequences of bursts matching the expected burst period will have a higher probability of being true detections. 9.2 Step 1  Classification of detections False positives resulting from random radio noise are often characterized by three simultaneously occurring features. First, the run lengths of these false detections are typically quite short. A run is a series of consecutive bursts of a given tag detected by the same antenna at the same receiver. Short run lengths mean that only a few recorded consecutive bursts are identified to match a specific tag. This feature arises from simple probability statistics: in a series of random pulses it is more likely to find the specific signal pattern of a tag only by chance if that pattern is short, which is usually the case in most of the tags registered with Motus. The detection probability of a deployed tag also depends on its burst interval meaning that longer burst intervals have a lower probability of being detected. Tags with long burst intervals thus tend to be recorded less often as the animal moves out of the beam of the recording antenna. Tags with short burst intervals, in turn, tend to be recorded with a longer run length, therefore bearing higher probabilities of being a false positive with a long run length. The second common feature of false detections is that within a run a lot of bursts are missed. During the process of automated tag filtering up to 60 bursts can be missed without the run being terminated for the identified tag. This makes biological sense as the detection probability of a tag deployed on a moving animal also depends on the structure and type of the landscape, the orientation of the antenna of the tag as well as on the distance and height the animal is moving relative to the recording antenna. If the animal drops in height, vanishes behind a structure or if it quickly turns its body axis, recordings of the tag can be interrupted, i.e. bursts can be missed. Recordings with a very high amount of missed bursts, however, might be less trustworthy. The third feature is that the time intervals of the recorded bursts might not properly match the time intervals as specified by the manufacturer and recorded during tag registration. For technical reasons, there is a certain offset allowed for during automated tag filtering at Motus (+/-4 ms), indicated in the alltags variable slop (see Appendix A for detailed explanation of variables). The variable burstSlop is the signed time offset of a recorded burst relative to its expected position in the recorded time sequence based on the tag registration burst interval which allows for bursts to be missed. If you calculate measured burst intervals between two subsequently recorded bursts of the same tag, i.e. ignoring missed bursts, they sometimes deviate widely from the burst interval as specified by the manufacturer and tag registration. These deviations can arise from accumulations of time offsets which would otherwise be neglected if missed bursts were accounted for. This means, small burstSlops sometimes might suggest better recordings of a tag than they really are. As pointed out, none of the three common features of false positives described above can alone describe the quality of a detection. We thus want to use all three of them to classify our detection dataset a priori into good and bad detections. # set system environment time zone to GMT Sys.setenv(tz=&quot;GMT&quot;) # load required packages library(motus) library(rms) library(ggplot2) library(dplyr) library(lubridate) # set base theme for plots theme_set(theme_bw(base_size = 18)) ### download sample data from James Bay Shorebird Project #176 # note: if you haven&#39;t downloaded sample dataset before, use &#39;new = T&#39; # specify &#39;dir =&#39; to save elsewhere than working directory db &lt;- tagme(176, new = F, update = F, forceMeta = F, dir = &quot;./data/&quot;) t &lt;- tbl(db, &quot;alltags&quot;) df &lt;- t %&gt;% select(hitID, runID, ts, sig, sigsd, noise, freq, freqsd, slop, burstSlop, # select variables motusTagID, port, runLen, tagModel, tagBI, tagDeployID, deviceID, recvDeployID, recvDeployLat, recvDeployLon, recv, recvSiteName) %&gt;% arrange(motusTagID, ts) %&gt;% # order data frame collect %&gt;% as.data.frame %&gt;% # convert into flat data frame mutate(ts = as.POSIXct(ts, origin=&quot;1970-01-01 00:00:00&quot;, tz=&quot;GMT&quot;)) %&gt;% # convert ts into readable format distinct() rm(t) # find duplicated runIDs (duplicates in ts, motusTagID, port, recv) # note, there are no duplicates in the sample dataset! # runsDup &lt;- df %&gt;% # filter(duplicated(cbind(ts, motusTagID, port, recv))==T) %&gt;% # select(runID) # # filter data (remove runs with duplicates) # df &lt;- df %&gt;% filter(!(runID %in% runsDup$runID)) # # rm(runsDup) Since we want to consider each detection within its recorded time frame, we calculate features 2 and 3 for each run individually. ##### Step 1 - Classification of detections ### calculate features 2 and 3 for each run runFeat &lt;- df %&gt;% group_by(runID) %&gt;% mutate(duration = as.numeric(difftime(max(ts), min(ts), units=&quot;s&quot;)), nPred = ceiling(duration/tagBI), # expected number of bursts in run if none are missed nMiss = nPred - runLen, # number of bursts missed in run propMiss = nMiss/nPred, # feature 2 - proportion of bursts missed in run meanBI = mean(as.numeric(diff(ts))), # mean observed burst interval based on all intervals between sequential bursts in a run deltaMeanBI = meanBI - tagBI) %&gt;% # feature 3 - difference between observed mean burst interval and expected burst interval based from manufacturer/tag registration select(runID, motusTagID, port, runLen, tagModel, tagBI, recv, recvSiteName, recvDeployLat, recvDeployLon, duration, nPred, nMiss, propMiss, meanBI, deltaMeanBI) %&gt;% filter(duplicated(runID)==F) %&gt;% ungroup() Now, we can classify our dataset of runs into the a priori categories good, bad and unassigned. We use a simple if-else statement and arbitrarily defined threshold values for each of the three features. Of course, threshold setting is up to you. We recommend a conservative classification of good runs having less than 25% of the bursts missed or the deviation between the recorded mean burst interval and the tag burst interval should be smaller than the tag burst interval itself. Bad runs are those recorded with run lengths smaller 4 or more than 75% of the bursts missed or the deviation between the recorded mean burst interval is more than 3 times the tag burst interval. ### assign category for goodness of detection (run) # filter by propMiss &gt;= 0.75, deltaMeanBI &gt;= 3*tagBI, runLen &lt; 4 runFeat$category &lt;- ifelse(abs(runFeat$propMiss) &gt; 0.75 | runFeat$deltaMeanBI &gt; 3 * runFeat$tagBI | runFeat$runLen &lt; 4, &quot;bad&quot;, ifelse(abs(runFeat$propMiss) &lt; 0.25 | runFeat$deltaMeanBI &lt; runFeat$tagBI, &quot;good&quot;, &quot;unassigned&quot;)) To validate your threshold classification, you can make frequency distribution plots for each of the three features for a priori categories good, bad, and unassigned. Note, zoom into x axes by yourself for better visibility. # some diagnostic plots plotdata &lt;- data.frame(group = rep(c(&quot;runLen&quot;, &quot;propMiss&quot;, &quot;deltaMeanBI&quot;), each = nrow(runFeat)), value = c(runFeat$runLen, runFeat$propMiss, runFeat$deltaMeanBI), category = c(rep(runFeat$category, 3)), stringsAsFactors = F) #%&gt;% #filter(category != &quot;unassigned&quot;) # uncomment the %&gt;% filter() statement to ignore the &#39;unassigned&#39; p1 &lt;- ggplot(data = plotdata, aes(abs(value), group = category, colour = category)) + geom_density() + facet_wrap(~group, scales = &quot;free&quot;) rm(plotdata) p1 9.3 Step 2  Identification of potential diagnostic parameters The Motus alltags table provides some physical parameters, such as sigsd, noise, freqsd, slop, burstSlop (see Appendix A for detailed explanation of variables). We can calculate the mean values of each parameter for each run and check graphically if it can be used to describe the quality of the recorded run. ##### Step 2 - Identification of potential diagnostic parameters ### calculate run mean values for # &#39;sigsd&#39;, &#39;noise&#39;, &#39;freqsd&#39;, &#39;slop&#39;, &#39;burstSlop&#39; runTemp &lt;- df %&gt;% group_by(runID) %&gt;% mutate(meanTs = mean(ts), meanSigSD = mean(sigsd), meanNoise = mean(noise), meanFreqSD = mean(freqsd), meanSlop = mean(slop), meanBurstSlop = mean(burstSlop)) %&gt;% select(runID, meanTs, meanSigSD, meanNoise, meanFreqSD, meanSlop, meanBurstSlop) %&gt;% filter(duplicated(runID)==F) %&gt;% ungroup() runFeat &lt;- merge(runFeat, runTemp, by = &quot;runID&quot;) rm(runTemp) # plot variables (visual inspection of informative content) plotdata &lt;- data.frame(group = rep(c(&quot;meanSigSD&quot;, &quot;meanNoise&quot;, &quot;meanFreqSD&quot;, &quot;meanSlop&quot;, &quot;meanBurstSlop&quot;), each = nrow(runFeat)), value = c(runFeat$meanSigSD, runFeat$meanNoise, runFeat$meanFreqSD, runFeat$meanSlop, runFeat$meanBurstSlop), category = c(rep(runFeat$category, 5)), stringsAsFactors = F) #%&gt;% #filter(category != &quot;unassigned&quot;) # uncomment the %&gt;% filter() statement to ignore the &#39;unassigned&#39; p2 &lt;- ggplot(data = plotdata, aes(abs(value), group = category, colour = category)) + geom_density() + facet_wrap(~group, scales = &quot;free&quot;) rm(plotdata) p2 There are, of course, other factors that can help to validate the detection. We want to pick two of them, noisiness and continuity, and create additional variables to describe these factors. Noisiness is quite difficult to characterize, but it can be stated that at times with many recordings at a given receiver, there is a lot of noise. We can use the activity table to identify the number of runs and their lengths for each antenna of each receiver recorded per hour. We can get a more complete picture of noisiness using the activity table because it includes numbers of runs across all projects, not just our own. We can also calculate proportion of short run lengths in runs per receiver hour and link the data from the activity table back to the runs in the alltags table via the runs table by calculating the hourBin for each runID. This allows us to connect the information on noise in the activity table back to our detection data. In addition, there might be a propensity for some tags to be recorded with short run lengths, i.e. detections resulting from noise. We can therefore calculate for each tag a variable for the overall proportion of short run lengths. # get activity table a &lt;- tbl(db, &quot;activity&quot;) adf &lt;- a %&gt;% collect %&gt;% as.data.frame # convert into flat data frame rm(a) # get runs table r &lt;- tbl(db, &quot;runs&quot;) rdf &lt;- r %&gt;% collect %&gt;% as.data.frame %&gt;% mutate(hourBin = floor(tsBegin/3600)) # calculate hourBin for each run rm(r) # join runs and activity tables to get hourly values on runs/recv for each runID radf &lt;- left_join(rdf, adf, by = c(&quot;batchIDbegin&quot; = &quot;batchID&quot;, &quot;ant&quot;, &quot;hourBin&quot;)) # join with detection data df &lt;- left_join(df, radf %&gt;% select(runID, numRuns, numHits, run2, run3), by = &quot;runID&quot;) ### calculate &#39;noise&#39; variables with values from activity table runTemp &lt;- df %&gt;% mutate(propRS = (run2 + run3)/numRuns) %&gt;% # proportion of short runs per receiver hour group_by(motusTagID) %&gt;% mutate(tagPropRS = length(unique(runID[runLen&lt;4]))/length(unique(runID))) %&gt;% # tags proportion of short runs group_by(runID) %&gt;% select(runID, numRuns, propRS, tagPropRS) %&gt;% filter(duplicated(runID)==F) %&gt;% ungroup() runFeat &lt;- merge(runFeat, runTemp, by = &quot;runID&quot;) rm(runTemp) # plot variables plotdata &lt;- data.frame(group = rep(c(&quot;numRuns&quot;, &quot;propRS&quot;, &quot;tagPropRS&quot;), each = nrow(runFeat)), value = c(runFeat$numRuns, runFeat$propRS, runFeat$tagPropRS), category = c(rep(runFeat$category, 3)), stringsAsFactors = F) #%&gt;% #filter(category != &quot;unassigned&quot;) # uncomment the %&gt;% filter() statement to ignore the unassigned p3 &lt;- ggplot(data = plotdata, aes(abs(value), group = category, colour = category)) + geom_density() + facet_wrap(~group, scales = &quot;free&quot;) rm(plotdata) p3 The other factor that might bear some importance and potential for diagnostics is continuity. This means that recordings assigned to match a certain tag may be more trustworthy if other recordings assigned to the same tag happen in some time window at the same or another antenna of the same receiver station. We thus calculate the number of runs and the number of recording antenna ports assigned to the same tag within 25 minutes of the mean time stamp of the given run. ### calculate &#39;continuity&#39; variables runTemp &lt;- df %&gt;% group_by(runID) %&gt;% mutate(meanTs = mean(ts)) %&gt;% group_by(motusTagID, recv) %&gt;% mutate(nContRuns = length(unique(runID[ts &lt;= meanTs + 25*60 | ts &gt;= meanTs - 25*60])), nPorts = length(unique(port[ts &lt;= meanTs + 25*60 | ts &gt;= meanTs - 25*60]))) %&gt;% group_by(runID) %&gt;% select(runID, nContRuns, nPorts) %&gt;% filter(duplicated(runID)==F) %&gt;% ungroup() runFeat &lt;- merge(runFeat, runTemp, by = &quot;runID&quot;) rm(runTemp) We can check the importance of these new variables graphically again. # plot variables plotdata &lt;- data.frame(group = rep(c(&quot;nContRuns&quot;, &quot;nPorts&quot;), each = nrow(runFeat)), value = c(runFeat$nContRuns, runFeat$nPorts), category = c(rep(runFeat$category, 2)), stringsAsFactors = F) #%&gt;% #filter(category != &quot;unassigned&quot;) # uncomment the %&gt;% filter() statement to ignore the &#39;unassigned&#39; p4 &lt;- ggplot(data = plotdata, aes(abs(value), group = category, colour = category)) + geom_density() + facet_wrap(~group, scales = &quot;free&quot;) rm(plotdata) p4 9.4 Step 3  Prediction of the probability of being a false positive From the plots produced above, we can examine which variables we would like to include in our logistic regression model to predict the probability of a given run being a false positive. An additional factor we might use is tag model. Depending on the antenna of the tag, the specified burst intervals or the transmitted power of the tag, different tag types might bear different detection probabilities and consequently, different probabilities of resulting in false detections. This only makes sense, however, if different tag types are used, or if different tag properties were assigned to different tag types. To better match these to your data, you can use the date-bin of tag registration or create your own variable. The modelling approach is quite simple: first, confine your created dataset to data for either category good or bad and transform the category into a binary variable. Make sure you have assigned 1 to bad and 0 to good in order to predict the probability of being a bad detection! Note the unassigned category is ignored here as we now want to predict the probabilities for these data. Second, run a binomial generalized linear model over the variables you have selected based on the diagnostic plots you have made before and store the results into another variable. You can also calculate some goodness of fit parameters to check the predictive power of your model fit. Finally, you can use the stored model outcome to predict the estimated probability of being a false positive for all runs in your detection data. Note that our example model includes all variables mentioned above, but we recommend you to carefully select powerful variables that might best represent the characteristics of your own data. You may also want to explore other potential variables that we do not include in this example. ##### Step 3 - Prediction of the probability of being a false positive modeldata &lt;- runFeat %&gt;% filter(category != &quot;unassigned&quot;) %&gt;% mutate(category = as.numeric(ifelse(category == &quot;good&quot;, 0, 1))) # basic model M &lt;- glm(category ~ meanSigSD + meanNoise + meanFreqSD + meanSlop + meanBurstSlop + numRuns + propRS + tagPropRS + nContRuns + nPorts, data = modeldata, family = binomial()) summary(M) ## ## Call: ## glm(formula = category ~ meanSigSD + meanNoise + meanFreqSD + ## meanSlop + meanBurstSlop + numRuns + propRS + tagPropRS + ## nContRuns + nPorts, family = binomial(), data = modeldata) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.67085 -0.89046 0.02365 0.94677 2.28095 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -5.248e+00 8.463e-01 -6.202 5.59e-10 *** ## meanSigSD -6.627e-03 3.306e-03 -2.005 0.04500 * ## meanNoise -4.412e-02 9.099e-03 -4.849 1.24e-06 *** ## meanFreqSD 6.430e+00 2.117e+00 3.037 0.00239 ** ## meanSlop 8.265e+02 1.525e+02 5.419 5.98e-08 *** ## meanBurstSlop -6.526e+01 3.130e+01 -2.085 0.03704 * ## numRuns 4.883e-04 3.595e-04 1.358 0.17433 ## propRS 3.702e+00 2.169e-01 17.065 &lt; 2e-16 *** ## tagPropRS 1.494e+00 5.009e-01 2.983 0.00286 ** ## nContRuns 7.711e-04 1.396e-04 5.523 3.32e-08 *** ## nPorts -2.552e-01 9.593e-02 -2.661 0.00780 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 4253.4 on 3112 degrees of freedom ## Residual deviance: 3013.1 on 3102 degrees of freedom ## (4 observations deleted due to missingness) ## AIC: 3035.1 ## ## Number of Fisher Scoring iterations: 8 # goodness of fit parameters MRS &lt;- lrm(category ~ meanSigSD + meanNoise + meanFreqSD + meanSlop + meanBurstSlop + numRuns + propRS + tagPropRS + nContRuns + nPorts, data = modeldata) MRS$stats[10] # Nagelkerke&#39;s pseudo R^2 ## R2 ## 0.4411341 rm(modeldata) # predict probability of being a &#39;bad&#39; run runFeat$probBad &lt;- predict(M, runFeat, &quot;response&quot;) You can now plot the probability for each of the categories you have defined in step 1 to visually check the validity of your predictions. Ideally, runs of the category good should have resulted in low probability estimates, whereas runs of the category bad should have resulted in high probability estimates. There should, however, also be some overlap meaning there should be some runs previously assigned as bad with low probability estimates. Nevertheless, the two good and bad curves should be clearly separated. # plot predicted values (graphical inspection of goodness of fit) p5 &lt;- ggplot(data = runFeat, aes(probBad, group = category, colour = category)) + geom_density() + xlab(&quot;estimate of probability of being a &#39;bad&#39; run&quot;) p5 You could also use this graph to define your own threshold probability to filter false positives from your data. Make sure not to filter single detections (i.e. by hitID), but to exclude all detections within a run that match your filter criterion for your dataset, i.e. to filter by runID. We generally recommend that afterward you use the tools described in section 5.3 to check individually if a detection or run you have excluded by your individual threshold settings may still be valid in a biological sense, or if additional detections should be excluded. ### set individual threshold and filter detection data by run # find runIDs with probBad &lt; 0.8 runsKeep &lt;- runFeat %&gt;% filter(probBad &lt; 0.8 &amp; duplicated(runID)==F) %&gt;% select(runID) %&gt;% pull() # filter detection data df &lt;- df %&gt;% filter(runID %in% runsKeep) rm(runsKeep) # add threshold to plot of predicted values p5 + geom_vline(xintercept = 0.8, linetype = &quot;dashed&quot;) Note: We used the three characteristics runLen, propMiss, and deltaMeanBI when assigning the a priori classification of detections for the sample dataset (project 176), but these characteristics may not be as appropriate for other datasets. There are, of course, other features of false positives and you are invited to create your own set of characteristics for your data. We highly recommend you examine your own data carefully and think critically about how you classify your detection data. This tool is designed to help you detect false positives and speed processing of large datasets, but it is not a one-size-fits-all solutiona careful examination of your dataset and carefully considered selection of classification criteria and predictor variables is absolutely necessary. For example, you might consider classifying bad detections as those where over 85% of detections per hour are short runs or where a receiver records more than 100 runs per hour (i.e. a noisy sitesimilar to how the motusFilter and the filterByActivity function work), and good detections as those where fewer than 50% of detections per hour are short runs. In this case you would be using some of the noise variables calculated below as classification features, so you must exclude them as predictor variables. Instead, you could consider some of the features we used in this example to classify the detections (runLen, propMiss, and meanDeltaBI), as potential predictor variables. "],["appendixA.html", "A Appendix - alltags and alltagsGPS structure", " A Appendix - alltags and alltagsGPS structure The following variables are included in alltags and alltagsGPS view in the SQLite file (note that the final three gps related fields are only available in alltagsGPS). Field Description hitID unique Motus ID for this tag detection runID unique Motus ID for the run this detection belongs to batchID unique Motus ID for the processing batch this detection came from ts timestamp, in seconds since 1 Jan, 1970 UTC; precision: 0.1 ms (SG); 2.5 ms (Lotek). sig signal strength in native units; for SG: dB (max) (logarithmic, 0 = max possible, -10 = 0.1 * max, etc.); for Lotek: raw value (0255) sigsd std. dev. in signal strength among pulses in this burst. SG Only; NA for Lotek noise estimate of background radio noise when tag detected, in dB (max) for SG; NA for Lotek freq frequency offset from antenna listening frequency, in kHz for SG only; NA for Lotek freqsd std. dev. of freq offset among pulses in this burst, in kHz. Values larger than 0.1 kHz suggest a bogus detection. SG only; NA for Lotek. slop total absolute difference (milliseconds) in inter-pulse intervals for this burst between registration and detection. SG only; NA for Lotek burstSlop signed difference (seconds) between detection and registration burst intervals. This is always 0 for the first burst in a run (see posInRun) done logical: is run finished? motusTagID Motus tag ID - unique to each individual tag registered ambigID ambiguous ID assigned to ambiguous tags port the port number that the detection occurred on runLen number of tag bursts in the current run; constant for all records having the same runID bootnum boot session of receiver for SG; NA for Lotek tagProjectID ID of the project that manages this tag. mfgID manufacturer ID tagType codeSet for coded tags, the name of the codeset (e.g. Lotek-3) mfg tag manufacturer tagModel manufacturers model name for a tag (e.g. NTQB-3-2) tagLifespan estimated lifespan of tag (days) nomFreq nominal tag frequency (MOTUS: Nominal frequency receiver was tuned to, in Mhz. This really only applies to SG, where we usually tune 4 kHz below the nominal tag frequency. So in that case, antFreq = 166.376 while nomFreq = 166.380 tagBI burst interval of tag, in seconds (e.g., 5.8984) pulseLen tag pulse length (milliseconds), if applicable. This value is only assigned based on the sample recording of the tag. tagDeployID Motus tag deployment ID speciesID unique numeric Motus ID (integer) for the species on which the tag was deployed markerNumber number for any additional marker placed on organism (e.g., bird band #) markerType type of additional marker (e.g. metal band) tagDeployStart tag deployment start date tagDeployEnd tag deployment end date tagDeployLat latitude of tag deployment, in decimal degrees N - negative values for Southern hemisphere tagDeployLon longitude of tag deployment, in decimal degrees E - negative values for Western hemisphere tagDeployAlt altitude of tag deployment, in meters ASL tagDepComments additional comments or unclassified metadata for tag (often in JSON format) fullID full tag ID as PROJECT#MFGID:BI@NOMFREQ. Not necessarily unique over time. See motusTagID for a unique tag deviceID Motus device ID associated with the receiver serial number recvDeployID Receiver deployment ID recvDeployLat latitude of receiver deployment, in decimal degrees N - negative values for Southern hemisphere recvDeployLon longitude of receiver deployment, in decimal degrees E - negative values for Western hemisphere recvDeployAlt altitude of receiver deployment, in meters ASL recv serial number of the receiver; e.g., SG-1234BBBK5678 or Lotek-12345 recvDeployName name assigned to the receiver deployment by the project manager recvSiteName name assigned to a site by the project manager (e.g. location name). The same label can be used for multiple deployments. isRecvMobile logical; whether the sensor is deployed on a mobile platform (eg. a ship) recvProjID unique (numeric) ID of the project that deployed this receiver (e.g., 8) antType character; antenna type, e.g. 9-element Yagi, Omni antBearing numeric; compass direction antenna main axis is pointing at (degrees clockwise from local magnetic North 0-360) antHeight numeric; height (meters) of antenna main axis above ground speciesEN species English (common) name speciesFR species French (common) name speciesSci species scientific name speciesGroup species group, e.g., BIRDS, BATS tagProjName short label of project that deployed the tag, e.g., HolbSESA recvProjName short label of project that deployed the receiver e.g., HolbSESA gpsLat latitude of receiver GPS location at time of writing the hourly detections file (degrees North) gpsLon longitude of receiver GPS location at time of writing the hourly detections file (degrees East) gpsAlt altitude of receiver GPS at time of writing the hourly detections file (meters) "],["appendixB.html", "B Appendix - Troubleshooting B.1 General Problems B.2 Logging out of motus B.3 Resume data download B.4 Google Maps B.5 Common problems and solutions:", " B Appendix - Troubleshooting As a first step, always ensure you are using the latest version of the motus package (see Appendix C.1), and you have all required packages installed, loaded, and up to date (see Chapter 2). While attempting to download data with the motus package, you may encounter errors, many of which are likely due to an interrupted connection. Always ensure you are connected to the internet when using the tagme() function with update = TRUE. Most issues can be solved by either logging out of the motus package, or by restarting R and resuming the download using tagme(). If errors persist and you are unable to download your data, the server may be temporarily offline. Please contact Motus with any concerns at motus@birdscanada.org. B.1 General Problems Many, many, problems arise from conflicts between R packages which may be out of date. If you have a problem that you cant seem to resolve, try the following steps in order (stopping when the problem goes away): Update motus and packages that motus depends on. (You may first need to install the remotes package). Re-start R remotes::update_packages(&quot;motus&quot;) Update all your packages. Re-start R remotes::update_packages() Update R https://cran.r-project.org/. (You may have to reinstall packages) B.2 Logging out of motus motusLogout() B.3 Resume data download To resume your data download, run tagme() again, but do not include new = TRUE: tagme(project.num, update = TRUE, dir = ...) B.4 Google Maps As of October 16, 2018 recent updates require the use of a Google key to access google maps. To obtain an access key, you must be a registered Google user with up to date billing information, however you do not have to pay for the service (for the first little while at least). To obtain a key: login to the Google Cloud Platform. If you do not already have a project then create one. Check that you have current billing information - you will not be charged but it must be present and up to date. Under the navigation menu on the left, click APIs &amp; Services &gt; Credentials, then click Create credentials &gt; API key. You may need to enable Google Maps Static API. You can do this through the navigation menu in the upper left corner, and selecting APIs &amp; Services &gt; library, choosing Google Maps Static API and clicking Enable. Full details are listed under Detailed Guide here. Note that you may have to enable Google Maps Static API. For troubleshooting see here and here. Once you have your access key, youll need to provide it with the call register_google(), each time you start a new R session you will be required to enter your key. Then you can create Google maps with the ggmap package using the get_googlemap() function and specifying the lat/lon center of your map (as opposed to bounding box as with stamen maps). B.5 Common problems and solutions: B.5.1 I cannot access Project 176 / I download 0 records from Project 176 Remember that project 176 is only accessible with the username and password: motus.sample. B.5.2 I get the message Auto-disconnecting SQLiteConnection one or multiple times after using tagme() If this occurs after data download has finished, this message can be ignored. If it occurs during an active download, the connection will usually be maintained and the download will continue. However if the download stops, simply run tagme() again. If that does not work, we suggest logging out of the motus package or restarting R (see sections B.2 and B.3). B.5.3 I get an Internal Server Error message when using tagme(, update = TRUE) If you get this message while updating your .motus file, use tagme() again to continue the download. B.5.4 I get an Error: Forbidden message when using tagme() This error may occur if you are attempting to download multiple projects simultaneously from the same user account. If you get this error, please logout of the motus package, and try tagme() again (see sections B.2 and B.3). B.5.5 I get an error Object xxxx not found, referring to a table or field name, or some of your examples in the book do not work. Be sure to start the steps from the top of the chapter and run them in sequential order. Another possibility is that your .motus database hasnt been updated to support the latest version of the motus package. To ensure that your .motus file is up-to-date with the motus package: sql.motus &lt;- tagme(project.num, dir= ...) checkVersion(sql.motus) To correct any warnings, you should follow these steps: download the latest version of the motus package (refer to Chapter 2). terminate and restart your R session. load the motus library using library(motus) in your R console. load your sqlite file. Look for notes on the console indicating that your database is being updated. check the version again. library(motus) sql &lt;- tagme(project.num, dir= ...) checkVersion(sql) B.5.6 I get an error Error in rsqlite_connect(dbname, loadable.extensions, flags, vfs) : Could not connect to database: unable to open database file when attempting to run tagme() If you get this message, its likely that youre attempting a new download or update to a nonexistant directory. The directory is specified in the dir = \"\" command of the tagme() function. If the directory is not specified, files will be saved to your working directory. Use getwd() to determine your current working directory. Use setwd() to set a new working directory. To specify a location to save files from your working directory use ./ followed by the file path. getwd() # show working directory, in this case it&#39;s &quot;C:/Documents&quot; # downloads data to your working directory tagme(proj.num, new = TRUE, update = TRUE) # downloads data to the data folder within your working directory # ie. the file path C:/Documents/data tagme(proj.num, new = TRUE, update = TRUE, dir = &quot;./data/&quot;) # downloads data to the file path C:/Downloads tagme(proj.num, new = TRUE, update = TRUE, dir = &quot;C:/Downloads&quot;) B.5.7 I see GPS coordinates of 0 or 999 These values are recorded from the GPS unit in the field. Values like these should be ignored, you can replace these with NA, or insert the recvDeployLat/recvDeplOyLon values which are taken from receiver deployment metadata entered by users. ## to replace gpsLat/gpsLon values of NA, 0, or 999 with that of receiver deployment metadata in the alltags table, and read into a data.frame df.alltags &lt;- tbl.alltags %&gt;% mutate(recvLat = if_else((is.na(gpsLat)|gpsLat == 0|gpsLat == 999), recvDeployLat, gpsLat), recvLon = if_else((is.na(gpsLon)|gpsLon == 0|gpsLon == 999), recvDeployLon, gpsLon) collect() %&gt;% as.data.frame B.5.8 I see port with a value of -1 Port -1 represents the A1+A2+A3+A4 compound antenna which is sometimes reported in Lotek .DTA file detections. This likely means the receiver has combined the signal from 4 antennas to detect the tag. B.5.9 I get the error Error in rsqlite_fetch(res@ptr, n = n) : database disk image is malformed This is likely due to corrupt files which can occur during download. The easiest solution is to delete your current .motus file and download from scratch. Of course, there is always the possibility that the book contains errors! If this does not work, please contact motus@birdscanada.org. "],["appendixC.html", "C Appendix - motus - Summary and plotting functions C.1 checkVersion C.2 sunRiseSet C.3 plotAllTagsCoord C.4 plotAllTagsSite C.5 plotDailySiteSum C.6 plotRouteMap C.7 plotSite C.8 plotSiteSig C.9 plotTagSig C.10 simSiteDet C.11 siteSum C.12 siteSumDaily C.13 siteTrans C.14 tagSum C.15 tagSumSite C.16 timeToSunriset", " C Appendix - motus - Summary and plotting functions The motus R package offers functions that work with .motus data to do common computations, summaries and plots. This appendix outlines these functions and provides examples on function use. Many of these functions work with both tbl and data.frame formats, however some require the data to be in sql format as specified below. Detailed instructions on accessing and formatting data are available in Chapter 3. The examples throughout this chapter work with the sample data which can be accessed and converted to various formats through the following code: # download and access sample data in sql format # username: motus.sample, password: motus.sample sql.motus &lt;- tagme(176, new = TRUE, update = TRUE, dir = &quot;./data&quot;) # extract &quot;alltags&quot;&quot; table from sql file &quot;sql.motus&quot; tbl.alltags &lt;- tbl(sql.motus, &quot;alltagsGPS&quot;) ## convert the tbl &quot;tbl.alltags&quot; to a data.frame called &quot;df.alltags&quot; df.alltags &lt;- tbl.alltags %&gt;% collect() %&gt;% as.data.frame() You can access the function help pages using `?sunRiseSet in the R console. Or view the underlying function code like this: sunRiseSet ## function (data, lat = &quot;recvDeployLat&quot;, lon = &quot;recvDeployLon&quot;, ## ts = &quot;ts&quot;) ## { ## data &lt;- data %&gt;% dplyr::collect() %&gt;% as.data.frame() ## data$ts &lt;- lubridate::as_datetime(data$ts, tz = &quot;UTC&quot;) ## cols &lt;- c(lat, lon, ts) ## loc_na &lt;- data[!stats::complete.cases(data[cols]), ] ## loc &lt;- data[stats::complete.cases(data[cols]), ] ## if (nrow(loc) == 0) ## stop(&quot;No data with coordinates &#39;&quot;, lat, &quot;&#39; and &#39;&quot;, lon, ## &quot;&#39;&quot;, call. = FALSE) ## loc$sunrise &lt;- maptools::sunriset(as.matrix(dplyr::select(loc, ## lon, lat)), loc$ts, POSIXct.out = T, direction = &quot;sunrise&quot;)$time ## loc$sunset &lt;- maptools::sunriset(as.matrix(dplyr::select(loc, ## lon, lat)), loc$ts, POSIXct.out = T, direction = &quot;sunset&quot;)$time ## data &lt;- merge(loc, loc_na, all = TRUE) ## return(data) ## } ## &lt;bytecode: 0x000000003ca837a0&gt; ## &lt;environment: namespace:motus&gt; C.1 checkVersion C.1.1 Description When you call the tagme() function to load the sqlite database, there is a process that will verify that your database has the version matching the most current version of the motus package and store the version in a new table called admInfo. Over time, changes will be made that require adding new tables, views or fields to the database. The following call will check that your database has been updated to the version matching the current version of the motus package. Refer to Appendix B if this call returns a warning; if you do not have the most recent version, see Chapter 2 to update motus. C.1.2 Arguments sql.motus an sqlite database of .motus data downloaded using tagme() C.1.3 Example checkVersion(sql.motus) C.2 sunRiseSet C.2.1 Description Creates and adds a sunrise and sunset variable to a data.frame containing latitude, longitude, and a date/time as POSIXct or numeric. C.2.2 Arguments data can be either a selected table from .motus detection data e.g. alltags, or a data.frame of detection data including at a minimum variables for date/time, latitude, and longitude lat variable with latitude values, defaults to recvDeployLat lon variable with longitude values, defaults to recvDeployLon ts variable with time in UTC as numeric or POSIXct, defaults to ts C.2.3 Example Add sunrise/sunset variables to the alltags data.frame alltags.df.sun &lt;- sunRiseSet(df.alltags) head(alltags.df.sun) ## hitID runID batchID ts tsCorrected sig sigsd noise freq ## 1 45107 8886 53 2015-10-26 11:19:49 1445858390 52 0 -96 4 ## 2 45108 8886 53 2015-10-26 11:20:28 1445858429 54 0 -96 4 ## 3 45109 8886 53 2015-10-26 11:21:17 1445858477 55 0 -96 4 ## 4 45110 8886 53 2015-10-26 11:21:55 1445858516 52 0 -96 4 ## 5 45111 8886 53 2015-10-26 11:22:44 1445858564 49 0 -96 4 ## 6 199885 23305 64 2015-10-26 11:12:04 1445857924 33 0 -96 4 ## freqsd slop burstSlop done motusTagID ambigID port runLen bootnum tagProjID ## 1 0 1e-04 0.0000 1 16047 NA 3 5 11 176 ## 2 0 1e-04 -0.0021 1 16047 NA 3 5 11 176 ## 3 0 1e-04 0.0001 1 16047 NA 3 5 11 176 ## 4 0 1e-04 -0.0010 1 16047 NA 3 5 11 176 ## 5 0 1e-04 0.0001 1 16047 NA 3 5 11 176 ## 6 0 1e-04 0.0000 1 16047 NA 1 11 4 176 ## mfgID tagType codeSet mfg tagModel tagLifespan nomFreq tagBI pulseLen ## 1 378 ID Lotek4 Lotek NTQB-3-2 NA 166.38 9.6971 2.5 ## 2 378 ID Lotek4 Lotek NTQB-3-2 NA 166.38 9.6971 2.5 ## 3 378 ID Lotek4 Lotek NTQB-3-2 NA 166.38 9.6971 2.5 ## 4 378 ID Lotek4 Lotek NTQB-3-2 NA 166.38 9.6971 2.5 ## 5 378 ID Lotek4 Lotek NTQB-3-2 NA 166.38 9.6971 2.5 ## 6 378 ID Lotek4 Lotek NTQB-3-2 NA 166.38 9.6971 2.5 ## tagDeployID speciesID markerNumber markerType tagDeployStart tagDeployEnd ## 1 1839 4670 135268103 metal band 1441908000 1457632800 ## 2 1839 4670 135268103 metal band 1441908000 1457632800 ## 3 1839 4670 135268103 metal band 1441908000 1457632800 ## 4 1839 4670 135268103 metal band 1441908000 1457632800 ## 5 1839 4670 135268103 metal band 1441908000 1457632800 ## 6 1839 4670 135268103 metal band 1441908000 1457632800 ## tagDepLat tagDepLon tagDepAlt ## 1 51.4839 -80.45 NA ## 2 51.4839 -80.45 NA ## 3 51.4839 -80.45 NA ## 4 51.4839 -80.45 NA ## 5 51.4839 -80.45 NA ## 6 51.4839 -80.45 NA ## tagDepComments ## 1 {&quot;ageID&quot;:&quot;HY&quot;,&quot;bill&quot;:36.5,&quot;blood&quot;:&quot;Y&quot;,&quot;country&quot;:&quot;Canada&quot;,&quot;culmen&quot;:36.5,&quot;fatScore&quot;:3,&quot;locationID&quot;:&quot;NorthPoint_net&quot;,&quot;province&quot;:&quot;Ontario&quot;,&quot;sexID&quot;:&quot;U&quot;,&quot;tarsus&quot;:33.3,&quot;weight&quot;:137.8,&quot;wing&quot;:162,&quot;comments&quot;:null} ## 2 {&quot;ageID&quot;:&quot;HY&quot;,&quot;bill&quot;:36.5,&quot;blood&quot;:&quot;Y&quot;,&quot;country&quot;:&quot;Canada&quot;,&quot;culmen&quot;:36.5,&quot;fatScore&quot;:3,&quot;locationID&quot;:&quot;NorthPoint_net&quot;,&quot;province&quot;:&quot;Ontario&quot;,&quot;sexID&quot;:&quot;U&quot;,&quot;tarsus&quot;:33.3,&quot;weight&quot;:137.8,&quot;wing&quot;:162,&quot;comments&quot;:null} ## 3 {&quot;ageID&quot;:&quot;HY&quot;,&quot;bill&quot;:36.5,&quot;blood&quot;:&quot;Y&quot;,&quot;country&quot;:&quot;Canada&quot;,&quot;culmen&quot;:36.5,&quot;fatScore&quot;:3,&quot;locationID&quot;:&quot;NorthPoint_net&quot;,&quot;province&quot;:&quot;Ontario&quot;,&quot;sexID&quot;:&quot;U&quot;,&quot;tarsus&quot;:33.3,&quot;weight&quot;:137.8,&quot;wing&quot;:162,&quot;comments&quot;:null} ## 4 {&quot;ageID&quot;:&quot;HY&quot;,&quot;bill&quot;:36.5,&quot;blood&quot;:&quot;Y&quot;,&quot;country&quot;:&quot;Canada&quot;,&quot;culmen&quot;:36.5,&quot;fatScore&quot;:3,&quot;locationID&quot;:&quot;NorthPoint_net&quot;,&quot;province&quot;:&quot;Ontario&quot;,&quot;sexID&quot;:&quot;U&quot;,&quot;tarsus&quot;:33.3,&quot;weight&quot;:137.8,&quot;wing&quot;:162,&quot;comments&quot;:null} ## 5 {&quot;ageID&quot;:&quot;HY&quot;,&quot;bill&quot;:36.5,&quot;blood&quot;:&quot;Y&quot;,&quot;country&quot;:&quot;Canada&quot;,&quot;culmen&quot;:36.5,&quot;fatScore&quot;:3,&quot;locationID&quot;:&quot;NorthPoint_net&quot;,&quot;province&quot;:&quot;Ontario&quot;,&quot;sexID&quot;:&quot;U&quot;,&quot;tarsus&quot;:33.3,&quot;weight&quot;:137.8,&quot;wing&quot;:162,&quot;comments&quot;:null} ## 6 {&quot;ageID&quot;:&quot;HY&quot;,&quot;bill&quot;:36.5,&quot;blood&quot;:&quot;Y&quot;,&quot;country&quot;:&quot;Canada&quot;,&quot;culmen&quot;:36.5,&quot;fatScore&quot;:3,&quot;locationID&quot;:&quot;NorthPoint_net&quot;,&quot;province&quot;:&quot;Ontario&quot;,&quot;sexID&quot;:&quot;U&quot;,&quot;tarsus&quot;:33.3,&quot;weight&quot;:137.8,&quot;wing&quot;:162,&quot;comments&quot;:null} ## tagDeployTest fullID deviceID recvDeployID ## 1 NA SampleData#378:9.7@166.38(M.16047) 486 2510 ## 2 NA SampleData#378:9.7@166.38(M.16047) 486 2510 ## 3 NA SampleData#378:9.7@166.38(M.16047) 486 2510 ## 4 NA SampleData#378:9.7@166.38(M.16047) 486 2510 ## 5 NA SampleData#378:9.7@166.38(M.16047) 486 2510 ## 6 NA SampleData#378:9.7@166.38(M.16047) 515 2512 ## recvDeployLat recvDeployLon recvDeployAlt recv recvDeployName ## 1 42.60699 -72.71657 NA Lotek-159 Shelburne ## 2 42.60699 -72.71657 NA Lotek-159 Shelburne ## 3 42.60699 -72.71657 NA Lotek-159 Shelburne ## 4 42.60699 -72.71657 NA Lotek-159 Shelburne ## 5 42.60699 -72.71657 NA Lotek-159 Shelburne ## 6 42.68067 -72.47392 NA Lotek-164 BennettMeadow ## recvSiteName isRecvMobile recvProjID recvUtcOffset antType antBearing ## 1 &lt;NA&gt; 0 74 NA yagi-9 127 ## 2 &lt;NA&gt; 0 74 NA yagi-9 127 ## 3 &lt;NA&gt; 0 74 NA yagi-9 127 ## 4 &lt;NA&gt; 0 74 NA yagi-9 127 ## 5 &lt;NA&gt; 0 74 NA yagi-9 127 ## 6 &lt;NA&gt; 0 74 NA yagi-9 243 ## antHeight speciesEN speciesFR speciesSci speciesGroup ## 1 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus BIRDS ## 2 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus BIRDS ## 3 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus BIRDS ## 4 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus BIRDS ## 5 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus BIRDS ## 6 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus BIRDS ## tagProjName recvProjName gpsLat gpsLon gpsAlt sunrise ## 1 SampleData &lt;NA&gt; NA NA NA 2015-10-26 11:16:49 ## 2 SampleData &lt;NA&gt; NA NA NA 2015-10-26 11:16:49 ## 3 SampleData &lt;NA&gt; NA NA NA 2015-10-26 11:16:49 ## 4 SampleData &lt;NA&gt; NA NA NA 2015-10-26 11:16:49 ## 5 SampleData &lt;NA&gt; NA NA NA 2015-10-26 11:16:49 ## 6 SampleData &lt;NA&gt; NA NA NA 2015-10-26 11:15:58 ## sunset ## 1 2015-10-26 21:52:11 ## 2 2015-10-26 21:52:11 ## 3 2015-10-26 21:52:11 ## 4 2015-10-26 21:52:11 ## 5 2015-10-26 21:52:11 ## 6 2015-10-26 21:51:06 C.3 plotAllTagsCoord C.3.1 Description Plot latitude/longitude vs time (UTC rounded to the hour) for each tag using .motus detection data. Coordinate is by default taken from a receivers GPS latitude recordings. C.3.2 Arguments data a selected table from .motus detection data, e.g. alltags, or a data.frame of detection data including at a minimum variables for date/time, and either latitude or longitude tagsPerPanel number of tags in each panel of the plot, by default this is 5 coordinate variable name from which to obtain location values, by default it is set to recvDeployLat ts variable for a date/time object as numeric or POSIXct, defaults to ts recvDepName variable consisting of receiver deployment name fullID variable consisting of a tag fullID mfgID variable consisting of a tags manufacturer ID C.3.3 Example Plot select tags from tbl.alltags with 3 tags per panel plotAllTagsCoord( filter(tbl.alltags, motusTagID %in% c(19129, 16011, 17357, 16035, 22897, 23316)), tagsPerPanel = 3) C.4 plotAllTagsSite C.4.1 Description Plot latitude/longitude vs time (UTC rounded to the hour) for each tag using .motus detection data. Coordinate is by default taken from a receivers GPS latitude recordings. C.4.2 Arguments data a selected table from .motus detection data, e.g. alltags, or a data.frame of detection data including at a minimum variables for date/time, and either latitude or longitude tagsPerPanel number of tags in each panel of the plot, by default this is 5 coordinate variable name from which to obtain location values, by default it is set to recvDeployLat ts variable for a date/time object as numeric or POSIXct, defaults to ts recvDepName variable consisting of receiver deployment name fullID variable consisting of a tag fullID mfgID variable consisting of a tags manufacturer ID C.4.3 Example Plot tbl file tbl.alltags using gpsLat and 3 tags per panel for select species Red Knot plotAllTagsSite(filter(tbl.alltags, speciesEN == &quot;Red Knot&quot;), coordinate = &quot;recvDeployLat&quot;, tagsPerPanel = 3) C.5 plotDailySiteSum C.5.1 Description Plots total number of detections across all tags, and total number of tags detected per day for a specified site. Depends on siteSumDaily function. C.5.2 Arguments data a selected table from .motus data, e.g. alltags, or a data.frame of detection data including at a minimum variables for motusTagID, sig, recvDepName, ts motusTagID variable consisting of a motus tag ID sig variable consisting a signal strength variable recvDepName variable consisting of receiver deployment name ts variable for a date/time object as numeric or POSIXct, defaults to ts C.5.3 Example Plot of all tag detections at site Longridge using data.frame df.alltags plotDailySiteSum(df.alltags, recvDeployName = &quot;Longridge&quot;) C.6 plotRouteMap C.6.1 Description ggmap map of routes of Motus tag detections coloured by motusTagID. User defines a date range to show points for receivers that were operational at some point during specified date range. ### Arguments data a .motus sql file maptype map type to display, can be: terrain , terrain-background, toner, watercolor, etc. lat top and bottom latitude bounds. If NULL (default) this is calculated from the data lon left and right longitude bounds. If NULL (default) this is calculated from the data zoom integer for zoom 3-21, 3 being continent level, 10 being city-scale recvStart start date for date range of active receivers recvEnd end date for date range of active receivers C.6.2 Example Plot routemap of all detection data, with terrain maptype, and receivers active between 2016-01-01 and 2017-01-01 plotRouteMap(sql.motus, maptype = &quot;terrain&quot;, recvStart = &quot;2016-01-01&quot;, recvEnd = &quot;2016-12-31&quot;) ## Source : http://tile.stamen.com/terrain/3/1/2.png ## Source : http://tile.stamen.com/terrain/3/2/2.png ## Source : http://tile.stamen.com/terrain/3/1/3.png ## Source : http://tile.stamen.com/terrain/3/2/3.png C.7 plotSite C.7.1 Description C.7.2 Arguments data a selected table from .motus data, e.g. alltags, or a data.frame of detection data including at a minimum variables for ts, antBearing, fullID, recvDepName ts variable for a date/time object as numeric or POSIXct, defaults to ts antBearing variable consisting antenna bearing variable fullID variable consisting of a tag fullID recvDepName variable consisting of receiver deployment name C.7.3 Example Plot only detections at a specific site; Piskwamish for data.frame df.alltags plotSite(filter(df.alltags, recvDeployName == &quot;Piskwamish&quot;)) C.8 plotSiteSig C.8.1 Description Plot signal strength vs time for all tags detected at a specified site, coloured by antenna C.8.2 Arguments data a selected table from .motus data, e.g. alltags, or a data.frame of detection data including at a minimum variables for antBearing, ts, lat, sig, fullID, recvDepName antBearing variable consisting antenna bearing variable ts variable for a date/time object as numeric or POSIXct, defaults to ts recvDeployLat variable consisting of receiver deployment latitude sig variable consisting a signal strength variable fullID variable consisting of a tag fullID recvDepName variable consisting of receiver deployment name C.8.3 Example Plot select tags for site Piskwamish plotSiteSig(filter(df.alltags, motusTagID %in% c(16037, 16039, 16035)), recvDeployName = &quot;Netitishi&quot;) C.9 plotTagSig C.9.1 Description Plot signal strength vs time for specified tag, faceted by site (ordered by latitude) and coloured by antenna C.9.2 Arguments data a selected table from .motus data, e.g. alltags, or a data.frame of detection data including at a minimum variables for motusTagID, sig, ts, antBearing, recvDeployLat, fullID, recvDepName motusTagID variable consisting of a motus tag ID antBearing variable consisting antenna bearing variable ts variable for a date/time object as numeric or POSIXct, defaults to ts recvDeployLat variable consisting of receiver deployment latitude sig variable consisting a signal strength variable fullID variable consisting of a tag fullID recvDepName variable consisting of receiver deployment name C.9.3 Example Plot signal strength of a specified tag using tbl file tbl.alltags plotTagSig(tbl.alltags, motusTagID = 16035) C.10 simSiteDet C.10.1 Description Creates a data.frame consisting of only detections of tags that are detected at two or more receivers at the same time. C.10.2 Arguments data a selected table from .motus data, e.g. alltags, or a data.frame of detection data including at a minimum variables for ts, motusTagID, recvDepName ts variable for a date/time object as numeric or POSIXct, defaults to ts motusTagID variable consisting of a motus tag ID recvDepName variable consisting of receiver deployment name C.10.3 Example To get a data.frame called simSites of just simultaneous detections from a data.frame df.alltags simSites &lt;- simSiteDet(df.alltags) head(simSites) ## [1] motusTagID ts num.dup hitID runID ## [6] batchID tsCorrected sig sigsd noise ## [11] freq freqsd slop burstSlop done ## [16] ambigID port runLen bootnum tagProjID ## [21] mfgID tagType codeSet mfg tagModel ## [26] tagLifespan nomFreq tagBI pulseLen tagDeployID ## [31] speciesID markerNumber markerType tagDeployStart tagDeployEnd ## [36] tagDepLat tagDepLon tagDepAlt tagDepComments tagDeployTest ## [41] fullID deviceID recvDeployID recvDeployLat recvDeployLon ## [46] recvDeployAlt recv recvDeployName recvSiteName isRecvMobile ## [51] recvProjID recvUtcOffset antType antBearing antHeight ## [56] speciesEN speciesFR speciesSci speciesGroup tagProjName ## [61] recvProjName gpsLat gpsLon gpsAlt ## &lt;0 rows&gt; (or 0-length row.names) C.11 siteSum C.11.1 Description Creates a summary of the first and last detection at a site, the length of time between first and last detection, the number of tags, and the total number of detections at a site. Plots total number of detections across all tags, and total number of tags detected at each site. C.11.2 Arguments data a selected table from .motus data, e.g. alltags, or a data.frame of detection data including at a minimum variables for motusTagID, sig, recvDeployLat, recvDepName, and ts motusTagID variable consisting of a motus tag ID sig variable consisting a signal strength variable recvDeployLat variable consisting of receiver deployment latitude recvDepName variable consisting of receiver deployment name ts variable for a date/time object as numeric or POSIXct, defaults to ts units units to display time difference, defaults to hours, options include secs, mins, hours, days, weeks C.11.3 Example Create site summaries for select sites with time in minutes site_summary &lt;- siteSum(filter(df.alltags, recvDeployName %in% c(&quot;Niapiskau&quot;, &quot;Netitishi&quot;, &quot;Old Cur&quot;, &quot;Washkaugou&quot;)), units = &quot;mins&quot;) head(site_summary) ## # A tibble: 3 x 6 ## recvDeployName first_ts last_ts tot_ts num.tags num.det ## &lt;fct&gt; &lt;dttm&gt; &lt;dttm&gt; &lt;drtn&gt; &lt;int&gt; &lt;int&gt; ## 1 Niapiskau_50.~ 2016-10-01 23:47:57 2016-10-27 00:03:21 36015~ 6 82376 ## 2 Washkaugou_51~ 2016-10-09 23:52:45 2016-10-10 00:00:42 7~ 2 172 ## 3 Netitishi_51.~ 2015-08-14 17:53:49 2015-09-08 01:10:13 34996~ 7 2363 C.12 siteSumDaily C.12.1 Description Creates a summary of the first and last daily detection at a site, the length of time between first and last detection, the number of tags, and the total number of detections at a site for each day. Same as siteSum, but daily by site. C.12.2 Arguments data a selected table from .motus data, e.g. alltags, or a data.frame of detection data including at a minimum variables for motusTagID, sig, recvDepName, ts motusTagID variable consisting of a motus tag ID sig variable consisting a signal strength variable recvDepName variable consisting of receiver deployment name ts variable for a date/time object as numeric or POSIXct, defaults to ts units units to display time difference, defaults to hours, options include secs, mins, hours, days, weeks C.12.3 Example Create site summaries for all sites within detection data with time in minutes using tbl file tbl.alltags daily_site_summary &lt;- siteSumDaily(tbl.alltags, units = &quot;mins&quot;) head(daily_site_summary) ## recvDeployName date first_ts ## 1 Assateague State Park\\n38.2, -75.1 2015-09-13 2015-09-13 10:12:50 ## 2 Baccaro\\n43.5, -65.5 2017-05-19 2017-05-19 16:01:21 ## 3 BennettMeadow\\n42.7, -72.5 2015-10-26 2015-10-26 11:12:04 ## 4 Binbrook_Conservation_Area\\n43.1, -79.8 2017-05-18 2017-05-18 03:13:25 ## 5 BISE\\n41.2, -71.6 2015-10-26 2015-10-26 17:55:47 ## 6 Blandford\\n44.5, -64.1 2015-12-26 2015-12-26 14:58:27 ## last_ts tot_ts num_tags num_det ## 1 2015-09-13 10:14:40 1.828847 mins 1 6 ## 2 2017-05-19 16:02:40 1.323297 mins 3 6 ## 3 2015-10-26 11:30:49 18.747692 mins 1 27 ## 4 2017-05-18 03:13:46 0.353195 mins 2 6 ## 5 2015-10-26 19:16:55 81.132212 mins 1 44 ## 6 2015-12-26 14:58:47 0.323150 mins 1 2 C.13 siteTrans C.13.1 Description Creates a data.frame of transitions between sites; detections are ordered by detection time, then transitions are identified as the period between the final detection at site x (possible departure), and the first detection (possible arrival) at site y (ordered chronologically). Each row contains the last detection time and lat/lon of site x, first detection time and lat/lon of site y, distance between the site pair, time between detections, rate of movement between detections, and bearing between site pairs. C.13.2 Arguments data a selected table from .motus data, e.g. alltags, or a data.frame of detection data including at a minimum variables for ts, motusTagID, tagDeployID, recvDeployLat, recvDeployLon, recvDepName ts variable for a date/time object as numeric or POSIXct, defaults to ts motusTagID variable consisting of a motus tag ID tagDeployID variable consisting of Motus tag deployment ID recvDeployLat variable consisting of receiver deployment latitude recvDeployLon variable consisting of receiver deployment longitude recvDepName variable consisting of receiver deployment name C.13.3 Example View site transitions for only tag 16037 from data.frame df.alltags transitions &lt;- siteTrans(filter(df.alltags, motusTagID == 16037), latCoord = &quot;recvDeployLat&quot;, lonCoord = &quot;recvDeployLon&quot;) head(transitions) ## # A tibble: 6 x 16 ## # Groups: motusTagID, tagDeployID [1] ## motusTagID tagDeployID data consec ts.x lat.x lon.x ## &lt;int&gt; &lt;int&gt; &lt;lis&gt; &lt;list&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 16037 1825 &lt;tib~ &lt;tibb~ 2015-08-17 17:02:39 NA NA ## 2 16037 1825 &lt;tib~ &lt;tibb~ 2015-08-28 16:40:18 51.5 -80.4 ## 3 16037 1825 &lt;tib~ &lt;tibb~ 2015-09-08 01:10:13 51.3 -80.1 ## 4 16037 1825 &lt;tib~ &lt;tibb~ 2015-09-08 18:37:16 44.6 -65.8 ## 5 16037 1825 &lt;tib~ &lt;tibb~ 2015-09-13 19:46:27 39.0 -74.8 ## 6 16037 1825 &lt;tib~ &lt;tibb~ 2015-09-14 15:56:49 37.1 -76.0 ## # ... with 9 more variables: recvDeployName.x &lt;chr&gt;, ts.y &lt;dttm&gt;, lat.y &lt;dbl&gt;, ## # lon.y &lt;dbl&gt;, recvDeployName.y &lt;chr&gt;, tot_ts &lt;drtn&gt;, dist &lt;dbl&gt;, rate &lt;dbl&gt;, ## # bearing &lt;dbl&gt; C.14 tagSum C.14.1 Description Creates a summary for each tag of its first and last detection time, first and last detection site, length of time between first and last detection, straight line distance between first and last detection site, rate of movement, and bearing C.14.2 Arguments data a selected table from .motus data, e.g. alltags, or a data.frame of detection data including at a minimum variables for motusTagID, fullID, recvDeployLat, recvDeployLon, recvDepName, ts motusTagID variable consisting of a motus tag ID fullID variable consisting of a tag fullID recvDeployLat variable consisting of receiver deployment latitude recvDeployLon variable consisting of receiver deployment longitude recvDepName variable consisting of receiver deployment name ts variable for a date/time object as numeric or POSIXct, defaults to ts C.14.3 Example Create tag summary for all tags within detection data using tbl file tbl.alltags tag_summary &lt;- tagSum(tbl.alltags) head(tag_summary) ## fullID first_ts last_ts ## 1 Niles#152:6.1@166.38(M.10811) 2015-08-03 06:37:11 2015-08-03 06:37:35 ## 2 ?proj?-0#395:9.7 2015-07-23 10:10:54 2015-09-02 20:06:13 ## 3 Selva#172:6.1@166.38(M.17021) 2015-09-02 04:06:07 2015-09-03 00:27:16 ## 4 SampleData#152:6.1@166.38(M.16011) 2015-08-03 06:37:11 2015-09-18 09:37:39 ## 5 SampleData#395:9.7@166.38(M.16052) 2015-09-12 17:38:04 2015-10-20 20:43:43 ## 6 SampleData#179:6.1@166.38(M.16037) 2015-08-17 17:01:38 2015-11-02 13:21:42 ## first_site last_site recvLat.x recvLon.x recvLat.y ## 1 North Bluff_51.5, -80.4 North Bluff_51.5, -80.4 51.4839 -80.4500 51.48390 ## 2 Machias_44.5, -67.1 Ruby&#39;s_62.9, -143.7 44.5023 -67.1018 62.89072 ## 3 Netitishi_51.3, -80.1 MDR_44, -68.1 51.2913 -80.1168 43.96893 ## 4 North Bluff_51.5, -80.4 NWW_39, -74.8 51.4839 -80.4500 39.02827 ## 5 Longridge_51.8, -80.7 Mount Thom_45.6, -63 51.8231 -80.6912 45.55480 ## 6 NP mobile_NA, NA Hillman_Marsh_42, -82.5 NA NA 42.04270 ## recvLon.y tot_ts dist rate bearing num_det ## 1 -80.45000 24.386 secs 0 0.0000000 -180.00000 4 ## 2 -143.68170 3578118.674 secs 5087724 1.4218993 -38.36268 12 ## 3 -68.12830 73268.958 secs 1211577 16.5360200 127.53144 279 ## 4 -74.81004 3985228.228 secs 1452237 0.3644051 160.20437 127 ## 5 -62.98590 3294338.784 secs 1472844 0.4470832 111.25011 147 ## 6 -82.51440 6639604.044 secs NA NA NA 1353 C.15 tagSumSite C.15.1 Description Creates a summary for each tag of its first and last detection time at each site, length of time between first and last detection of each site, and total number of detections at each site. C.15.2 Arguments data a selected table from .motus data, e.g. alltags, or a data.frame of detection data including at a minimum variables for motusTagID, fullID, recvDepName, ts motusTagID variable consisting of a motus tag ID fullID variable consisting of a tag fullID recvDepName variable consisting of receiver deployment name ts variable for a date/time object as numeric or POSIXct, defaults to ts C.15.3 Example Create tag summaries for only select tags with time in default hours with data.frame df.alltags tag_site_summary &lt;- tagSumSite(filter(df.alltags, motusTagID %in% c(16047, 16037, 16039))) head(tag_site_summary) ## fullID recvDeployName ## 1 SampleData#179:6.1@166.38(M.16037) BULL\\n37.1, -76 ## 2 SampleData#179:6.1@166.38(M.16037) Comeau (Marshalltown)\\n44.6, -65.8 ## 3 SampleData#179:6.1@166.38(M.16037) Hillman_Marsh\\n42, -82.5 ## 4 SampleData#179:6.1@166.38(M.16037) Netitishi\\n51.3, -80.1 ## 5 SampleData#179:6.1@166.38(M.16037) North Bluff\\n51.5, -80.4 ## 6 SampleData#179:6.1@166.38(M.16037) NP mobile\\nNA, NA ## first_ts last_ts tot_ts num_det ## 1 2015-09-14 15:55:48 2015-09-14 15:56:49 0.01693000 hours 2 ## 2 2015-09-08 18:29:57 2015-09-08 18:37:16 0.12192881 hours 6 ## 3 2015-11-02 13:20:47 2015-11-02 13:21:42 0.01525056 hours 2 ## 4 2015-08-30 01:36:08 2015-09-08 01:10:13 215.56819269 hours 1166 ## 5 2015-08-23 15:13:57 2015-08-28 16:40:18 121.43902892 hours 26 ## 6 2015-08-17 17:01:38 2015-08-17 17:02:39 0.01693344 hours 11 C.16 timeToSunriset C.16.1 Description Creates and adds variables for time to, and time from sunrise/sunset based on a variable of POSIXct dates/times data.frame must contain latitude, longitude, and a date/time variable C.16.2 Arguments data a selected table from .motus data, e.g. alltags, or a data.frame of detection data including at a minimum variables for date/time, latitude, and longitude lat variable with latitude values, defaults to recvDeployLat lon variable with longitude values, defaults to recvDeployLon ts variable for a date/time object as numeric or POSIXct, defaults to ts units units to display time difference, defaults to hours, options include secs, mins, hours, days, weeks C.16.3 Example Get sunrise and sunset information with units in minutes using tbl file tbl.alltags sunrise &lt;- timeToSunriset(tbl.alltags, units = &quot;mins&quot;) head(sunrise) ## hitID runID batchID ts tsCorrected sig sigsd noise freq ## 1 45107 8886 53 2015-10-26 11:19:49 1445858390 52 0 -96 4 ## 2 45108 8886 53 2015-10-26 11:20:28 1445858429 54 0 -96 4 ## 3 45109 8886 53 2015-10-26 11:21:17 1445858477 55 0 -96 4 ## 4 45110 8886 53 2015-10-26 11:21:55 1445858516 52 0 -96 4 ## 5 45111 8886 53 2015-10-26 11:22:44 1445858564 49 0 -96 4 ## 6 199885 23305 64 2015-10-26 11:12:04 1445857924 33 0 -96 4 ## freqsd slop burstSlop done motusTagID ambigID port runLen bootnum tagProjID ## 1 0 1e-04 0.0000 1 16047 NA 3 5 11 176 ## 2 0 1e-04 -0.0021 1 16047 NA 3 5 11 176 ## 3 0 1e-04 0.0001 1 16047 NA 3 5 11 176 ## 4 0 1e-04 -0.0010 1 16047 NA 3 5 11 176 ## 5 0 1e-04 0.0001 1 16047 NA 3 5 11 176 ## 6 0 1e-04 0.0000 1 16047 NA 1 11 4 176 ## mfgID tagType codeSet mfg tagModel tagLifespan nomFreq tagBI pulseLen ## 1 378 ID Lotek4 Lotek NTQB-3-2 NA 166.38 9.6971 2.5 ## 2 378 ID Lotek4 Lotek NTQB-3-2 NA 166.38 9.6971 2.5 ## 3 378 ID Lotek4 Lotek NTQB-3-2 NA 166.38 9.6971 2.5 ## 4 378 ID Lotek4 Lotek NTQB-3-2 NA 166.38 9.6971 2.5 ## 5 378 ID Lotek4 Lotek NTQB-3-2 NA 166.38 9.6971 2.5 ## 6 378 ID Lotek4 Lotek NTQB-3-2 NA 166.38 9.6971 2.5 ## tagDeployID speciesID markerNumber markerType tagDeployStart tagDeployEnd ## 1 1839 4670 135268103 metal band 1441908000 1457632800 ## 2 1839 4670 135268103 metal band 1441908000 1457632800 ## 3 1839 4670 135268103 metal band 1441908000 1457632800 ## 4 1839 4670 135268103 metal band 1441908000 1457632800 ## 5 1839 4670 135268103 metal band 1441908000 1457632800 ## 6 1839 4670 135268103 metal band 1441908000 1457632800 ## tagDepLat tagDepLon tagDepAlt ## 1 51.4839 -80.45 NA ## 2 51.4839 -80.45 NA ## 3 51.4839 -80.45 NA ## 4 51.4839 -80.45 NA ## 5 51.4839 -80.45 NA ## 6 51.4839 -80.45 NA ## tagDepComments ## 1 {&quot;ageID&quot;:&quot;HY&quot;,&quot;bill&quot;:36.5,&quot;blood&quot;:&quot;Y&quot;,&quot;country&quot;:&quot;Canada&quot;,&quot;culmen&quot;:36.5,&quot;fatScore&quot;:3,&quot;locationID&quot;:&quot;NorthPoint_net&quot;,&quot;province&quot;:&quot;Ontario&quot;,&quot;sexID&quot;:&quot;U&quot;,&quot;tarsus&quot;:33.3,&quot;weight&quot;:137.8,&quot;wing&quot;:162,&quot;comments&quot;:null} ## 2 {&quot;ageID&quot;:&quot;HY&quot;,&quot;bill&quot;:36.5,&quot;blood&quot;:&quot;Y&quot;,&quot;country&quot;:&quot;Canada&quot;,&quot;culmen&quot;:36.5,&quot;fatScore&quot;:3,&quot;locationID&quot;:&quot;NorthPoint_net&quot;,&quot;province&quot;:&quot;Ontario&quot;,&quot;sexID&quot;:&quot;U&quot;,&quot;tarsus&quot;:33.3,&quot;weight&quot;:137.8,&quot;wing&quot;:162,&quot;comments&quot;:null} ## 3 {&quot;ageID&quot;:&quot;HY&quot;,&quot;bill&quot;:36.5,&quot;blood&quot;:&quot;Y&quot;,&quot;country&quot;:&quot;Canada&quot;,&quot;culmen&quot;:36.5,&quot;fatScore&quot;:3,&quot;locationID&quot;:&quot;NorthPoint_net&quot;,&quot;province&quot;:&quot;Ontario&quot;,&quot;sexID&quot;:&quot;U&quot;,&quot;tarsus&quot;:33.3,&quot;weight&quot;:137.8,&quot;wing&quot;:162,&quot;comments&quot;:null} ## 4 {&quot;ageID&quot;:&quot;HY&quot;,&quot;bill&quot;:36.5,&quot;blood&quot;:&quot;Y&quot;,&quot;country&quot;:&quot;Canada&quot;,&quot;culmen&quot;:36.5,&quot;fatScore&quot;:3,&quot;locationID&quot;:&quot;NorthPoint_net&quot;,&quot;province&quot;:&quot;Ontario&quot;,&quot;sexID&quot;:&quot;U&quot;,&quot;tarsus&quot;:33.3,&quot;weight&quot;:137.8,&quot;wing&quot;:162,&quot;comments&quot;:null} ## 5 {&quot;ageID&quot;:&quot;HY&quot;,&quot;bill&quot;:36.5,&quot;blood&quot;:&quot;Y&quot;,&quot;country&quot;:&quot;Canada&quot;,&quot;culmen&quot;:36.5,&quot;fatScore&quot;:3,&quot;locationID&quot;:&quot;NorthPoint_net&quot;,&quot;province&quot;:&quot;Ontario&quot;,&quot;sexID&quot;:&quot;U&quot;,&quot;tarsus&quot;:33.3,&quot;weight&quot;:137.8,&quot;wing&quot;:162,&quot;comments&quot;:null} ## 6 {&quot;ageID&quot;:&quot;HY&quot;,&quot;bill&quot;:36.5,&quot;blood&quot;:&quot;Y&quot;,&quot;country&quot;:&quot;Canada&quot;,&quot;culmen&quot;:36.5,&quot;fatScore&quot;:3,&quot;locationID&quot;:&quot;NorthPoint_net&quot;,&quot;province&quot;:&quot;Ontario&quot;,&quot;sexID&quot;:&quot;U&quot;,&quot;tarsus&quot;:33.3,&quot;weight&quot;:137.8,&quot;wing&quot;:162,&quot;comments&quot;:null} ## tagDeployTest fullID deviceID recvDeployID ## 1 NA SampleData#378:9.7@166.38(M.16047) 486 2510 ## 2 NA SampleData#378:9.7@166.38(M.16047) 486 2510 ## 3 NA SampleData#378:9.7@166.38(M.16047) 486 2510 ## 4 NA SampleData#378:9.7@166.38(M.16047) 486 2510 ## 5 NA SampleData#378:9.7@166.38(M.16047) 486 2510 ## 6 NA SampleData#378:9.7@166.38(M.16047) 515 2512 ## recvDeployLat recvDeployLon recvDeployAlt recv recvDeployName ## 1 42.60699 -72.71657 NA Lotek-159 Shelburne ## 2 42.60699 -72.71657 NA Lotek-159 Shelburne ## 3 42.60699 -72.71657 NA Lotek-159 Shelburne ## 4 42.60699 -72.71657 NA Lotek-159 Shelburne ## 5 42.60699 -72.71657 NA Lotek-159 Shelburne ## 6 42.68067 -72.47392 NA Lotek-164 BennettMeadow ## recvSiteName isRecvMobile recvProjID recvUtcOffset antType antBearing ## 1 &lt;NA&gt; 0 74 NA yagi-9 127 ## 2 &lt;NA&gt; 0 74 NA yagi-9 127 ## 3 &lt;NA&gt; 0 74 NA yagi-9 127 ## 4 &lt;NA&gt; 0 74 NA yagi-9 127 ## 5 &lt;NA&gt; 0 74 NA yagi-9 127 ## 6 &lt;NA&gt; 0 74 NA yagi-9 243 ## antHeight speciesEN speciesFR speciesSci speciesGroup ## 1 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus BIRDS ## 2 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus BIRDS ## 3 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus BIRDS ## 4 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus BIRDS ## 5 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus BIRDS ## 6 NA Red Knot BÃ©casseau maubÃ¨che Calidris canutus BIRDS ## tagProjName recvProjName gpsLat gpsLon gpsAlt sunrise ## 1 SampleData &lt;NA&gt; NA NA NA 2015-10-26 11:16:49 ## 2 SampleData &lt;NA&gt; NA NA NA 2015-10-26 11:16:49 ## 3 SampleData &lt;NA&gt; NA NA NA 2015-10-26 11:16:49 ## 4 SampleData &lt;NA&gt; NA NA NA 2015-10-26 11:16:49 ## 5 SampleData &lt;NA&gt; NA NA NA 2015-10-26 11:16:49 ## 6 SampleData &lt;NA&gt; NA NA NA 2015-10-26 11:15:58 ## sunset ts_to_set ts_since_set ts_to_rise ts_since_rise ## 1 2015-10-26 21:52:11 632.3533 806.2056 1438.215974 3.013824 ## 2 2015-10-26 21:52:11 631.7104 806.8485 1437.573097 3.656701 ## 3 2015-10-26 21:52:11 630.9109 807.6480 1436.773577 4.456221 ## 4 2015-10-26 21:52:11 630.2513 808.3076 1436.113997 5.115801 ## 5 2015-10-26 21:52:11 629.4518 809.1071 1435.314477 5.915321 ## 6 2015-10-26 21:51:06 639.0310 799.5242 3.896393 1437.332308 "],["appendixD.html", "D Appendix - motus - Data filtering functions D.1 listRunsFilters D.2 Arguments D.3 Example D.4 createRunsFilter D.5 getRunsFilters D.6 writeRunsFilter", " D Appendix - motus - Data filtering functions The motus R package offers functions that can be used to assign probabilities to tag detections, and to filter detections based on those probabilities. For example, as you work through your data to clean false positive and ambiguous detections (see Chapter 5), you may determine that some detections do not belong to your tag(s). Instead of simply using an R script to filter out those detections, you can use these filter functions to create and save a custom filter in your .motus file, which assigns a probability value between 0 and 1 to the runIDs supplied in the filter. The data filtering functions in the R package work at the level of a run. A run is a group of consecutive detections of a tag detected on a receiver. In general, a detection with a run length of 2 has a high probability of being a false positive detection. The probabilities associated with each runID can be generated in a number of possible ways, including at the simplest level, generating a list of 0s and 1s for records that you would like to exclude or include. Alternatively, you might develop a model that assigns a probability to each runID in your data. D.1 listRunsFilters D.1.1 Description Returns a dataframe containing the filterIDs, logins, names, projectIDs and descriptions for a given tag or receiver projectID available in the local database. D.2 Arguments src is the SQLite object that you get from loading a .motus file into R, e.g., sql.motus file in Chapter 3. D.3 Example filt.df &lt;- listRunsFilters(src = sql.motus) D.4 createRunsFilter D.4.1 Description This function can be used mostly by users to modify properties of existing filters (e.g., filter description or projectID), but it is also being called internally by writeRunsFilter (section D.6) to generate a new filterID. To save the actual filter records, you must use writeRunsFilter (section D.6). The function returns the filterID (integer) in the local database that matches the new or existing filter with the provided filterName. If a filter with the same name already exists, the function generates a warning and returns the ID of the existing filter. D.4.2 Arguments src is the SQLite object that you get from loading a .motus file into R, e.g., sql.motus file in Chapter 3. filterName the name you would like to assign to the filter. The function only creates a new filter if the name does not already exist locally. motusProjID the numeric ID associated with a project, e.g., 176 for the sample data used throughout this book. The function defaults to motusProjID = NA when project ID is not supplied, which is the recommended value for now. The project ID assigned to a filter will mostly be useful for future synchronization of filters with the Motus server. The detection records contained in the filter do not have to be assigned to the projectID assigned to the filter. descr default NA. Optional description of the filter. update boolean (default = FALSE). If the filter already exists, determines if the properties (e.g. descr are preserved or updated) D.4.3 Example Create a new filter called myfilter for the sql.motus database which is not attached to a specific project: createRunsFilter(sql.motus, &quot;myfilter&quot;) # OR add assignment to project createRunsFilter(sql.motus, &quot;myfilter&quot;, motusProjID = 176) # OR add project and description, possibly updating any previous version called myfilter. createRunsFilter(sql.motus, &quot;myfilter&quot;, motusProjID = 176, descr = &quot;assign probability of 0 to false positives&quot;, update = TRUE) D.5 getRunsFilters D.5.1 Description Returns a sqlite table reference to the runsFilters records saved in the database (runID, motusTagID, and probability) associated with a specific name (and optionally project) from the local database. For examples on how you can use the returned table to merge with your detection data, refer to section 5.9.2 in chapter 5. D.5.2 Arguments src is the SQLite object that you get from loading a .motus file into R, e.g., sql.motus file in Chapter 3. filterName the name you used when you created or saved your filter. Function returns a warning if the filterName doesnt exist. motusProjID the numeric ID associated with a project, e.g., 176 for the sample data used throughout this book. The function defaults to motusProjID = 'NA' when project ID is not supplied. D.5.3 Example tbl.filt &lt;- getRunsFilters(src = sql.motus, filterName = &quot;myfilter&quot;) tbl.filt2 &lt;- getRunsFilters(sql.motus, &quot;myfilter2&quot;) # filter records from df that are in tbl.filt df &lt;- left_join(df, tbl.filt, by = c(&quot;runID&quot;, &quot;motusTagID&quot;)) %&gt;% mutate(probability = if_else(is.na(probability), 1, probability)) %&gt;% filter(probability &gt; 0) # you can apply a second filter, tbl.filt2, to the result of the previous filter df &lt;- left_join(df, tbl.filt2, by = c(&quot;runID&quot;, &quot;motusTagID&quot;)) %&gt;% mutate(probability = if_else(is.na(probability), 1, probability)) %&gt;% filter(probability &gt; 0) D.6 writeRunsFilter D.6.1 Description Writes to the local database (SQLite file) the content of a dataframe containing runID, motusTagID, and assigned probability. If the filterName provided does not exist, the function will call createRunsFilter (section D.4) to create one in your database. The default behaviour of the function is that any new records from the dataframe are appended to the existing or new filter called filterName, those that already are present (same runID and motusTagID) are replaced (overwrite=TRUE), but those that are not included in the dataframe are retained in the existing filter table (delete=FALSE). To entirely replace the existing filter values with those of the new dataframe, use delete=TRUE. The function returns a sqlite table reference to the filter, similarly to getRunsFilter (section D.5). D.6.2 Arguments src is the SQLite object that you get from loading a .motus file into R, e.g., sql.motus file in Chapter 3. filterName the name of the filter you would like to assign the database to. motusProjID the numeric ID associated with a project, e.g., 176 for the sample data used throughout this book. Default = NA when project ID is not supplied. df dataframe which contains the runID (integer), motusTagID (integer), and probability (float) of detections you would like to assign a filter to. motusTagID should be the actual tag ID, and not the negative ambigID associated with ambiguous detections. overwrite Default = \"TRUE\". When TRUE, ensures that existing records (same runID and motusTagID) matching the same filterName and runID get replaced in the local database. delete Default = \"FALSE\". When TRUE, removes all existing filter records associated with the filterName and re-inserts the ones contained in df. This option should be used if df contains the entire set of filters you want to save. D.6.3 Examples # write a dataframe containing filter records (runID, motusTagID and # probability) to myfilter writeRunsFilter(src = sql.motus, filterName = &quot;myfilter&quot;, df = filter.df) # write a dataframe containing filter records (runID, motusTagID and # probability) to myfilter, overwriting a previous version entirely writeRunsFilter(src = sql.motus, fileName = &quot;myfilter&quot;, df = filter.df, delete = TRUE) # write a dataframe containing filter records (runID, motusTagID and # probability) to &quot;myfilter&quot;, but only append new records, leaving previously # created ones intact writeRunsFilter(src = sql.motus, &quot;myfilter&quot;, df = filter.df, overwrite = FALSE) "],["birds-eye-view-of-motus-data.html", "E Birds Eye View of Motus Data E.1 What data look like E.2 False positives E.3 False negatives E.4 Complication: data are processed in batches E.5 Batches E.6 Reprocessing Data E.7 The (eventual) Reprocessing Contract E.8 Reprocessing simplified: only by boot session E.9 Distributing reprocessed data", " E Birds Eye View of Motus Data This document has been adapted from a version written by John Brzustowski in 2017. It provides an overview of the fundamentals of how Motus data processing works. The document has been adapted to incorporate more recent developments, particularly the addition of new digital tags and base stations manufactured by Cellular Tracking Technologies (CTT), who took over the development from Cornell University. E.1 What data look like Heres a segment of data from a receiver (with a single antenna): Receiver R Time -&gt; \\==========================================================================\\ Tag A: / 1-----1--1----1-----1-----1 4---4-----4--4-------4--4-/ &lt;- antenna #1 \\. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \\ Tag B: / 3-----3--3--3--3--3-------3----3--3 / &lt;- antenna #1 \\. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \\ Tag C: / 2--2---2--2--2--2--2--2--2--2--2--2--2--2--2--2--2--2--2--2 / &lt;- antenna #1 \\. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \\ Tag C: / 5--------5--5--5--5--5--5-----5--------5--------5 / &lt;- antenna #2 \\==========================================================================\\ time increases from left (earlier) to right (later) horizontal lanes, separated by . . . correspond to individual tags, labelled at left hits (detections) of a tag are plotted as single digits within its lane in the diagram above, runs are labelled by digits. So all hits of tag A above are either in run 1 or in run 4. the same tag can be detected simultaneously on multiple antennae, and therefore be part of runs that overlap in time. For example, tag C is detected on antenna 1 and 2. In principle, the same tag should never be part of overlapping runs on the SAME antenna, but in practice this can happen in noisy environments with Lotek tags, and it should be assumed that these runs are likely from other sources than actual tags (false positives). Overlapping run would not happen with CTT tags because of the way runs are built, but the rate of hits would still be expected to be around 1 per second or lower. for Lotek coded ID tags, individual hits are not sufficient to determine which tag is being detected, because multiple tags transmit the same ID. However, the period (spacing between consecutive transmissions) is precise, and differs among tags sharing the same ID. the fundamental unit of detection for Lotek coded ID tags is the run, or sequence of hits of a given ID, with spacing compatible with the value for that tag. i.e. two hits might differ by the tags period, or by twice its period, or three times its period, , up to a limit required by drift between clocks on the transmit and receive sides. for Lotek ID tags, a run can have gaps (missing hits) up to a certain size. Beyond that size, measurement error and clock drift are large enough that we cant be sure that the next detection of the same ID code is after a compatible time interval. So for tag A above, were not sure the gap between the last detection in run 1 and the first detection in run 4 is really compatible with tag A, so run 1 is ended and a new run is begun. We could link runs 1 and 4 post-hoc, once we saw that run 4 was being built with gaps compatible with tag A, but at present, the run-building algorithm doesnt backtrack.) for CTT tags, there are 2^32 unique codes, which ensures that each of them is unique. Contrary to Lotek tags, runs are not limited to consecutive detections matching a precise period, in part because the period may vary depending on the energy available from the photovoltaic cell. Run are still assembled based on consecutive detections on a single antenna (or node, if applicable), as long as they are not spaced by more than an arbitrary period (600 seconds). E.2 False positives False positives (apparent detections of tags actually caused by other sources) exist in all technologies and need to be taken into account. These can happen for quite a number of reasons, and will sometimes affect Lotek and CTT tags in different measure. False positives are difficult to identify, but there are approaches to identify conditions in which the are more likely to occur, and potential ways to mitigate them. Noisy environments: radio noise from interference can create bursts that look like tags. As the amoung of radio pulses from other sources increases in the environment, so it the expected number of false positives. Bit errors: actual tag signals may be incorrectly transmitted. Those should rarely produce valid IDs, but they will be more likely with CTT tags, mostly because where is a very high number of possible combinations (4 billions). They should still rarely produce an ID of a tag actually manufactured. In CTT tags, bit errors has been found to lead more often to certain patterns (e.g. the last trailing digits being all 7 or Fs: xxxFFFF due to only a partial signal being received), and those patterns have since been excluded from the list of valid tags. Aliasing: aliasing happens when the combination of multiple tags create the appearance of a tag that is not present but matches another known tag. This can happen in at least 2 ways: 1) 2 tags with distinct IDs, but with the same period (both Lotek and CTT). 2) 2 tags with the same ID, but with distinct periods (only for Lotek). In the first case, if the burst of both tags overlap, they may interfere with each other and create the appearance of a new tag for a while. Assuming that the 2 tags do not have exactly the same period, their bursts should eventually drift apart and the precise alias probably will not persist over a very long run. In the second case, if you have multiple tags with the same ID but distinct periods, this may potentially also result in new periods, but those would likely rarely exceed 2 consecutive hits (run length = 2). Both types of aliasing is mostly problematic in environments where you have many tags present simultaneously that increases the incidence of overlapping tags (e.g. colonies). For both Lotek and CTT tags, their manufacturers have integrated various methods to reduce the incidence of false detections into their proprietary technologies. Data collected by Sensor Gnomes are processed in Motus by the Tag finder, which looks at properties of the signal to exclude likely false positives (e.g. higher deviation in the frequency of pulses within a burst). The parameters can potentially be adjusted, but an aggressive approach aimed at reducing false positives will also result in an increase in false negatives. Run length: With both types of tag technologies, the likelihood of obtaining false positives should decrease as the run length increases. For Lotek tags, we generally recommend ignoring runs comprised only of 2 or 3 hits. Some (many?) probably relate to real tag detections, but the vast majority probably do not. For CTT tags, we do not yet have a suggested minimum threshold. In most cases, given that tag period is short, one would expect that true single-hit runs to be quite rare, so those should likely be excluded to be safer. The likelihood of obtaining the same false ID in consecutive detections is probably very low, except for some specific tag IDs that are more prone to error. Runs of 2 detections or more are probably safe in most instances. Measures of noise. A higher amount of radio pulses is likely a good predictor of false positives, though other factors are also at play, and not all radio noise is problematic in the same way. We recommend that you use the number of runs comprised of only 2 hits, which is provided by the activity table (see details here). In noisy environments, shorter runs are much more likely to be false positives and should be excluded. Missed detections: False positives should more often lead to gaps in detections during a run. A run that contains several gaps in detection would therefore be deemed less reliable. A simple metric for this would be to divide the number of hits in a run (the run lenght) by the duration of the run (tsEnd - tsStart). Longer runs with few or no gaps in detection would be optimal. Overlapping runs. Runs of the same tag on the same antenna should also be an indication of false positives, but this should be highly correlated with the number and/or ratio of short runs described above. Spatio-temporal models. State-space models and other approach can be used to assess whether movement make sense from a biological point of view, and can help assign probabilities that individual detections are valid. If you have any suggestions about techniques you are using to separate true detections from false positives, we encourage you to share them with us! E.3 False negatives False negatives are usually even more difficult to detect. Faulty equipement or installation is always possible of course. Please refer to the installation guidelines to make sure you follow all the recommendations. DO NOT FORGET to register your tags! (details here) DO NOT FORGET to activate your tags before deploying them! Make sure that you report your tag and receiver deployment details BEFORE uploading your data. Motus tag finder only seek tags that are known to be deployed. E.4 Complication: data are processed in batches The picture above is complicated by several facts: receivers are often deployed to isolated areas so that we can only obtain raw data from them occasionally receivers are not aware of the full set of currently-active tags sensorgnome receivers do not know the full Lotek code set; they record pulses thought to be from Lotek coded ID tags, but are only able to assemble them into tag hits for a small set of tags for which they have an on-board database, built from the users own recordings of their tags. This limitation is due to restrictions in the agreement between Lotek and Acadia University for our use of their codeset. Lotek receivers report each detected tagID independently, and do not assemble them into runs. This means a raw Lotek .DTA file does not distinguish between tag 123:4.5 and tag 123:9.1 (i.e. between tags with ID 123 and burst intervals 4.5 seconds and 9.1 seconds). It follows that: raw receiver data must be processed on a server with full knowledge of: which tags are deployed and likely active the Lotek codeset(s) raw data should be processed in incremental batches processed data should be distributed to users in incremental batches, especially if they wish to obtain results as they arrive, rather than in one lump after all their tags have expired. E.5 Batches A batch is the result of processing one collection of raw data files from a receiver. Batches are not inherent in the data, but instead reflect how data were processed. Batches arise in these ways: a user visits an isolated receiver, downloads raw data files from it, then uploads the files to motus.org once they are back from the field a receiver connected via WiFi, ethernet, or cell modem is polled for new data files; this typically happens every hour, with random jitter to smooth the processing load on the motus server an archive of data files from a receiver is re-processed on the motus server, because important metadata have changed (e.g. new or changed tag deployment records), or because a significant change has been made to processing algorithms. Batches are artificial divisions in the data stream, so runs of hits will often cross batch boundaries. Adding this complication to the picture above gives this: Receiver R Time -&gt; \\====================|=================================|=====================\\ Tag A: / 1-----1--1-|---1-----1-----1 4---4|-----4--4-------4--4-/ \\. . . . . . . . . . | . . . . . . . . . . . . . . . . | . . . . . . . . . . \\ Tag B: / | 3-----3--3--3--3--3-------3---|-3--3 / \\. . . . . . . . . . | . . . . . . . . . . . . . . . . | . . . . . . . . . . \\ Tag C: / 2--2---2|--2--2--2--2--2--2--2--2--2--2--2|--2--2--2--2--2--2 / \\====================|=================================|=====================\\ | | &lt;---- Batch N ------&gt;|&lt;------- Batch N+1 -------------&gt;|&lt;----- Batch N+2 ----&gt; E.5.1 Receiver Reboots A receiver reboots when it is powered down and then (possibly much later) powered back up. Reboots often correspond to a receiver: being redeployed having its software updated or having a change made to its attached radios, so motus treats receiver reboots in a special way: a reboot always begins a new batch; i.e. batches never extend across reboots. This simplifies determination of data ownership. For example, all data in a boot session (time period between consecutive reboots) are deemed to belong to the same motus project. This reflects the fact that a receiver is (almost?) always turned off between the time it is deployed by one project, and the time it is redeployed by another project. any active tag runs are ended when a receiver reboots. Even if the same tag is present and broadcasting, and even if the reboot takes only a few minutes, hits of a tag before and after the reboot will belong to separate runs. This is partly for convenience in determining data ownership, as mentioned above. It is also necessary because sometimes receiver clocks are not properly set by the GPS after a reboot, and so the timestamps for that boot session will revert to a machine default, e.g. 1 Jan 2000. Although runs from these boot sessions could in principle be re-assembled post hoc if the system clock can be pinned from information in field notes, this is not done automatially at present. parameters to the tag-finding algorithm are set on a per-batch basis. At some field sites, we want to allow more lenient filtering because there is very little radio noise. At other sites, filtering should be more strict, because there is considerable noise and high false-positive rates for tags. motus allows projects to set parameter overrides for individual receivers, and these overrides are applied by boot session, because redeployments (always?) cause a reboot. when reprocessing data (see below) from an archive of data files, each boot session is processed as a batch. E.5.2 Incremental Distribution of Data The Motus R package allows users to build a local copy of the database of all their tags (or receivers) hits incrementally. A user can regularly call the tagme() function to obtain any new hits of their tags. Because data are processed in batches, tagme() either does nothing, or downloads one or more new batches of data into the users local DB. Each new batch corresponds to a set of files processed from a single receiver. A batch record includes these items: - receiver device ID - how many of hits of their tags occurred in the batch - first and last timestamp of the raw data processed in this batch Each new batch downloaded will include hits of one or more of the userss tags (or someones tags, if the batch is for a receiver database). A new batch might also include some GPS fixes, so that the user knows where the receiver was when the tags were detected. A new batch will include information about runs. This information comes in three versions: information about a new run; i.e. one that begins in this batch information about a continuing run; i.e. a run that began in a previous batch, has some hits in this batch, and is not known to have ended information about an ending run; i.e. a run that began in a previous batch, might have some hits in this batch, but which is also known to end in this batch (because a sufficiently long time has elapsed since the last detection of its tag) Although the unique runID identifier for a run doesnt change when the user calls tagme(), the number of hits in that run and its status (done or not), might change. E.6 Reprocessing Data motus will occasionally need to reprocess raw files from receivers. There are several reasons: new or modified tag deployment records. The tag detection code relies on knowing the active life of each tag it looks for, to control rates of false positive and false negative hits. If the deployment record for a tag only reaches the server after it has already processed raw files overlapping the tags deployment, then those files will need to be reprocessed in order to (potentially) find the tag therein. Similary, if a tag was mistakenly sought during a period when it was not deployed, it will have used up signals that could instead have come from other tags, thereby causing both its own false positives, and false negatives on other tags. (This is only true for Lotek ID tags; CTT should be unaffected, provided deployed tags are well dispersed in the ID codespace.) bug fixes or improvements in the tag finding algorithm corrections of mis-filed data from receivers. Sometimes, duplication among receiver serial numbers (a rare event) is only noticed after data from them has already been processed. Those data will likely have to be reprocessed so that hits are assigned to the correct station. Interleaved data from two receivers having the same serial number will typically prevent hits from at least one of them, as the tag finder ignores data where the clock seems to have jumped backwards significantly. E.7 The (eventual) Reprocessing Contract Reprocessing can be very disruptive from the users point of view (What happened to my hits?), so motus reprocessing will be: optional: users should be able to obtain new data without having to accept reprocessed versions of data they already have. reversible: users should be able to go back to a previous version of any reprocessed data they have accepted. transparent: users will receive a record of what was reprocessed, why, when, what was done differently, and what changed all-or-nothing: for each receiver boot session for which users have data, these data must come entirely from either the original processing, or a subsequent single reprocessing event. The user must not end up with an undefined mix of data from original and reprocessed sources. in-band: the users copy of data will be updated to incorporate reprocessed data as part of the normal process of updating to obtain new data, unless they choose otherwise. We expect that most users will want to accept reprocessed data most of the time. Initially, motus data processing might not adhere to this contract, but it is an eventual goal. E.8 Reprocessing simplified: only by boot session A general reprocessing scenario would look like this: Receiver R Time -&gt; \\=================!==|=================================|======!==============\\ Tag A: / 1-----1-!1-|---1-----1-----1 4---4|-----4!-4-------4--4-/ \\. . . . . . . . .!. | . . . . . . . . . . . . . . . . | . . .!. . . . . . . \\ Tag B: / ! | 3-----3--3--3--3--3-------3---|-3--3 ! / \\. . . . . . . . .!. | . . . . . . . . . . . . . . . . | . . .!. . . . . . . \\ Tag C: / 2--2-!-2|--2--2--2--2--2--2--2--2--2--2--2|--2--2!-2--2--2--2 / \\=================!==|=================================|======!==============\\ ! | | ! &lt;---- Batch N ----!-&gt;|&lt;------- Batch N+1 -------------&gt;|&lt;-----!Batch N+2 ----&gt; ! ! !&lt;- Reprocess this period (no, too hard!) -&gt;! if raw data records from an arbitrary stretch of time could be reprocessed. However, this is complicated because runs like 1 2, and 4 above might lose or gain hits within the reprocessing period, but not outside of it. This might even break an existing run into distinct new runs. This situation is challenging (NB: not impossible; might be a TODO) to formalize and represent in the database if we want to maintain a full history of processing. For example, if reprocessing deletes some hits from run 2, how do we represent both the old and the new versions of that run? The complications arise due to runs crossing the reprocessing period boundaries, so for simplicity we should choose a reprocessing period that no runs cross. Currently, that means a boot session, as discussed above. E.9 Distributing reprocessed data The previous section shows why we only reprocess data by boot session. Given that, how do we get reprocessed data to users while fulfilling the reprocessing contract? Note that a reprocessed boot session will fully replace one or more existing batches and one or more runs, because batches and runs both nest within boot sessions. Replacement of data by reprocessed versions should happen in-band (5 above), so one approach is this: the batches_for_XXX API entries should mark new batches which result from reprocessing, so that the client can deal with them appropriately. This can be done by adding a field called reprocessID with these semantics: reprocessID == 0: data in this batch are from new raw files; the normal situation reprocessID == X &gt; 0: data in this batch are from reprocessing existing raw files. X is the ID of the reprocessing event, and a new API entry reprocessing_info (X) can be called to obtain details about it. if the user chooses to accept the reprocessed version, then existing batches, runs, hits and GPS fixes from the same receiver and boot session are retired before adding the new batches. if the user chooses to reject the reprocessed version, then X is added to a client-side blacklist, and the user will not receive any data from batches whose reprocessID is on the blacklist. later, if a user decides to accept a reprocessing event they had earlier declined, then the IDs of new batches for that event can be fetched from another new API reprocessing_batches (X), and the original batches will be deleted to let users more efficiently fetch the best version of their dataset (i.e. accepting all reprocessing events), we should also mark batches which are subsequently replaced by a reprocessing event. For this, we add the field replacedIn with these semantics: replacedIn == 0: data in this batch have not been replaced by any reprocessing event replacedIn == X &gt; 0: data in this batch have been replaced by reprocessing event X. Then the client can ignore any batches for which replacedIn &gt; 0. We could also add a new boolean parameter unreplacedOnly to the batches_for_XXX API entries. It defaults to false, but if true, then only batches which have not been replaced by subsequent reprocessing events are returned. users can choose a policy for how reprocessed data are handled by setting the value of Motus$acceptReprocessedData in their workspace before calling tagme(): Motus$acceptReprocessedData &lt;- TRUE; always accept batches of data from reprocessing events Motus$acceptReprocessedData &lt;- FALSE; never accept batches of data from reprocessing events Motus$acceptReprocessedData &lt;- NA (default); ask about each reprocessing event "]]
